---
id: 3223
title: "משפט מייהיל-נרוד"
date: 2015-02-11 15:25:06
layout: post
categories: 
  - תורת הסיבוכיות
tags: 
  - אוטומטים
  - יחסי שקילות
  - משפט מייהיל-נרוד
  - שפות רגולריות
---
עבורי, משפט מייהיל-נרוד הוא המשפט האולטימטיבי בכל הנוגע להבנה של מה בעצם הופך שפה לרגולרית או ללא רגולרית, איך "אמור" להיראות אוטומט עבורה, ובכלל איך עובד הקטע הזה של אוטומטים. לטעמי זה המשפט היפה ביותר בחומר הזה. אבל אני לא רוצה להציג אותו מהר מדי. בספרי לימוד לרוב פשוט נותנים את הניסוח שלו, אחרי קצת עבודת הכנה נדרשת שבה מציגים עוד כמה מושגים. בפוסט הזה אני לא רצה לעשות את זה - אני רוצה לנסות ו"לגלות" אותו מחדש, כדי שנבין קצת יותר טוב מאיפה הוא מגיע ולמה הוא (והטרמינולוגיה שמתלווה אליו) הגיוניים.

השאלה שהולכת להנחות אותנו בפוסט הזה היא זו: <strong>איך בונים אוטומט מינימלי עבור שפה רגולרית? </strong>כאשר "מינימלי" כאן פירושו מבחינת מספר המצבים שלו, ו"אוטומט" הולך להיות סופי דטרמיניסטי.

אם כן, הבעיה היא זו: נתונה לנו שפה {% equation %}L{% endequation %}, ואנחנו רוצים לבנות עבורה אוטומט עם מספר מצבים מינימלי. בעצם מתחבאות כאן שתי בעיות שונות: האחת, אם {% equation %}L{% endequation %} נתונה לנו על ידי אוטומט {% equation %}A{% endequation %} כך ש-{% equation %}L\left(A\right)=L{% endequation %}. במקרה כזה, אנחנו רוצים לבצע מעין אופטימיזציה של {% equation %}A{% endequation %} ולקבל ממנו אוטומט שקול עם מספר מצבים מינימלי. אתייחס לבעיה הזו בהמשך אבל אני מעדיף להתחיל דווקא מהבעיה השניה - כאן {% equation %}L{% endequation %} נתונה לנו בניסוח מילולי, ואנחנו רוצים לבנות ידנית את האוטומט עבורה כך שהוא יהיה המינימלי. באיזו גישה כדאי לנקוט לשם כך?

בואו נתחיל עם דוגמה פשוטה. השפה {% equation %}L=\left\{ w\in\left\{ a,b\right\} ^{*}\ |\ \left|w\right|\equiv_{2}0\right\} {% endequation %} של כל המילים מאורך זוגי. אני רוצה לבנות אוטומט לשפה. ממה מתחילים? ובכן, ממה שחייבים. לאוטומט חייב להיות מצב התחלתי {% equation %}q_{0}{% endequation %}, אז אני מוסיף אותו לקבוצת המצבים של האוטומט. עכשיו אני שואל את עצמי - האם זה יהיה מצב מקבל או לא? התשובה לשאלה הזו נקבעת על פי השאלה האם {% equation %}\varepsilon{% endequation %} שייכת לשפה או לא. אם היא כן - אז {% equation %}q_{0}{% endequation %} חייב להיות מקבל אחרת אין שום סיכוי שנקבל את {% equation %}\varepsilon{% endequation %}; אם היא לא, אז אסור ל-{% equation %}q_{0}{% endequation %} להיות מקבל. במקרה שלנו המסקנה היא ש-{% equation %}q_{0}{% endequation %} יהיה מצב מקבל.

עכשיו, מה אני עוד חייב לעשות? להגדיר את פונקציית המעברים של האוטומט. אני לוקח את {% equation %}a{% endequation %} ומנסה להבין איך אני רוצה להגדיר את {% equation %}\delta\left(q_{0},a\right){% endequation %}. יש לי שתי אפשרויות: או שזה יהיה {% equation %}q_{0}{% endequation %}, או שזה יהיה מצב חדש. האם זה יכול להיות {% equation %}q_{0}{% endequation %}? ובכן, כבר הסכמנו ש-{% equation %}q_{0}{% endequation %} הוא מצב מקבל, ולכן אם {% equation %}\delta\left(q_{0},a\right)=q_{0}{% endequation %} ינבע מכך ש-{% equation %}a\in L{% endequation %}, מה שלא נכון. מכאן שאין לי ברירה - <strong>אסור</strong> להגדיר {% equation %}\delta\left(q_{0},a\right)=q_{0}{% endequation %} ואני חייב להכניס מצב חדש למשחק.

בואו נעצור שניה ונתאר בצורה קצת אחרת את מה שראינו כרגע. לפני דקה החלטתי ש-{% equation %}q_{0}{% endequation %} יהיה מצב מקבל בגלל ש-{% equation %}\varepsilon\in L{% endequation %} . רגע אחר כך החלטתי שאסור לי להגדיר {% equation %}\delta\left(q_{0},a\right)=q_{0}{% endequation %} בגלל ש-{% equation %}a\notin L{% endequation %}. כלומר, מה שראיתי הוא שיש <strong>הפרדה</strong> בין {% equation %}\varepsilon{% endequation %} ובין {% equation %}a{% endequation %} - שתי המילים הללו שונות בצורה מהותית בכך שהאחת שייכת לשפה והשניה לא. המסקנה שלי הייתה שלא ייתכן שפונקציית המעברים {% equation %}\delta{% endequation %} תעביר את שתיהן לאותו מקום - שחייב להתקיים {% equation %}\hat{\delta}\left(q_{0},\varepsilon\right)\ne\hat{\delta}\left(q_{0},a\right){% endequation %}. זה אולי נשמע טריוויאלי בינתיים, אבל זה תופס את הרעיון הבסיסי שמאחורי מייהיל-נרוד.

טוב, חזרה לבניית האוטומט. הגענו למסקנה שאנחנו צריכים מצב חדש - נקרא לו {% equation %}q_{1}{% endequation %} - כך ש-{% equation %}\delta\left(q_{0},a\right)=q_{1}{% endequation %}. כמו כן בהכרח {% equation %}q_{1}{% endequation %} אינו מצב מקבל, אחרת הייתי מקבל את {% equation %}a{% endequation %} ושוב היינו בצרות. האם סיימנו? לא! כי ראשית כל עדיין לא טיפלתי ב-{% equation %}\delta\left(q_{0},b\right){% endequation %}; ושנית, עכשיו אני צריך לטפל גם במעברים של {% equation %}q_{1}{% endequation %}.

עבור {% equation %}\delta\left(q_{0},b\right){% endequation %} שוב ברור שאסור שיתקיים {% equation %}\delta\left(q_{0},b\right)=q_{0}{% endequation %}. אז יש לי שתי אפשרויות: או ש-{% equation %}\delta\left(q_{0},b\right)=q_{1}{% endequation %} או ש-{% equation %}\delta\left(q_{0},b\right)=q_{2}{% endequation %} עבור מצב חדש, {% equation %}q_{2}{% endequation %}. עכשיו, לנו ברור אינטואיטיבית שאני יכול להגדיר {% equation %}\delta\left(q_{0},b\right)=q_{1}{% endequation %} כי מה כבר ההבדל בין {% equation %}a{% endequation %} ו-{% equation %}b{% endequation %} בכל הנוגע לשפה {% equation %}L{% endequation %}. זה ברור לכם? אינטואיטיבית? יופי, כי זה בדיוק מה שמייהיל-נרוד בא לפרמל - את ההבנה האינטואיטיבית הזו. בינתיים בואו נניח שאני מגדיר {% equation %}\delta\left(q_{0},b\right)=q_{1}{% endequation %} ועכשיו בואו נדבר על המעברים שיוצאים מ-{% equation %}q_{1}{% endequation %}. מה יהיה {% equation %}\delta\left(q_{1},a\right){% endequation %}? ובכן, המצב שאליו נעבור הוא המצב שאליו מגיעים באוטומט אם קוראים את {% equation %}aa{% endequation %}, וזו מילה מאורך זוגי ולכן זה צריך להיות מצב מקבל. לכן יש לנו שתי אפשרויות: או להוסיף מצב מקבל חדש {% equation %}q_{2}{% endequation %} ולהעביר אליו, או להגדיר {% equation %}\delta\left(q_{1},a\right)=q_{0}{% endequation %} ובדומה גם {% equation %}\delta\left(q_{1},b\right)=q_{0}{% endequation %} מה שיסיים את בניית האוטומט כי כעת הוא "סגור" (טיפלנו בכל זוג של מצב וקלט). ושוב מגיעה לעזרתנו ה"אינטואיציה" שלנו שאומרת שאכן אפשר להגדיר {% equation %}\delta\left(q_{1},a\right)=q_{0}{% endequation %} ולא תהיה עם זה בעיה. אבל אנחנו רוצים להיות פורמליים, ולכן השאלה המרכזית ביותר כאן היא - איזו בעיה עלולה להתעורר, ולמה?

בואו נבין מה המשמעות של הגדרת {% equation %}\delta\left(q_{1},a\right)=q_{0}{% endequation %}. זה אומר שיתקיים {% equation %}\hat{\delta}\left(q_{0},\varepsilon\right)=\hat{\delta}\left(q_{0},aa\right){% endequation %}. כלומר, קיבלנו שתי מילים שהאוטומט מעביר לאותו מצב בדיוק. זה דורש שהן שתיהן יהיו בשפה ביחד, או ששתיהן לא יהיו בשפה ביחד, אחרת יש לנו בעיה ברורה. אבל קורה יותר מזה. אוטומט הוא הרי <strong>חסר זכרון</strong>. הוא לא יודע מה המילה שהביאה אותו למצב נתון. אם הוא הגיע לאותו מצב אחרי קריאת {% equation %}\varepsilon{% endequation %} ואחרי קריאת {% equation %}aa{% endequation %}, אז <strong>המשך החישוב</strong> שלו יהיה זהה ולא משנה איזו מילה הביאה אותו למצב הזה.

זה אומר ש<strong>לכל</strong> מילה {% equation %}z{% endequation %} שאותה אנחנו קוראים החל מהרגע שבו הגענו למצב הזה, התשובה שהאוטומט יחזיר אחרי קריאת {% equation %}z{% endequation %} הזו לא תהיה תלויה במה שהביא אותו אל המצב מלכתחילה. ולכן האוטומט צריך לענות את אותה תשובה על {% equation %}\varepsilon\cdot z{% endequation %} ועל {% equation %}aa\cdot z{% endequation %}, וזאת לכל {% equation %}z{% endequation %}. האבחנה הזו היא לב העניין.

בואו נראה דוגמה אחרת. הפעם השפה תהיה {% equation %}L=\left\{ w\in\left\{ a,b\right\} ^{*}\ |\ \left|w\right|\not\equiv_{3}0\right\} {% endequation %} - שפת כל המילים שאורכן <strong>אינו</strong> מתחלק ב-3. חיש קל ברור ש-{% equation %}\delta\left(q_{0},a\right)=q_{1}{% endequation %} כך ש-{% equation %}q_{1}{% endequation %} מקבל ו-{% equation %}q_{0}{% endequation %} אינו מקבל (מדוע?), וכעת השאלה היא מה לעשות עם {% equation %}\delta\left(q_{1},a\right){% endequation %}. מצד אחד, גם {% equation %}a{% endequation %} וגם {% equation %}aa{% endequation %} שניהם בשפה, ולכן ברמה העקרונית אם נגדיר {% equation %}\delta\left(q_{1},a\right)=q_{1}{% endequation %} (ולכן {% equation %}\hat{\delta}\left(q_{0},aa\right)=\hat{\delta}\left(q_{0},a\right){% endequation %}) זה לא יגרום לשגיאה מיידית; אבל השגיאה חייבת להגיע בצעד הבא, כי {% equation %}aa\cdot a\notin L{% endequation %} אבל {% equation %}a\cdot a\in L{% endequation %} ולכן {% equation %}z=a{% endequation %} היא מילה ש"מפרידה" בין {% equation %}a{% endequation %} ובין {% equation %}aa{% endequation %}. המסקנה היא שאנחנו חייביים מצב מקבל חדש {% equation %}q_{2}{% endequation %} כך ש-{% equation %}\delta\left(q_{1},a\right)=q_{2}{% endequation %}.

אם כן, מצאנו תכונה שמתארת האם זוג מילים הן כאלו שהאוטומט שבונים עבור השפה יכול להעביר לאותו מצב, או שאסור לו. אני אשתמש בסימון {% equation %}uR_{L}v{% endequation %} כדי לתאר את הסיטואציה שבה {% equation %}u,v{% endequation %} מקיימות את התכונה הזו; זה סימון מקובל לכך ששני איברים נמצאים יחד ב<strong>יחס</strong>. תזכורת קצרה לגבי מהו יחס, פורמלית: פשוט אוסף של זוגות. אני כותב {% equation %}uR_{L}v{% endequation %} במקום לכתוב {% equation %}\left(u,v\right)\in R_{L}{% endequation %} פשוט כי זה יותר קומפקטי.

הנה ההגדרה הפורמלית, שבשלב הזה אני מקווה שכבר תהיה ברורה וכך גם המוטיבציה אליה: {% equation %}uR_{L}v{% endequation %} אם ורק אם <strong>לכל</strong> {% equation %}z\in\Sigma^{*}{% endequation %} מתקיים ש-{% equation %}uz\in L\iff vz\in L{% endequation %}.

עכשיו, היחס הזה מקיים שלוש תכונות נחמדות: ראשית, {% equation %}uR_{L}u{% endequation %} לכל {% equation %}u\in\Sigma^{*}{% endequation %} - זה די מובן מאליו למה. גם מובן מאליו למה אם {% equation %}uR_{L}v{% endequation %} אז גם {% equation %}vR_{L}u{% endequation %}. התכונה השלישית יותר מעניינת: אם {% equation %}uR_{L}v{% endequation %} וגם {% equation %}vR_{L}w{% endequation %} אז {% equation %}uR_{L}w{% endequation %}. למה? פשוט, כי לכל {% equation %}z{% endequation %} מתקיים ש-{% equation %}uz\in L\iff vz\in L\iff wz\in L{% endequation %}. שלוש התכונות הללו נקראות, בהתאמה, <strong>רפלקיסיבות, סימטריות וטרנזיטיביות</strong>, ויחס שמקיים את שלוש התכונות הללו נקרא <strong>יחס שקילות</strong>. המהות של יחס שקילות היא שהוא מעין הכללה של מושג השוויון - הוא אומר "שני האובייקטים הללו אמנם לא חייבים להיות זהים, אבל באספקט אחד שלהם שמעניין אותנו הם שווים".

בהינתן איבר {% equation %}w{% endequation %}, אפשר להסתכל על קבוצת כל האיברים ששקולים לו על פי היחס, כלומר הקבוצה {% equation %}\left[w\right]_{R_{L}}\triangleq\left\{ u\in\Sigma^{*}\ |\ wR_{L}u\right\} {% endequation %}. לקבוצה כזו קוראים <strong>מחלקת השקילות </strong>של {% equation %}w{% endequation %}. זו תמיד קבוצה לא ריקה, כי {% equation %}w\in\left[w\right]_{R_{L}}{% endequation %} (כי רפלקסיביות). יותר מזה, אם {% equation %}u\in\left[w\right]_{R_{L}}{% endequation %} אז {% equation %}w\in\left[u\right]_{R_{L}}{% endequation %} (כי סימטריות) ואם {% equation %}v\in\left[w\right]_{R_{L}}\cap\left[u\right]_{R_{L}}{% endequation %} אז {% equation %}uR_{L}w{% endequation %} (כי טרנזיטביות). המסקנה מכל אלו: אוסף מחלקות השקילות של כל המילים ב-{% equation %}\Sigma^{*}{% endequation %}, דהיינו {% equation %}\left\{ \left[w\right]_{R_{L}}\ |\ w\in\Sigma^{*}\right\} {% endequation %} הוא <strong>חלוקה</strong> של {% equation %}\Sigma^{*}{% endequation %} לתת-קבוצות שהן זרות זו לזו, לא ריקות, ואיחודן נותן את כל {% equation %}\Sigma^{*}{% endequation %}. את האוסף הזה נהוג לסמן {% equation %}\Sigma^{*}/R_{L}\triangleq\left\{ \left[w\right]_{R_{L}}\ |\ w\in\Sigma^{*}\right\} {% endequation %}. קוראים לאוסף הזה לפעמים "קבוצת המנה" של יחס השקילות. הגודל שלו הולך להיות חשוב מאוד בהמשך אז בואו ניתן לו סימון: {% equation %}\mbox{index}\left(R_{L}\right)=\left|\Sigma^{*}/R_{L}\right|{% endequation %}.

עכשיו אפשר לנסח את משפט מייהיל-נרוד פורמלית: שפה {% equation %}L{% endequation %} היא רגולרית אם ורק אם {% equation %}\mbox{index}\left(R_{L}\right){% endequation %} סופי. יותר מכך: במקרה שבו {% equation %}L{% endequation %} רגולרית, אז {% equation %}\mbox{index}\left(R_{L}\right){% endequation %} הוא מספר המצבים של אוטומט <strong>מינימלי</strong> עבור השפה {% equation %}L{% endequation %}. זה גם נותן אינטואיציה לגבי הסיבה שבגללה אין אוטומט לשפה לא רגולרית {% equation %}L{% endequation %}: מכיוון ש-{% equation %}\mbox{index}\left(R_{L}\right)=\infty{% endequation %} לשפות כאלו, אז מספר המצבים באוטומט מינימלי עבורן היה אינסופי - וזה כמובן לא חוקי.

בואו נעבור להוכיח את המשפט. יש לנו שני כיוונים להוכיח. ראשית כל אני אראה שאם {% equation %}\mbox{index}\left(R_{L}\right){% endequation %} סופי אז קיים אוטומט סופי דטרמיניסטי שמקבל את {% equation %}L{% endequation %}, ואני אעשה את זה בצורה הכי ישירה שיש - אציג אוטומט עבור {% equation %}L{% endequation %}. ההוכחה הזו מקסימה מאוד, לטעמי, כי אנחנו הולכים לבנות את האוטומט הזה <strong>מתוך</strong> מחלקות השקילות של {% equation %}R_{L}{% endequation %}. לי זה קצת מזכיר את ההוכחה של משפט השלמות של גדל, אבל לא ארחיב על כך יותר מדי.

לפני שאציג את הבניה התקינה, בואו נחשוב על הבעיה מכיוון שונה שיתן לנו (לדעתי) אינטואיציה חזקה מאוד לגבי מדוע המשפט נכון ואיך בכלל יכולים להגיע אליו. בואו נניח לרגע שאני מסיר את המגבלה המעצבנת הזו ש-{% equation %}Q{% endequation %} חייב להיות סופי, ובוא ניקח שפה {% equation %}L{% endequation %} כלשהי. אני טוען שעכשיו אפשר לבנות אוטומט שמקבל את {% equation %}L{% endequation %}. איך הוא ייראה?

הדרך הכי טבעית לבנות אוטומט כזה היא לבנות את קבוצת המצבים כך שיש מצב לכל מילה, והקריאה של המילה מביאה את האוטומט אל המצב הזה. כלומר, נגדיר {% equation %}Q=\left\{ q_{w}\ |\ w\in\Sigma^{*}\right\} {% endequation %}. המצב ההתחלתי שלנו יהיה {% equation %}q_{\varepsilon}{% endequation %}, ואנחנו רוצים שיתקיים {% equation %}\hat{\delta}\left(q_{\varepsilon},w\right)=q_{w}{% endequation %}. די ברור שהדרך הנכונה להגדיר את פונקציית המעברים שלנו היא זו: {% equation %}\delta\left(q_{w},\sigma\right)=q_{w\sigma}{% endequation %}. כעת, מי יהיו המצבים המקבלים? בדיוק כאלו שמתאימים למילים שבשפה, כלומר {% equation %}F=\left\{ q_{w}\ |\ w\in L\right\} {% endequation %}. קחו רגע ותסבירו לעצמכם למה הבניה הזו באמת עובדת - הבעיה ה"קטנה" היחידה היא ש-{% equation %}Q{% endequation %} היא אינסופית.

אז מה אומרים מייהיל-נרוד? פשוט מאוד - קחו את האוטומט הנאיבי הזה, ותנסו <strong>לצמצם</strong> אותו כך שנישאר רק עם מספר סופי של מצבים. המפתח לצמצום של אוטומט הוא יחס השקילות {% equation %}R_{L}{% endequation %}. מה הוא אומר? אם שתי מילים שקולות ב-{% equation %}R_{L}{% endequation %}, זה אומר שמרגע שהאוטומט סיים לקרוא אותן, המשך החישוב שלו יכול להיות זהה. כלומר, <strong>אין סיבה</strong> ששתי המילים הללו יובילו למצבים שונים; הן יכולות להוביל לאותו מצב בדיוק. לכן אם {% equation %}uR_{L}v{% endequation %} אנחנו רוצים שהמצבים {% equation %}q_{u},q_{v}{% endequation %} יהיו אותו מצב - <strong>לאחד</strong> אותם. אבל זה נכון לא רק לזוגות של מצבים - באופן כללי, לכל מחלקת שקילות של {% equation %}R_{L}{% endequation %}, כל המילים שבמחלקה יכולות להוביל לאותו מצב. לכן יהיה לנו <strong>מצב לכל מחלקת שקילות</strong>. שאר ההגדרות של האוטומט הן מה שקורה כשלוקחים את הבניה שלמעלה ומחליפים את המצבים במחלקות שקילות.

אם כן, אני מגדיר {% equation %}Q=\Sigma^{*}/R_{L}=\left\{ \left[w\right]_{R_{L}}\ |\ w\in\Sigma^{*}\right\} {% endequation %}. שימו לב לדמיון ל-{% equation %}\left\{ q_{w}\ |\ w\in\Sigma^{*}\right\} {% endequation %} שלמעלה, רק שהחלפתי את {% equation %}q_{w}{% endequation %} ב-{% equation %}\left[w\right]_{R_{L}}{% endequation %}. במקום מצב לכל מילה, אני לוקח מצב לכל <strong>מחלקת שקילות</strong> של מילים. בכתיב שלי אני כותב את אותה מחלקת שקילות הרבה פעמים (למשל, אם {% equation %}uR_{L}v{% endequation %} אז {% equation %}\left[u\right]_{R_{L}}=\left[v\right]_{R_{L}}{% endequation %} ולכן מחלקת השקילות הזו תופיע לפחות פעמיים) - אבל זכרו שכאשר כותבים קבוצה וחוזרים על אותו איבר כמה פעמים, הוא "נחשב" רק פעם אחת. אז אין לי חזרות מיותרות ואם מספר מחלקות השקילות סופי, מספר המצבים של האוטומט סופי. כמו קודם, מה שאנחנו רוצים שיתקיים הוא ש-{% equation %}\hat{\delta}\left(q_{0},w\right)=\left[w\right]{% endequation %}

מה יהיה המצב ההתחלתי שלנו? כמובן, {% equation %}q_{0}=\left[\varepsilon\right]{% endequation %} (בלי זה לא היה סיכוי שיתקיים השוויון על פונקציית המעברים לעיל).

ומה יהיו המצבים המקבלים? כמובן, {% equation %}F=\left\{ \left[w\right]\ |\ w\in L\right\} {% endequation %}.

אויך נגדיר את פונקציית המעברים? שוב, זה לא חכם יותר מאשר לקחת את מה שתיארתי באוטומט האינסופי: {% equation %}\delta\left(\left[w\right],\sigma\right)=\left[w\sigma\right]{% endequation %}. מצד שני, ההגדרה הזו יותר טריקית ממה שנראה במבט ראשון כי יש כאן סכנה כללית שיש כשמתעסקים עם יחסי שקילות - אם אני מגדיר פונקציה על מחלקת שקילות <strong>באמצעות נציגים</strong>, אני צריך להוכיח שההגדרה לא תלויה בנציג, אחרת ההגדרה שלי לא שווה כלום.

בואו נסביר את זה יותר בפירוט. הפחד שלי הוא שקיימות מילים {% equation %}u,v{% endequation %} כך ש-{% equation %}uR_{L}v{% endequation %} ולכן {% equation %}\left[u\right]=\left[v\right]{% endequation %}, אבל משום מה <strong>לא</strong> יתקיים ש-{% equation %}u\sigma R_{L}v\sigma{% endequation %}. כלומר, נקבל {% equation %}\left[u\sigma\right]\ne\left[v\sigma\right]{% endequation %}. זה אומר שההגדרה {% equation %}\delta\left(\left[w\right],\sigma\right)=\left[w\sigma\right]{% endequation %} היא <strong>תלויה בנציג</strong> שאני בוחר למחלקת השקילות: אם אני אבחר לייצג את המחלקה עם {% equation %}u{% endequation %} אני אקבל פלט אחד, ואם אני אייצג אותה עם {% equation %}v{% endequation %} אני אקבל פלט אחר. זה בלתי נסבל בהגדרה של פונקציה: הרעיון הבסיסי בפונקציה הוא שלכל קלט קיים פלט יחיד. לא ייתכן שלאותו קלט יהיו כמה פלטים שתלויים באופן שבו אנחנו מסמנים את הקלט. הוכחה כזו מראה שהפונקציה כפי שהגדרתי אותה היא <strong>מוגדרת היטב</strong>.

אז מה עושים? מוכיחים שזה לא יכול לקרות. נניח ש-{% equation %}\left[u\right]=\left[v\right]{% endequation %} ונוכיח ש-{% equation %}\left[u\sigma\right]=\left[v\sigma\right]{% endequation %} פשוט על פי הגדרה. לצורך כך צריך להיזכר בהגדרה של {% equation %}R_{L}{% endequation %}: צריך להראות שלכל {% equation %}z{% endequation %} מתקיים {% equation %}u\sigma\cdot z\in L\iff v\sigma\cdot z\in L{% endequation %}. לצורך כך, נשתמש בנשק שלנו: ידוע ש-{% equation %}uR_{L}v{% endequation %} ולכן לכל {% equation %}z^{\prime}{% endequation %} מתקיים {% equation %}u\cdot z^{\prime}R_{L}v\cdot z^{\prime}{% endequation %}. אם כן, פשוט נבחר {% equation %}z^{\prime}=\sigma z{% endequation %} וסיימנו.

בעצם הראינו כאן תכונה מעניינת נוספת של היחס {% equation %}R_{L}{% endequation %} - תכונה שאקרא לה <strong>אינוריאנטיות מימין</strong>. הנה הגדרה כללית שלה: יחס {% equation %}R{% endequation %} הוא אינוריאנטי מימין אם לכל {% equation %}u,v{% endequation %} המקיימים {% equation %}uRv{% endequation %} ולכל {% equation %}\sigma\in\Sigma{% endequation %} מתיים ש-{% equation %}u\sigma Rv\sigma{% endequation %} - גם אם אנחנו מאריכים לצד ימין את המילים {% equation %}u,v{% endequation %} <strong>על ידי אותה אות</strong> אנחנו עדיין נשארים ביחס (ההפך לא נכון - ייתכנו שתי מילים לא שקולות שאחרי שמחברים להן עוד אות מימין הופכות לשקולות). התכונה הזו עוד תועיל לנו בהמשך.

בואו נוכיח שהבניה שלנו עובדת. ראשית כל, נוכיח באינדוקציה ש-{% equation %}\hat{\delta}\left(q_{0},w\right)=\left[w\right]{% endequation %}. זו הוכחה קלה כי הבניה מיועדת לכך שהיא תעבוד: עבור הבסיס {% equation %}w=\varepsilon{% endequation %} זה נובע מייד מההגדרה - {% equation %}\hat{\delta}\left(q_{0},\varepsilon\right)=q_{0}=\left[\varepsilon\right]{% endequation %}; עבור צעד האינדוקציה, ניקח מילה מהצורה {% equation %}w\sigma{% endequation %} כך שניתן להשתמש באינדוקציה על {% equation %}w{% endequation %}, וכעת {% equation %}\hat{\delta}\left(q_{0},w\sigma\right)=\delta\left(\hat{\delta}\left(q_{0},w\right),\sigma\right)=\delta\left(\left[w\right],\sigma\right)=\left[w\sigma\right]{% endequation %} - שוב, נובע ישירות מהבניה.

עכשיו כמעט סיימנו, אבל יש נקודה טריקית אחת שעוד יהיה צורך להתייחס אליה. אנחנו רוצים להראות ש-{% equation %}w\in L\iff\hat{\delta}\left(q_{0},w\right)\in F{% endequation %}. לפי מה שראינו כבר, זה שקול להוכחה ש-{% equation %}w\in L\iff\left[w\right]\in F{% endequation %}. כיוון אחד הוא ברור: אם {% equation %}w\in L{% endequation %} אז {% equation %}\left[w\right]\in F{% endequation %} על פי בניית האוטומט. אבל הכיוון השני קצת פחות ברור - אם {% equation %}\left[w\right]\in F{% endequation %} זה <strong>לא אומר</strong> מיידית ש-{% equation %}w\in L{% endequation %}: מה שזה אומר הוא שקיים {% equation %}u\in L{% endequation %} כך ש-{% equation %}\left[w\right]=\left[u\right]{% endequation %}. אבל כל מה שצריך לעשות הוא להיזכר שוב בהגדרה {% equation %}R_{L}{% endequation %}: אם {% equation %}wR_{L}u{% endequation %} אז לכל {% equation %}z{% endequation %} מתקיים {% equation %}wz\in L\iff uz\in L{% endequation %} ובפרט עבור {% equation %}z=\varepsilon{% endequation %}. מכיוון ש-{% equation %}u\in L{% endequation %} נקבל ש-{% equation %}w\in L{% endequation %} וסיימנו.

סיכום ביניים: הראינו שאם {% equation %}\mbox{index}\left(R_{L}\right){% endequation %} סופי אז {% equation %}L{% endequation %} רגולרית. עכשיו אני רוצה להראות את הכיוון השני: שאם {% equation %}L{% endequation %} רגולרית אז {% equation %}\mbox{index}\left(R_{L}\right){% endequation %} סופי. ואני הולך לעשות את זה על ידי כך שאוכיח ש-{% equation %}\mbox{index}\left(R_{L}\right){% endequation %} הוא מספר המצבים באוטומט מינימלי עבור {% equation %}L{% endequation %} - מן הסתם זה גם מוכיח מייד שהמספר הזה סופי (כי {% equation %}L{% endequation %} רגולרית אז קיים לה אוטומט עם מספר מצבים סופי).

לצורך כך, בואו ניקח אוטומט {% equation %}A{% endequation %} כלשהו עבור {% equation %}L{% endequation %}. האבחנה המרכזית כאן הוא שגם {% equation %}A{% endequation %} מגדיר יחס שקילות משל עצמו - שתי מילים הן שקולות אם אחרי קריאתן האוטומט מגיע לאותו המצב. זה מעין היפוך רעיוני של {% equation %}R_{L}{% endequation %} - במקרה של {% equation %}R_{L}{% endequation %} הרעיון היה ש<strong>אם</strong> שתי מילים הן שקולות, אז <strong>אפשר</strong> להביא את שתיהן לאותו מצב; עכשיו אנחנו אומרים שאם כבר ראינו ששתי מילים מגיעות לאותו מצב, אז בואו נגדיר שהן שקולות.

פורמלית נגדיר {% equation %}uR_{A}v{% endequation %} אם ורק אם {% equation %}\hat{\delta}\left(q_{0},u\right)=\hat{\delta}\left(q_{0},v\right){% endequation %} באוטומט {% equation %}A{% endequation %}. קל מאוד להוכיח שזה יחס שקילות. עוד דבר שקל מאוד לראות הוא ש-{% equation %}\mbox{index}\left(R_{A}\right)\le\left|Q\right|{% endequation %}. מדוע? כי אפשר להגדיר התאמה חח"ע מקבוצת מחלקות השקילות של {% equation %}R_{A}{% endequation %} אל קבוצת המצבים של {% equation %}A{% endequation %}: לכל {% equation %}\left[w\right]{% endequation %} נתאים את המצב {% equation %}\hat{\delta}\left(q_{0},w\right){% endequation %}. קל לראות שההתאמה הזו מוגדרת היטב והיא חח"ע. ולמה ייתכן שאין שוויון, כלומר ש-{% equation %}\mbox{index}\left(R_{A}\right)&lt;\left|Q\right|{% endequation %}? כי ב-{% equation %}A{% endequation %} עשויים להיות מצבים "מיותרים" שאי אפשר להגיע אליהם על ידי קריאת אף מילה.

כל מה שנשאר לי להראות, אם כן, הוא ש-{% equation %}\mbox{index}\left(R_{L}\right)\le\mbox{index}\left(R_{A}\right){% endequation %} לכל {% equation %}A{% endequation %} המקיים {% equation %}L\left(A\right)=L{% endequation %}. אני אוכיח משהו קצת יותר חזק מכך - שכל מחלקת שקילות של {% equation %}R_{L}{% endequation %} היא <strong>איחוד</strong> של מחלקת שקילות אחת או יותר של {% equation %}R_{A}{% endequation %}. כלומר, אם {% equation %}R_{L}{% endequation %} מחלק לנו את {% equation %}\Sigma^{*}{% endequation %} לתת-קבוצות, הרי ש-{% equation %}R_{A}{% endequation %} לוקח את תת הקבוצות הללו ולכל היותר מחלק אותן עוד קצת (במקום לבצע חלוקה שונה לגמרי שמניבה חתיכות שאי אפשר לחבר כדי לקבל את החתיכות של {% equation %}R_{L}{% endequation %}). פורמלית, מה שאני רוצה להראות הוא שלכל {% equation %}u\in\Sigma^{*}{% endequation %} מתקיים ש-{% equation %}\left[u\right]_{R_{A}}\subseteq\left[u\right]_{R_{L}}{% endequation %} (ולכן {% equation %}\left[u\right]_{R_{L}}=\bigcup_{w\in\left[u\right]_{R_{L}}}\left[w\right]_{R_{A}}{% endequation %} - נסו להוכיח זאת!). על סיטואציה כזו אומרים ש-{% equation %}R_{A}{% endequation %} "מעדן" את {% equation %}R_{L}{% endequation %} - כי החלוקה ש-{% equation %}R_{A}{% endequation %} מגדיר היא כמו זו של {% equation %}R_{L}{% endequation %} רק יותר "עדינה".

אם כן, בואו ניקח {% equation %}v\in\left[u\right]_{R_{A}}{% endequation %} ונוכיח ש-{% equation %}v\in\left[u\right]_{R_{L}}{% endequation %}. כלומר, אנחנו יודעים ש-{% equation %}uR_{A}v{% endequation %} ורוצים להוכיח ש-{% equation %}uR_{L}v{% endequation %}. אם כן, ניקח {% equation %}z\in\Sigma^{*}{% endequation %} כלשהי ונוכיח ש-{% equation %}uz\in L\iff vz\in L{% endequation %}. אבל, אם אתם עדיין נושמים בכלל, זה ממש קל! מכיוון ש-{% equation %}uR_{A}v{% endequation %} אנחנו יודעים ש-{% equation %}\hat{\delta}\left(q_{0},u\right)=\hat{\delta}\left(q_{0},v\right){% endequation %} ועל כן {% equation %}\hat{\delta}\left(q_{0},uz\right)=\hat{\delta}\left(q_{0},vz\right){% endequation %} ומכאן התוצאה נובעת מאליה.

סיימנו, אבל אפשר להכליל את התוצאה הזו עוד קצת. בואו ננסה להבין באילו תכונות של {% equation %}A{% endequation %} ושל {% equation %}R_{A}{% endequation %} השתמשנו בהוכחה. ראשית, השתמשנו בכך שאם {% equation %}uR_{A}v{% endequation %} אז {% equation %}uzR_{A}vz{% endequation %} - זו מעין הכללה של מה שקראתי לו "אינוריאנטיות מימין" כי כאן אנחנו משרשרים מצד ימין מילה ולא אות בודדת, אבל די ברור ששתי ההגדרות הללו שקולות (כי אפשר לשרשר את כל {% equation %}z{% endequation %} "אות-אות". כלומר, השתמשנו בכך ש-{% equation %}R_{A}{% endequation %} הוא יחס <strong>אינוריאנטי מימין</strong>. בתכונה השניה של {% equation %}R_{A}{% endequation %} השתמשתי בצורה קצת יותר מובלעת - אמרתי שאם {% equation %}uR_{A}v{% endequation %} אז {% equation %}u\in L\iff v\in L{% endequation %} (איפה?) מכיוון שאפשר לחשוב על {% equation %}L{% endequation %} בתור מגדירה יחס שקילות משל עצמה (שכולל בדיוק שתי מחלקות - {% equation %}L{% endequation %} והמשלימה של {% equation %}L{% endequation %}) נוח לקרוא לתכונה הזו "{% equation %}R_{A}{% endequation %} מעדן את {% equation %}L{% endequation %}".

כעת אני רוצה להכליל את התוצאה שזה עתה הוכחתי: לא רק ש-{% equation %}R_{A}{% endequation %} מעדן את {% equation %}R_{L}{% endequation %}, אלא <strong>כל</strong> יחס שקילות אינוריאנטי מימין שמעדן את {% equation %}L{% endequation %}, מעדן את {% equation %}R_{L}{% endequation %}. למעשה, מן הסתם גם {% equation %}R_{L}{% endequation %} מקיים את אותן שתי תכונות - הוא אינוריאנטי מימין ומעדן את {% equation %}L{% endequation %}. לכן אפשר לומר "{% equation %}R_{L}{% endequation %} הוא יחס השקילות המקסימלי מבין היחסים שהם אינוריאנטיים מימין ומעדנים את {% equation %}L{% endequation %}", כאשר "מקסימלי" הוא ביחס לעידון.

ההוכחה של התוצאה הזו זהה להוכחה שכבר ראינו. אם {% equation %}R{% endequation %} הוא יחס שקילות אינוריאנטי מימין שמעדן את {% equation %}L{% endequation %} אז ניקח {% equation %}uRv{% endequation %} ונוכיח ש-{% equation %}uR_{L}v{% endequation %}: ניקח {% equation %}z{% endequation %}, אז {% equation %}uzRvz{% endequation %} בגלל האינוריאנטיות מימין, ולכן {% equation %}uz\in L\iff vz\in L{% endequation %}, בגלל ש-{% equation %}R{% endequation %} מעדן את {% equation %}L{% endequation %}. למרות שזו הוכחה מגוחכת של שורה אחת אני חושב שהיא מצויינת, כי היא מאפשרת לנו "להרגיש" מה בעצם כל כך מיוחד ביחס {% equation %}R_{L}{% endequation %} ולמה הוא הדבר שהכי טבעי לדבר עליו בהקשר הזה.

כל הדיון הזה היה מופשט למדי, אז בואו נדבר על התכל'ס. נתונה לי שפה {% equation %}L{% endequation %}. מה שמשפט מייהיל-נרוד מאפשר לי לעשות בצורה נוחה הוא להוכיח <strong>חסמים</strong> על מספר המצבים שדרוש לאוטומט סופי דטרמיניסטי כדי לקבל את {% equation %}L{% endequation %}. מצד אחד, אפשר לקבל חסם עליון בצורה הבאה: נותנים יחס שקילות כלשהו שהוא אינוריאנטי מימין ומעדן את {% equation %}L{% endequation %}, ואז מספר מחלקות השקילות שלו הוא חסם עליון שכזה (ובפרט אם הוא סופי זה מוכיח שהשפה רגולרית). מצד שני, אפשר לקבל חסם תחתון על המספר הזה אם מציגים מספר כלשהו של מחלקות שקילות <strong>שונות</strong> של היחס {% equation %}R_{L}{% endequation %} - ואז המספר הזה הוא חסם תחתון, ובפרט אם הצגנו אינסוף מחלקות שקילות אז {% equation %}L{% endequation %} אינה רגולרית.

בואו נתעכב על הכיוון הזה. אני אפילו לא חייב לתת במפורש מחלקות שקילות - מספיק שאתן קבוצה כלשהי של מילים כך שאף זוג מילים מביניהן אינן שקולות, וזה יתן לי את החסם התחתון שלי. זה כלי שימושי מאוד לקבלת הערכה מהירה של כמה מסובך אוטומט עבור שפה כלשהי חייב להיות.

בואו נראה איך את {% equation %}L=\left\{ a^{n}b^{n}\ |\ n\in\mathbb{N}\right\} {% endequation %} המשפט אוכל בלי מלח. פשוט נסתכל על קבוצת המילים {% equation %}\left\{ a^{n}\ |\ n\in\mathbb{N}\right\} {% endequation %}. זו קבוצה אינסופית. קל לראות שאין בה זוג מילים שקולות: ניקח {% equation %}a^{n},a^{k}{% endequation %} כך ש-{% equation %}n\ne k{% endequation %}, ואז קל להציג {% equation %}z{% endequation %} שמפריד ביניהן: {% equation %}z=b^{n}{% endequation %}, כי {% equation %}a^{n}b^{n}\in L{% endequation %} אבל {% equation %}a^{k}b^{n}\notin L{% endequation %}. זהו.

גם את {% equation %}L=\left\{ ww\ |\ w\in\left\{ a,b\right\} ^{*}\right\} {% endequation %} המשפט אוכל בקלות. נבחר את קבוצת המילים {% equation %}\left\{ a^{n}b\ |\ n\in\mathbb{N}\right\} {% endequation %} ועבור {% equation %}a^{n}b,a^{k}b{% endequation %} מילה מפרידה תהיה {% equation %}z=a^{n}b{% endequation %}, כי בבירור {% equation %}a^{k}ba^{n}b{% endequation %} היא לא מהצורה {% equation %}ww{% endequation %} (כי אם היא כן, אז {% equation %}w{% endequation %} מסתיימת ב-{% equation %}b{% endequation %} כי {% equation %}ww{% endequation %} מסתיימת ב-{% equation %}b{% endequation %}, אבל זה גורר ש-{% equation %}w=a^{n}b{% endequation %} וגם {% equation %}w=a^{k}b{% endequation %}).

נעבור עכשיו לדוגמת הראשוניים, {% equation %}L=\left\{ a^{p}\ |\ p\mbox{ is prime}\right\} {% endequation %}. מה יוכיח במקרה הזה שהשפה לא רגולרית? קבוצה אינסופית {% equation %}A{% endequation %} של מספרים טבעיים כך שלכל {% equation %}a,b\in A{% endequation %} שונים זה מזה, קיים {% equation %}d{% endequation %} טבעי כך שבדיוק אחד מבין {% equation %}a+d,b+d{% endequation %} הוא מספר ראשוני.

למצוא קבוצה כזו - זה קל. אפילו כל הטבעיים מקיימים את התכונה הזו. אבל להוכיח את זה - זה כבר פחות טריוויאלי. הנה הוכחה אפשרית אחת. ראשית, נניח בלי הגבלת הכלליות ש-{% equation %}a&lt;b{% endequation %}. כעת נמצא ראשוני {% equation %}p&gt;b{% endequation %} כך שכל {% equation %}b-1{% endequation %} המספרים שבאים אחרי {% equation %}p{% endequation %} הם בודאות לא ראשוניים. אם מצאנו כזה, סיימנו, כי אז נסמן {% equation %}d=p-a{% endequation %} ונקבל ש-{% equation %}a+d{% endequation %} ראשוני אבל {% equation %}b+d=p+\left(b-a\right)\le p+\left(b-1\right){% endequation %} לא ראשוני. למה קיים {% equation %}p{% endequation %} כזה? ובכן, בואו ונסתכל על הקבוצה {% equation %}\left\{ b!+2,b!+3,\dots,b!+b\right\} {% endequation %}. המספר הראשון בקבוצה מתחלק ב-2, השני ב-3 וכן הלאה, ויש בקבוצה בסך הכל {% equation %}b-1{% endequation %} איברים. ניקח את {% equation %}p{% endequation %} להיות הראשוני הגדול ביותר שקטן מ-{% equation %}b!+2{% endequation %} וסיימנו.

מה שנחמד פה הוא שאפשר להפוך את היוצרות: אנחנו כבר יודעים ששפת הראשוניים לא רגולריים כי הוכחנו את זה עם למת הניפוח. אם כן, משפט מייהיל-נרוד מראה ש<strong>קיימת</strong> קבוצה אינסופית של טבעיים שלכל זוג איברים מתוכם קיים {% equation %}d{% endequation %} כך שבדיוק אחד מבין {% equation %}a+d,b+d{% endequation %} הוא ראשוני. והמשפט מראה את זה בצורה שהיא לא קונסטרוקטיבית למדי. כמובן, כאן זה משפט שהוא פשוט בפני עצמו, אבל בכלל לא חשבתי עליו עד שלא נתקלתי בו כתוצאה של מייהיל-נרוד כאן. מתמטיקה זה כיף.
