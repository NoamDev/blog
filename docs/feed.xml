<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/blog/" rel="alternate" type="text/html" /><updated>2019-06-25T00:35:08+03:00</updated><id>http://localhost:4000/blog/feed.xml</id><title type="html">לא מדויק</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">משפט הערך הממוצע של לגראנז’</title><link href="http://localhost:4000/blog/2019/06/17/lagrange_mean_value_theorem" rel="alternate" type="text/html" title="משפט הערך הממוצע של לגראנז'" /><published>2019-06-17T17:59:37+03:00</published><updated>2019-06-17T17:59:37+03:00</updated><id>http://localhost:4000/blog/2019/06/17/lagrange_mean_value_theorem</id><content type="html" xml:base="http://localhost:4000/blog/2019/06/17/lagrange_mean_value_theorem">&lt;p&gt;ביקשו ממני לסגור את אחד החורים המציקים שיש בבלוג - לתאר את &lt;strong&gt;משפט הערך הממוצע &lt;/strong&gt;של לגראנז’, שהוא אחד מהתוצאות הבסיסיות והמעניינות ביותר שמלמדים על &lt;strong&gt;נגזרות&lt;/strong&gt;. כתבתי בשעתו &lt;a href=&quot;https://gadial.net/2010/11/21/derivative/&quot;&gt;פוסט שמתאר מהן נגזרות&lt;/a&gt; והוא הרקע שדרוש כדי להבין את משפט לגראנז’; אבל אל לגראנז’ עצמו לא הגעתי. אז נתחיל עם תזכורת קטנה על מה מדובר.&lt;/p&gt;

&lt;p&gt;אנחנו מדברים על &lt;strong&gt;פונקציות ממשיות&lt;/strong&gt;: פונקציות \(f:\mathbb{R}\to\mathbb{R}\). אם יש לנו מספיק מזל, הפונקציות הללו הן “נחמדות”, והקצב שבו הן משתנות ניתן גם הוא לתיאור על ידי פונקציה, שנקראת &lt;strong&gt;הנגזרת&lt;/strong&gt; של \(f\). פורמלית, אנחנו מגדירים את הנגזרת של \(f\) בנקודה \(a\) בתור הערך של הגבול \(\lim_{h\to0}\frac{f\left(a+h\right)-f\left(a\right)}{h}\), במקרה שבו הוא קיים. בואו נסתכל שניה על הביטוי הזה יותר בפירוט כדי להבין מה הוא אומר: אפשר לכתוב אותו גם בתור&lt;/p&gt;

&lt;p&gt;\(\lim_{h\to0}\frac{f\left(a+h\right)-f\left(a\right)}{\left(a+h\right)-a}\)&lt;/p&gt;

&lt;p&gt;כלומר, אפשר לחשוב עליו בתור הערך \(\frac{f\left(b\right)-f\left(a\right)}{b-a}\) עבור נקודות \(b\) שהן “הולכות וקרבות” ל-\(a\). אבל מה זה הערך הזה? זה פשוט &lt;strong&gt;השינוי הממוצע&lt;/strong&gt; בין הערך של \(f\) בנקודה \(a\) והערך שלה בנקודה \(b\). קל לראות את זה עם דוגמא יומיומית: נניח שאנחנו נוסעים מתל אביב לאילת ומודדים כמה התרחקנו מתל אביב עד כה בעזרת הפונקציה \(f\). אם בזמן \(t_{1}=1\) (בשעות) היינו במרחק 50 ק”מ מתל אביב ובזמן \(t_{2}=4\) היינו במרחק 290 ק”מ מתל אביב, אז &lt;strong&gt;המהירות הממוצעת&lt;/strong&gt; שלנו בנסיעה הזו בין שני פרקי הזמן הללו נתונה, בקילומטר לשעה, על ידי&lt;/p&gt;

&lt;p&gt;\(\frac{f\left(t_{2}\right)-f\left(t_{1}\right)}{t_{2}-t_{1}}=\frac{290-50}{4-1}=\frac{240}{3}=80\)&lt;/p&gt;

&lt;p&gt;מה המשמעות של מהירות ממוצעת שכזו? האם זה אומר שזו המהירות שבה נסענו במשך רוב הדרך? לא. ייתכן שנסענו במהירות 100 קמ”ש בשעתיים הראשונות שאחרי \(t_{1}=1\), ואז את 40 הקילומטרים הנוספים עשינו בזחילה במהירות 40 קמ”ש בשעה האחרונה. המשמעות של המהירות הממוצעת היא זו - אם היינו נוסעים כל הדרך באותה מהירות בדיוק, בלי לשנות אותה כלל, אז היינו עוברים את אותה הדרך.&lt;/p&gt;

&lt;p&gt;על נגזרת אפשר לחשוב בתור “ערך ממוצע רגעי”. כלומר, אנחנו מחשבים את המהירות הממוצעת שלנו לא על פני פרק זמן של שלוש שעות אלא על פני פרק זמן של דקה… לא בעצם, פרק זמן של שנייה… לא, בעצם מילישנייה… וכן הלאה. אם יש איזו מהירות מסויימת שהמהירות הממוצעת מספיק קרובה אליה, בהינתן שפרק הזמן שלנו קצר דיו (זה היה ניסוח מילולי מסורבל של מושג ה&lt;strong&gt;גבול&lt;/strong&gt;, \(\lim\)), אז המהירות המסויימת הזו היא &lt;strong&gt;הנגזרת&lt;/strong&gt; של פונקציית המיקום שלנו באותה נקודת זמן שאנחנו לוקחים ממנה פער כל כך קצרצר. בהקשר של מהירות קוראים לזה &lt;strong&gt;מהירות רגעית&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;כפי שאפשר להבין, מהירות רגעית שכזו היא עניין, אה, רגעי. מקומי. נקודתי. משהו שמתאר שבריר שניה אחד בהיסטוריה של הנסיעה. מה שמשפט הערך הממוצע של לגראנז’ עושה הוא להעביר אותנו מהמקומי הזה אל &lt;strong&gt;הגלובלי&lt;/strong&gt; - להראות שקיימת נקודה רגעית בזמן שמה שקורה בה הוא האפיון הממוצע של מה שקורה בכל פרק הזמן הרלוונטי. זה מתאים לחוויה היומיומית שלנו: אם בהתחלה נסענו במהירות ממוצעת של 100 קמ”ש ואז ירדנו למהירות ממוצעת של 40 קמ”ש, אז היה שבריר שניה כלשהו שבו מד המהירות שלנו הראה את המהירות 80 קמ”ש, שהיא המהירות הממוצעת עבור כל הנסיעה.&lt;/p&gt;

&lt;p&gt;אז הנה מה שלגראנז’ אומר, פורמלית: אם \(a&amp;lt;b\) ויש לנו פונקציה \(f:\left[a,b\right]\to\mathbb{R}\) פונקציה שרציפה בקטע הסגור \(\left[a,b\right]\) וגזירה בקטע הפתוח \(\left(a,b\right)\), אז קיימת נקודה \(c\in\left(a,b\right)\) כך ש-\(f^{\prime}\left(c\right)=\frac{f\left(b\right)-f\left(a\right)}{b-a}\). בפוסט הזה נוכיח את המשפט (בהסתמך על דברים קודמים, כמובן) וניתן דוגמא או שתיים לשימושיות שלו.&lt;/p&gt;

&lt;p&gt;ראשית, אי אפשר בלי להזכיר את האופן הגאומטרי שבו אנחנו רואים את המשפט. כשאנחנו מציירים פונקציה, אנחנו מציירים נקודות שהקואורדינטות שלהן הן מהצורה \(\left(x,f\left(x\right)\right)\) (כלומר, \(f\left(x\right)\) היא קואורדינטת ה-\(y\) של הציור). נקודות הקצה של הפונקציה הן \(\left(a,f\left(a\right)\right)\) ו-\(\left(b,f\left(b\right)\right)\). אם ניזכר איך הולכים דברים בגאומטריה אנליטית נראה שהביטוי \(\frac{f\left(b\right)-f\left(a\right)}{b-a}\) הוא &lt;strong&gt;שיפוע הישר&lt;/strong&gt; שמחבר את שתי הנקודות הללו. עכשיו, מה זו נגזרת? המשמעות של נגזרת בנקודה כלשהי היא &lt;strong&gt;שיפוע המשיק&lt;/strong&gt; לפונקציה בנקודה הזו. לכן לגראנז’ אומר שיש נקודה כלשהי על גרף הפונקציה ששיפוע המשיק לאותה נקודה זהה לשיפוע הישר שמחבר את שני קצוות הפונקציה. הנה איור באדיבות ויקיפדיה העברית:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3781&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/06/Mv4_he.svg_.png&quot; alt=&quot;&quot; width=&quot;1024&quot; height=&quot;931&quot; /&gt;&lt;/p&gt;

&lt;p&gt;איך מוכיחים את המשפט? כאן צריך להיזהר עם האינטואיציה שלנו, שעשויה להטעות אותנו. נחזור אל דוגמת הרכב שנסע במהירות של 100 קמ”ש ואז ירד למהירות של 40 קמ”ש. האינטואיציה שלנו אומרת שבירידה מ-100 קמ”ש אל 40 קמ”ש הייתה חייבת להיות שניה שבה המהירות הייתה 80 קמ”ש, כי אנחנו חושבים על מהירות בתור משהו ש&lt;strong&gt;משתנה באופן רציף&lt;/strong&gt;. יש לדבר הזה פורמליזם בחדו”א: פונקציה \(f\) היא &lt;strong&gt;רציפה&lt;/strong&gt; בנקודה \(a\) אם \(\lim_{x\to a}f\left(x\right)=f\left(a\right)\) (כלומר, הערך שנראה ש-\(f\) “אמורה לקבל” ב-\(a\) הוא מה שמתקבל בפועל). אם יש לנו פונקציה רציפה, אז יש לנו עבורה משהו שנקרא &lt;strong&gt;משפט ערך הביניים&lt;/strong&gt; שאומר שאם \(y\) הוא ערך כלשהו שנמצא בין \(f\left(a\right)\) ו-\(f\left(b\right)\), אז קיים \(x\in\left[a,b\right]\) כך ש-\(f\left(x\right)=y\). בפרט, מהירות של 80 קמ”ש נמצאת בין 100 קמ”ש ו-40 קמ”ש ולכן היא חייבת להתקבל מתישהו.&lt;/p&gt;

&lt;p&gt;אז מה הבעיה? הבעיה היא שנגזרת, באופן כללי, לא חייבת להיות פונקציה רציפה. אמנם, הדוגמאות הנגדיות (של פונקציות גזירות שהנגזרת שלהן אינה רציפה) הן לא יפות במיוחד ואפשר גם להוכיח שאי רציפות של “קפיצה” ישירות מ-100 קמ”ש אל 40 קמ”ש פשוט לא יכולה להתקיים, אבל השורה התחתונה היא שאנחנו רוצים להוכיח את המשפט בלי הסתמכות על משפט ערך הביניים.&lt;/p&gt;

&lt;p&gt;עוד נקודה שצריך לתת אליה תשומת לב היא שהתנאים של המשפט די קשיחים. ראשית, הדרישה ש-\(f\) תהיה גזירה בכל הקטע הפתוח \(\left(a,b\right)\). אחרת אפשר לקחת את דוגמת הנסיעה שלנו לאקסטרים: נדמיין שאנחנו נוסעים 100 קמ”ש ואז &lt;strong&gt;קופצים מיידית&lt;/strong&gt; אל 40 קמ”ש, בלי לעבור בערכים באמצע; אז באמת לא היינו בשום מקום במהירות 80 קמ”ש כפי שמשפט לגראנז’ טוען. העניין הוא שהנקודה שבה ביצענו את הקפיצה הזו לא תהיה גזירה; הנגזרת ממש לפניה היא 100 והנגזרת ממש אחריה היא 40, ובנקודה עצמה? הנגזרת לא מוגדרת.&lt;/p&gt;

&lt;p&gt;שנית, הדרישה הנוספת ש-\(f\) תהיה רציפה בכל \(\left[a,b\right]\) היא כמעט מובנת מאליה. היא חייבת להיות רציפה ב-\(\left(a,b\right)\) כי קל לראות שגזירות בקטע הזה גוררת רציפות בו. היא חייבת להיות רציפה בקצוות, אחרת אפשר יהיה לשנות את הערכים שלה שם באופן שרירותי לגמרי, למשל להגדיר \(f\left(a\right)=f\left(b\right)=232352\), ואז אין סיבה שמשפט ערך הביניים יעבוד כי הוא מתבסס בצורה חזקה על הערכים בקצוות ועל כך שהם מייצגים תקינים של מה שקורה בתוך הקטע.&lt;/p&gt;

&lt;p&gt;עכשיו אפשר לעבור להוכחה של המשפט. נתחיל עם מקרה פרטי שלו שנקרא &lt;strong&gt;משפט רול&lt;/strong&gt; שבעזרתו קל להוכיח את התוצאה הכללית. משפט רול אומר שאם \(f\left(a\right)=f\left(b\right)\) אז קיימת \(c\in\left[a,b\right]\) כך ש-\(f^{\prime}\left(c\right)=0\). אינטואיטיבית, אם נקודות ההתחלה והסיום של הטיול שלנו הן זהות, אז היה רגע שבו עמדנו במקום ולא זזנו.&lt;/p&gt;

&lt;p&gt;זה לא משפט טריוויאלי, אבל עם ידע רלוונטי בחדו”א אפשר לתת לו הוכחה של שורה אחת, שהאינטואיציה שלה די ברורה: אם נקודות ההתחלה והסיום שלנו זהות, אז או שלא זזנו בכלל כל הזמן, או שזזנו קדימה ואז אחורה ולכן הייתה שניה שבה עברנו מלזוז קדימה אל לזוז אחורה ובה לא זזנו; או שזזנו אחורה ואז קדימה ולכן הייתה שניה שבה לא זזנו. העניין הוא שהאינטואיציה הזו שוב מניחה רציפות של הנגזרת ובפעול משפט רול מצליח לעקוף את זה (ולכן אינו טריוויאלי) בעזרת משפטים קודמים, שרק בזכותם ההוכחה היא בת שורה אחת.&lt;/p&gt;

&lt;p&gt;בואו ניתן את השורה הזו למקרה שיש לכם את הידע הזה ואז נרחיב: מכיוון ש-\(f\) רציפה ב-\(\left[a,b\right]\) היא מקבלת בקטע הזה מקסימום ומינימום. אם הם בתוך הקטע, אז בכל אחד מהם ערך הנגזרת הוא 0 על פי משפט פרמה לנקודות קיצון; אם שניהם בקצוות הקטע אז הם שווים זה לזה ולכן הפונקציה קבועה ולכן הנגזרת שלה היא 0 בכל הקטע.&lt;/p&gt;

&lt;p&gt;הבעיה עם להסביר את כל המלל שכתבתי למעלה היא שלא ברור כמה רחוק אני אמור ללכת. את הטענה על משפט פרמה לנקודות קיצון &lt;a href=&quot;https://gadial.net/2011/01/16/derivative_and_extremal_problems_1-2/&quot;&gt;הוכחתי בפוסט קודם&lt;/a&gt;, אז אני פטור מלדבר עליה, אבל מה עם הטענה שפונקציה רציפה בקטע סגור מקבלת בו ערכי מקסימום ומינימום? הטענה הזו נקראת בחדו”א “משפט ויירשטראס” (השני; הראשון אומר שפונקציה רציפה בקטע סגור חסומה בו). אני יכול להוכיח אותה, אבל ההוכחה מתבססת על משהו יותר בסיסי שנקרא &lt;strong&gt;משפט בולצאנו-ויירשטראס&lt;/strong&gt;, שבתורו נובע מהתכונות הבסיסיות של הממשיים… בקיצור, אני לא הולך ללכת בכיוון הזה ואולי אדבר על משפטי ויירשטראס בפירוט בפוסט אחר מתישהו.&lt;/p&gt;

&lt;p&gt;דבר אחד כן קל מאוד להסביר: אם \(f\) היא פונקציה קבועה בקטע, אז הנגזרת שלה בכל נקודה בקטע היא \(0\) פשוט כי בביטוי \(\lim_{h\to0}\frac{f\left(a+h\right)-f\left(a\right)}{h}\) מתקיים \(f\left(a+h\right)=f\left(a\right)\) ולכן המונה הוא אפס.&lt;/p&gt;

&lt;p&gt;עכשיו, איך עוברים מהמשפט הזה אל משפט לגראנז’? די בקלות: אם יש לנו פונקציה \(f\left(x\right)\), אפשר לדבר על הפונקציה \(g\left(x\right)\) שמודדת את &lt;strong&gt;המרחק&lt;/strong&gt; של \(f\left(x\right)\) מהמיתר שמחבר את הנקודות \(\left(a,f\left(a\right)\right)\) ו-\(\left(b,f\left(b\right)\right)\). כלומר, היא מודדת כמה \(f\left(x\right)\) &lt;strong&gt;אינה&lt;/strong&gt; מתאימה לממוצע בנקודה מסויימת. בנקודות הקצה המרחק הזה יהיה 0, כך שאנחנו רואים את משפט רול בפעולה.&lt;/p&gt;

&lt;p&gt;כדי לכתוב את \(g\left(x\right)\) במפורש צריך להיזכר קודם כל בקצת גאומטריה אנליטית - איך כותבים את משוואות הקו הישר שמחבר שתי נקודות \(\left(x_{1},y_{1}\right),\left(x_{2},y_{2}\right)\)? התשובה היא שזו תהיה משוואה מהצורה \(y=mx+n\) כאשר \(m\) נקרא &lt;strong&gt;השיפוע&lt;/strong&gt; של הישר ואילו \(n\) היא נקודת החיתוך של הישר עם ציר \(y\) (כמה “גבוה” הישר יהיה כשנציב \(x=0\)). אם נציב את שתי הנקודות שידועות לנו במשוואה הזו נקבל שתי משוואות:&lt;/p&gt;

&lt;p&gt;\(y_{1}=mx_{1}+n\)&lt;/p&gt;

&lt;p&gt;\(y_{2}=mx_{2}+n\)&lt;/p&gt;

&lt;p&gt;אם נחסר אחת מהשניה ונחלק, נקבל&lt;/p&gt;

&lt;p&gt;\(m=\frac{y_{2}-y_{1}}{x_{2}-x_{1}}\)&lt;/p&gt;

&lt;p&gt;כאן אנחנו מניחים ש-\(x_{2}\ne x_{1}\) כדי שנוכל לחלק, וזה מתאים להנחה שלנו ש-\(a&amp;lt;b\) במשפט לגראנז’ (אם לא היינו מניחים את זה אז משפט לגרנז’ היה חסר משמעות; הוא היה אומר שקיים \(x\in\left(a,b\right)\) שמקיים כך-וכך, אבל \(\left(a,b\right)\) היה קטע ריק).&lt;/p&gt;

&lt;p&gt;את הערך של \(n\) קל למצוא עכשיו על ידי כך שניקח את המשוואה הראשונה ונעביר אגף: \(y_{1}-mx_{1}=n\). אם נציב את זה בחזרה במשוואה הכללית \(y=mx+n\) נקבל&lt;/p&gt;

&lt;p&gt;\(y=mx+\left(y_{1}-mx_{1}\right)\)&lt;/p&gt;

&lt;p&gt;כלומר&lt;/p&gt;

&lt;p&gt;\(y=m\left(x-x_{1}\right)+y_{1}\)&lt;/p&gt;

&lt;p&gt;במקרה שלנו, שבו \(\left(x_{1},y_{1}\right)=\left(a,f\left(a\right)\right)\) ו-\(\left(x_{2},y_{2}\right)=\left(b,f\left(b\right)\right)\), משוואת המיתר תהיה&lt;/p&gt;

&lt;p&gt;\(y=\frac{f\left(b\right)-f\left(a\right)}{b-a}\left(x-a\right)+f\left(a\right)\)&lt;/p&gt;

&lt;p&gt;ולכן אם אנחנו רוצים ש-\(g\left(x\right)\) תתאר את &lt;strong&gt;ההפרש&lt;/strong&gt; בין הערך של המיתר והפונקציה, כלומר \(f\left(x\right)-y\), נקבל:&lt;/p&gt;

&lt;p&gt;\(g\left(x\right)=f\left(x\right)-\frac{f\left(b\right)-f\left(a\right)}{b-a}\left(x-a\right)-f\left(a\right)\)&lt;/p&gt;

&lt;p&gt;אם נציב \(x=a\) במשוואה הזו נקבל&lt;/p&gt;

&lt;p&gt;\(g\left(a\right)=f\left(a\right)-f\left(a\right)=0\)&lt;/p&gt;

&lt;p&gt;ואם נציב בה \(b\) נקבל&lt;/p&gt;

&lt;p&gt;\(g\left(b\right)=f\left(b\right)-\left(f\left(b\right)-f\left(a\right)\right)-f\left(a\right)=0\)&lt;/p&gt;

&lt;p&gt;בנוסף לכך, \(g\) רציפה ב-\(\left[a,b\right]\) וגזירה ב-\(\left(a,b\right)\) בשל האופן הפשוט שבו היא מתקבלת מ-\(f\left(x\right)\) שגם כן מקיימת את התכונות הנחמדות הללו; זאת מכיוון שחיבור של פונקציות גזירות או כפל שלהן בקבוע מותיר אותן גזירות, וכמו כן פולינומים הם פונקציות גזירות.&lt;/p&gt;

&lt;p&gt;לכן ניתן להשתמש במשפט רול על \(g\) ולקבל שיש \(c\in\left(a,b\right)\) כך ש-\(g^{\prime}\left(c\right)=0\). כעת, מהי הנגזרת של \(g\)? קל לחשוב אותה במפורש:&lt;/p&gt;

&lt;p&gt;\(g^{\prime}\left(x\right)=f^{\prime}\left(x\right)-\frac{f\left(b\right)-f\left(a\right)}{b-a}\)&lt;/p&gt;

&lt;p&gt;ולכן אם \(g^{\prime}\left(c\right)=0\) נקבל ש-&lt;/p&gt;

&lt;p&gt;\(f^{\prime}\left(c\right)-\frac{f\left(b\right)-f\left(a\right)}{b-a}=0\)&lt;/p&gt;

&lt;p&gt;כלומר \(f^{\prime}\left(c\right)=\frac{f\left(b\right)-f\left(a\right)}{b-a}\) שזה בדיוק מה שרצינו. האינטואיציה פה שוב פשוטה ונובעת ממה שנקרא &lt;strong&gt;לינאריות הנגזרת&lt;/strong&gt;, \(\left(f+g\right)^{\prime}=f^{\prime}+g^{\prime}\): מכיוון ש-\(g\) היא ההפרש בין \(f\) ובין המיתר, אז הנגזרת של \(g\) היא ההפרש בין הנגזרת של \(f\) ובין נגזרת המיתר, שהיא פשוט השיפוע הקבוע של המיתר. לכן יש נקודה שבה ההפרש הזה מתאפס, והנגזרת של \(f\) שווה בדיוק לשיפוע המיתר.&lt;/p&gt;

&lt;p&gt;סיימנו להוכיח את המשפט, אבל מן הסתם פוסט בנושא לא יהיה שלם בלי לראות כמה מהשימושים הפשוטים שלו. כאמור, הרעיון במשפט הזה הוא היכולת לעבור מה”מקומי” (הנגזרת) אל ה”גלובלי” (ההתנהגות של הפונקציה בכל הקטע), ובמקרי קצה פשוטים יש כמה הסקות מיידיות שניתן לבצע:&lt;/p&gt;
&lt;ol&gt;
 	&lt;li&gt;אם הנגזרת של {::nomarkdown}\(f\){:/nomarkdown} היא 0 בקטע כלשהו אז {::nomarkdown}\(f\){:/nomarkdown} קבועה בכל הקטע הזה (קודם ראינו את ההפך - שהנגזרת של פונקציה קבועה היא 0; עכשיו אנחנו רואים שזה קורה רק לפונקציות קבועות)&lt;/li&gt;
 	&lt;li&gt;אם הנגזרת של {::nomarkdown}\(f\){:/nomarkdown} היא &lt;strong&gt;חיובית&lt;/strong&gt; בקטע כלשהו אז {::nomarkdown}\(f\){:/nomarkdown} היא &lt;strong&gt;עולה ממש&lt;/strong&gt; בכל הקטע הזה.&lt;/li&gt;
 	&lt;li&gt;אם הנגזרת של {::nomarkdown}\(f\){:/nomarkdown} היא &lt;strong&gt;שלילית &lt;/strong&gt;בקטע כלשהו אז {::nomarkdown}\(f\){:/nomarkdown} היא &lt;strong&gt;יורדת ממש&lt;/strong&gt; בכל הקטע הזה.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;שלושת אלו הם מה שנדרש לנו לצורך “חקירת פונקציות” כמו שלומדים בתיכון - זיהוי תחומי עליה וירידה של פונקציה. כדי לראות שזה נכון, אנחנו לוקחים שתי נקודות כלשהן בתוך הקטע, נקרא להן \(a,b\), כך ש-\(a&amp;lt;b\). עכשיו:&lt;/p&gt;
&lt;ol&gt;
 	&lt;li&gt;אם {::nomarkdown}\(f\){:/nomarkdown} קבועה בכל הקטע אנחנו מצפים שיתקיים {::nomarkdown}\(f\left(a\right)=f\left(b\right)\){:/nomarkdown}&lt;/li&gt;
 	&lt;li&gt;אם {::nomarkdown}\(f\){:/nomarkdown} עולה ממש בכל הקטע אנחנו מצפים שיתקיים {::nomarkdown}\(f\left(a\right)&amp;lt;f\left(b\right)\){:/nomarkdown}&lt;/li&gt;
 	&lt;li&gt;אם {::nomarkdown}\(f\){:/nomarkdown} יורדת ממש בכל הקטע אנחנו מצפים שיתקיים {::nomarkdown}\(f\left(a\right)&amp;gt;f\left(b\right)\){:/nomarkdown}&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;שלושת אלו אכן מתקיימים, בזכות משפט הערך הממוצע. כזכור, הוא אומר שקיימת \(c\in\left(a,b\right)\) כך ש-\(f^{\prime}\left(c\right)=\frac{f\left(b\right)-f\left(a\right)}{b-a}\). אולי קצת יותר קל להרגיש מה קורה אם כופלים ב-\(b-a\) ומקבלים&lt;/p&gt;

&lt;p&gt;\(f\left(b\right)-f\left(a\right)=f^{\prime}\left(c\right)\left(b-a\right)\)&lt;/p&gt;

&lt;p&gt;כלומר, אנחנו יכולים לתאר את ההפרש בין \(f\) בשתי נקודות הקצה של הקטע בעזרת אורך הקטע כפול קבוע מספרי כלשהו שקשור לנגזרת של \(f\). נחזור אל שלושת המקרים שלנו:&lt;/p&gt;
&lt;ol&gt;
 	&lt;li&gt;אם הנגזרת של {::nomarkdown}\(f\){:/nomarkdown} היא 0 בכל הקטע אז {::nomarkdown}\(f^{\prime}\left(c\right)=0\){:/nomarkdown} ולכן {::nomarkdown}\(f\left(b\right)-f\left(a\right)=0\){:/nomarkdown}, כלומר {::nomarkdown}\(f\left(b\right)=f\left(a\right)\){:/nomarkdown}&lt;/li&gt;
 	&lt;li&gt;אם הנגזרת של {::nomarkdown}\(f\){:/nomarkdown} היא חיובית בכל הקטע אז {::nomarkdown}\(f^{\prime}\left(c\right)\left(b-a\right)&amp;gt;0\){:/nomarkdown} ולכן {::nomarkdown}\(f\left(b\right)-f\left(a\right)&amp;gt;0\){:/nomarkdown}, כלומר {::nomarkdown}\(f\left(a\right)&amp;lt;f\left(b\right)\){:/nomarkdown}&lt;/li&gt;
 	&lt;li&gt;אם הנגזרת של {::nomarkdown}\(f\){:/nomarkdown} היא שלילית בכל הקטע אז {::nomarkdown}\(f^{\prime}\left(c\right)\left(b-a\right)&amp;lt;0\){:/nomarkdown} ולכן {::nomarkdown}\(f\left(b\right)-f\left(a\right)&amp;lt;0\){:/nomarkdown}, כלומר {::nomarkdown}\(f\left(a\right)&amp;gt;f\left(b\right)\){:/nomarkdown}&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;העובדה שאם הנגזרת של \(f\) היא אפס בקטע אז \(f\) היא קבועה היא הבסיס לעוד טענה מעניינת: אם הנגזרת של שתי פונקציות היא זהה, אז הן &lt;strong&gt;נבדלות בקבוע&lt;/strong&gt; ותו לא. בואו נראה את זה: נניח ש-\(f^{\prime}\left(x\right)=g^{\prime}\left(x\right)\) לכל \(x\) בקטע מסויים, אז \(\left(f-g\right)^{\prime}\left(x\right)=0\) לכל הנקודות בקטע הזה, ומכאן ש-\(f-g\) היא פונקציה קבועה: \(\left(f-g\right)\left(x\right)=c\) עבור \(c\in\mathbb{R}\) כלשהו בקטע, כלומר \(f\left(x\right)=g\left(x\right)+c\). זו אולי התוצאה הבסיסית ביותר שמכירים כשמדברים על &lt;strong&gt;אינטגרלים&lt;/strong&gt;: שאם מצאנו פונקציה קדומה של משהו, אז הפונקציות הקדומות הנוספות מתקבלות ממנה על ידי חיבור קבוע כלשהו.&lt;/p&gt;

&lt;p&gt;לסיום הפוסט אני רוצה להוכיח משפט מועיל מאין כמותו - &lt;strong&gt;כלל לופיטל&lt;/strong&gt;. יש פה קוריוז היסטורי קטן: לופיטל לא גילה או הוכיח את המשפט אלא יוהאן ברנולי עשה את זה (ולופיטל, תלמידו, פרסם אותו בספר שכתב וקיבל את הקרדיט; סוג של קניה בכסף של משפט שייקרא על שמך), ואני הולך להוכיח אותו עם משהו שנקרא “משפט הערך הממוצע של קושי” שחי הרבה אחרי לופיטל וברנולי (אין לי מושג איך ברנולי הוכיח את המשפט).&lt;/p&gt;

&lt;p&gt;כלל לופיטל הוא שיטה מועילה לחישוב &lt;strong&gt;גבולות&lt;/strong&gt; שהם מנה שבה המונה והמכנה שואפים שניהם לאפס (ועם קצת עבודה אפשר להשתמש בו עבור עוד סוגי גבולות בעייתיים אבל לא אכנס לכך בפוסט הזה). פורמלית, אם \(f,g\) הן פונקציות ממשיות ו-\(a\) מספר ממשי כלשהו כך ש-\(\lim_{x\to a}f\left(x\right)=\lim_{x\to a}g\left(x\right)=0\), ואם בנוסף לכך הגבול הבא קיים:&lt;/p&gt;

&lt;p&gt;\(\lim_{x\to a}\frac{f^{\prime}\left(x\right)}{g^{\prime}\left(x\right)}\)&lt;/p&gt;

&lt;p&gt;אז גם הגבול הבא קיים:&lt;/p&gt;

&lt;p&gt;\(\lim_{x\to a}\frac{f\left(x\right)}{g\left(x\right)}\)&lt;/p&gt;

&lt;p&gt;והם שווים, כלומר \(\lim_{x\to a}\frac{f\left(x\right)}{g\left(x\right)}=\lim_{x\to a}\frac{f^{\prime}\left(x\right)}{g^{\prime}\left(x\right)}\)&lt;/p&gt;

&lt;p&gt;המשמעות של הכלל היא שאם יש לנו גבול קשה לחישוב, למשל \(\lim_{x\to0}\frac{\sin x}{x}\), אז אפשר לנסות לפשט אותו על ידי גזירת המונה והמכנה; אם נצליח למצוא את הגבול המתאים עבור הנגזרות, ינבע מכך הגבול המקורי. בדוגמה שלנו גזירת המונה והמכנה מניבה את&lt;/p&gt;

&lt;p&gt;\(\lim_{x\to0}\frac{\cos x}{1}=1\)&lt;/p&gt;

&lt;p&gt;(יש בדוגמא שלי מעגליות מכוונת: כדי לדעת מהי הנגזרת של \(\sin\) כבר צריך להכיר את הערך של הגבול הזה; יש לי על כך &lt;a href=&quot;https://gadial.net/2008/01/20/lim_sin_x_over_x/&quot;&gt;פוסט כאן&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;איך מוכיחים את הכלל? בשביל זה אני צריך, כאמור, הכללה של משפט הערך הממוצע של לגראנז’ שנקראת משפט הערך הממוצע של קושי. אם בלגראנז’ הרעיון הוא שקיים \(c\) עבורו מתקיים&lt;/p&gt;

&lt;p&gt;\(f^{\prime}\left(c\right)=\frac{f\left(b\right)-f\left(a\right)}{b-a}\)&lt;/p&gt;

&lt;p&gt;אז במשפט קושי הרעיון הוא שקיים \(c\) עבורו מתקיים&lt;/p&gt;

&lt;p&gt;\(\frac{f^{\prime}\left(c\right)}{g^{\prime}\left(c\right)}=\frac{f\left(b\right)-f\left(a\right)}{g\left(b\right)-g\left(a\right)}\)&lt;/p&gt;

&lt;p&gt;עבור פונקציה \(g\) שמקיימת את אותם תנאים כמו של \(f\) (רציפה ב-\(\left[a,b\right]\) וגזירה ב-\(\left(a,b\right)\)) ובנוסף לכך החלוקה בה ובנגזרתה לא עושה צרות - כלומר, \(g\left(a\right)\ne g\left(b\right)\) ו-\(g^{\prime}\left(x\right)\ne0\) לכל \(x\in\left(a,b\right)\). לגראנז’ הוא מקרה פרטי של זה עבור פונקציית הזהות \(g\left(x\right)=x\).&lt;/p&gt;

&lt;p&gt;למען האמת, הניסוח לעיל של משפט קושי הוא קצת מעצבן; במקום שיהיה לנו משפט סימטרי ונחמד יש לנו את כל הדרישות הנוספות המעיקות על \(g\). אפשר להיפטר מהקושי הזה אם נפטרים מהחלוקה. כלומר, ניסוח “טוב יותר” של משפט קושי הוא שאם \(f,g\) רציפות על \(\left[a,b\right]\) וגזירות על \(\left(a,b\right)\) אז קיים \(c\in\left(a,b\right)\) כך ש-&lt;/p&gt;

&lt;p&gt;\(f^{\prime}\left(c\right)\left(g\left(b\right)-g\left(a\right)\right)=g^{\prime}\left(c\right)\left(f\left(b\right)-f\left(a\right)\right)\)&lt;/p&gt;

&lt;p&gt;איך מוכיחים את המשפט? על פניו אפשר לומר משהו כזה: נשתמש פעמיים במשפט לגראנז’ ונקבל ש-&lt;/p&gt;

&lt;p&gt;\(f^{\prime}\left(c\right)=\frac{f\left(b\right)-f\left(a\right)}{b-a}\)&lt;/p&gt;

&lt;p&gt;\(g^{\prime}\left(c\right)=\frac{g\left(b\right)-g\left(a\right)}{b-a}\)&lt;/p&gt;

&lt;p&gt;ועכשיו פשוט נכפול את אגף ימין של המשוואה האחת באגף שמאל של השניה, ואת אגף שמאל של השניה באגף ימין של הראשונה, ונצמצמם \(\frac{1}{b-a}\) משני האגפים. זה נשמע מאוד פשוט ואלגנטי ונחמד וזה גם &lt;strong&gt;שגוי מאוד&lt;/strong&gt; בצורה שכדאי לתת עליה את הדעת כי זו טעות מאוד נפוצה במתמטיקה. רואים אותה? קחו רגע לחשוב על זה.&lt;/p&gt;

&lt;p&gt;השגיאה היא בכך שכתבתי&lt;/p&gt;

&lt;p&gt;\(f^{\prime}\left(c\right)=\frac{f\left(b\right)-f\left(a\right)}{b-a}\)&lt;/p&gt;

&lt;p&gt;\(g^{\prime}\left(c\right)=\frac{g\left(b\right)-g\left(a\right)}{b-a}\)&lt;/p&gt;

&lt;p&gt;כך שבשתי המשוואות הללו מופיע &lt;strong&gt;אותו&lt;/strong&gt; ערך \(c\). זה &lt;strong&gt;לא&lt;/strong&gt; מה שמשפט הערך הממוצע של לגראנז’ מבטיח! הוא מבטיח שעבור \(f\) קיים קבוע \(c_{f}\) כך ש-\(f^{\prime}\left(c_{f}\right)=\frac{f\left(b\right)-f\left(a\right)}{b-a}\), ועבור \(g\) קיים קבוע \(c_{g}\) כך ש-\(g^{\prime}\left(c_{g}\right)=\frac{g\left(b\right)-g\left(a\right)}{b-a}\), אבל שום דבר לא מבטיח לנו \(c_{f}=c_{g}\); אנחנו צריכים איכשהו להפעיל את משפט לגראנז’ &lt;strong&gt;סימולטנית&lt;/strong&gt; לשתי הפונקציות הללו ביחד, ואין לנו את זה.&lt;/p&gt;

&lt;p&gt;העניין הוא שלא צריך להסתבך עם לגראנז, בכלל, הנה הוכחה ישירה בעזרת משפט רול שוב (רואים? משפט רול &lt;strong&gt;יעיל&lt;/strong&gt;! הוא בעצם מקפל בתוכו את כל החדו”א המורכב שנלמד עד לשלב הזה, ומרגע שיש לנו אותו צריך רק תעלולים פשוטים). נגדיר פונקציה&lt;/p&gt;

&lt;p&gt;\(h\left(x\right)=f\left(x\right)\left(g\left(b\right)-g\left(a\right)\right)-g\left(x\right)\left(f\left(b\right)-f\left(a\right)\right)\)&lt;/p&gt;

&lt;p&gt;כלומר, מאוד דומה לייצוג של המשוואה שאנחנו רוצים שתתקיים בסוף. כעת קל לראות ש-\(h\) היא רציפה ב-\(\left[a,b\right]\) וגזירה ב-\(\left(a,b\right)\) והנגזרת שלה היא&lt;/p&gt;

&lt;p&gt;\(h^{\prime}\left(x\right)=f^{\prime}\left(x\right)\left(g\left(b\right)-g\left(a\right)\right)-g^{\prime}\left(x\right)\left(f\left(b\right)-f\left(a\right)\right)\)&lt;/p&gt;

&lt;p&gt;וכמו כן מתקיים:&lt;/p&gt;

&lt;p&gt;\(h\left(a\right)=f\left(a\right)\left(g\left(b\right)-g\left(a\right)\right)-g\left(a\right)\left(f\left(b\right)-f\left(a\right)\right)=f\left(a\right)g\left(b\right)-g\left(a\right)f\left(b\right)\)&lt;/p&gt;

&lt;p&gt;\(h\left(b\right)=f\left(b\right)\left(g\left(b\right)-g\left(a\right)\right)-g\left(b\right)\left(f\left(b\right)-f\left(a\right)\right)=f\left(a\right)g\left(b\right)-g\left(a\right)f\left(b\right)\)&lt;/p&gt;

&lt;p&gt;כלומר \(h\left(a\right)=h\left(b\right)\) ולכן ממשפט רול קיים \(c\) כך ש-\(h^{\prime}\left(c\right)=0\), כלומר&lt;/p&gt;

&lt;p&gt;\(f^{\prime}\left(c\right)\left(g\left(b\right)-g\left(a\right)\right)-g^{\prime}\left(c\right)\left(f\left(b\right)-f\left(a\right)\right)=0\)&lt;/p&gt;

&lt;p&gt;וזה מה שרצינו.&lt;/p&gt;

&lt;p&gt;נשאר רק להוכיח את כלל לופיטל בעזרת משפט הערך הממוצע של קושי. זו הוכחה קצת פחות “נקייה” ממה שראינו עד כה, אז טוב ששמרתי אותה לסוף, אבל אין בה שום דבר נוראי; פשוט, הדרך הטובה ביותר להבין מה הולך בה היא לכתוב אותה בעצמכם. כמו מה שאני עושה כרגע. כי בחיי שאין לי שמץ של מושג מה הולך בהוכחה הזו למרות שקראתי אותה לפני רגע, אבל אני יודע שהיא פשוטה ואחרי שאכתוב אותה גם אבין אותה.&lt;/p&gt;

&lt;p&gt;ובכן, מה יש לנו? הפונקציות \(f,g\) שמקיימות שני דברים:&lt;/p&gt;
&lt;ol&gt;
 	&lt;li&gt;{::nomarkdown}\(\lim_{x\to a}f\left(x\right)=\lim_{x\to a}g\left(x\right)=0\){:/nomarkdown}&lt;/li&gt;
 	&lt;li&gt;{::nomarkdown}\(\lim_{x\to a}\frac{f^{\prime}\left(x\right)}{g^{\prime}\left(x\right)}\){:/nomarkdown} קיים&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;הטענה השניה נותנת לנו מידע כלשהו על הנגזרות בסביבת הנקודה \(a\). באופן כללי, הטענה \(\lim_{x\to a}h\left(x\right)=L\) אומרת שלכל \(\varepsilon&amp;gt;0\) קיים \(\delta&amp;gt;0\) כך שלכל \(x\) עבורו \(0&amp;lt;\left\|x-a\right\|&amp;lt;\delta\) מתקיים \(\left\|h\left(x\right)-L\right\|&amp;lt;\varepsilon\); בפרט, כדי שזה יתקיים, הכרחי ש-\(h\left(x\right)\) תהיה מוגדרת לכל \(x\) עבורו \(0&amp;lt;\left\|x-a\right\|&amp;lt;\delta\). החריג היחיד הוא הנקודה \(a\) עצמה, שאין לנו דרישה לגבי הערך של \(h\) בה. עכשיו, אצלנו \(h\left(x\right)=\frac{f^{\prime}\left(x\right)}{g^{\prime}\left(x\right)}\), כך שאנחנו יודעים שקיים \(\delta\) עבורו אם \(0&amp;lt;\left\|x-a\right\|&amp;lt;\delta\) אז \(\frac{f^{\prime}\left(x\right)}{g^{\prime}\left(x\right)}\) קיים; כלומר גם \(f^{\prime}\left(x\right)\) קיימת, וגם \(g^{\prime}\left(x\right)\) קיימת &lt;strong&gt;ושונה מאפס&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;הרעיון עכשיו הוא לקחת \(x\) כלשהו עבורו \(0&amp;lt;\left\|x-a\right\|&amp;lt;\delta\) ולהפעיל את משפט הערך הממוצע של קושי על הקטע שקצוותיו הם \(a\) ו-\(x\). יש כאן שני מקרים: כאשר \(a&amp;lt;x\) וכאשר \(a&amp;gt;x\), אבל מן הסתם מה שיקרה בהם יהיה סימטרי אז נניח ש-\(a&amp;lt;x\). עכשיו צריך שני דברים: ש-\(f,g\) יהיו &lt;strong&gt;רציפות&lt;/strong&gt; ב-\(\left[a,x\right]\), ושיהיו &lt;strong&gt;גזירות&lt;/strong&gt; ב-\(\left(a,x\right)\). את הדבר השני כבר יש לנו, ואנחנו גם יודעים שהפונקציות גזירות ב-\(x\) ולכן הן רציפות שם; הקושי היחיד הוא ב-\(a\). אנחנו יודעים ש-\(\lim_{x\to a}f\left(x\right)=\lim_{x\to a}g\left(x\right)=0\) ולכן כדי שהפונקציות הללו יהיו רציפות ב-\(a\) צריך להתקיים \(f\left(a\right)=g\left(a\right)=0\); אבל אם זה לא מתקיים, הן לא יהיו רציפות שם. לכן נכריח את זה לקרות - &lt;strong&gt;נגדיר מחדש&lt;/strong&gt; את הפונקציות הללו ב-\(a\) על ידי \(f\left(a\right)=g\left(a\right)=0\). האם ההגדרה מחדש הזו תיצור לנו בעיות? עוד מעט נחזור לשאלה הזו כדי לראות למה אין בעיות.&lt;/p&gt;

&lt;p&gt;עכשיו אפשר להשתמש במשפט הערך הממוצע של קושי ולקבל את הקיום של \(c\in\left(a,x\right)\) שעבורו מתקיים&lt;/p&gt;

&lt;p&gt;\(f^{\prime}\left(c\right)\left(g\left(x\right)-g\left(a\right)\right)=g^{\prime}\left(c\right)\left(f\left(x\right)-f\left(a\right)\right)\)&lt;/p&gt;

&lt;p&gt;ומכיוון ש-\(f\left(a\right)=g\left(a\right)=0\) אפשר לפשט קצת ולכתוב&lt;/p&gt;

&lt;p&gt;\(f^{\prime}\left(c\right)g\left(x\right)=g^{\prime}\left(c\right)f\left(x\right)\)&lt;/p&gt;

&lt;p&gt;ואם נחלק, נקבל&lt;/p&gt;

&lt;p&gt;\(\frac{f\left(x\right)}{g\left(x\right)}=\frac{f^{\prime}\left(c\right)}{g^{\prime}\left(c\right)}\)&lt;/p&gt;

&lt;p&gt;שכבר קצת מזכיר את המבנה של כלל לופיטל. אבל רגע אחד! אם אני מחלק בדברים, צריך לוודא שהם שונים מאפס! לגבי \(g^{\prime}\left(c\right)\) כבר ראינו את זה בהתחלה. מה לגבי \(g\left(x\right)\)? ובכן, אם היה מתקיים \(g\left(x\right)=0=g\left(a\right)\) אז אפשר היה להשתמש במשפט רול כדי למצוא נקודה בין \(a\) ל-\(x\) שבה \(g^{\prime}\) שווה לאפס, וכבר ראינו שזה לא יכול לקרות.&lt;/p&gt;

&lt;p&gt;עכשיו אפשר לסכם, עם טיעון קצת עדין שאפשר לנסח בחופזה בתור “מכיוון ש-\(c\) נמצא ב-\(\left(a,x\right)\) אז כאשר \(x\) שואף ל-\(a\) כך גם \(c\), ולכן \(\lim_{x\to a}\frac{f\left(x\right)}{g\left(x\right)}\) שווה ל-\(\lim_{c\to a}\frac{f^{\prime}\left(c\right)}{g^{\prime}\left(c\right)}\) כמבוקש”. אני ממליץ לכם לנסות להשלים את הפרטים בעצמכם כדי לקבל את תחושת ה”למה זה נכון” אבל הנה הפירוט הטכני בכל מקרה:&lt;/p&gt;

&lt;p&gt;פתחנו עם הנתון לפיו \(\lim_{x\to a}\frac{f^{\prime}\left(x\right)}{g^{\prime}\left(x\right)}\) קיים; בואו ואסמן אותו \(L=\lim_{x\to a}\frac{f^{\prime}\left(x\right)}{g^{\prime}\left(x\right)}\). אני רוצה להוכיח שגם \(\lim_{x\to a}\frac{f\left(x\right)}{g\left(x\right)}=L\), ואני אעשה את זה לפי הספר עם הגדרת האפסילון-דלתא הסטנדרטית. יהא אם כן \(\varepsilon&amp;gt;0\) כלשהו. מכיוון ש-\(L=\lim_{x\to a}\frac{f^{\prime}\left(x\right)}{g^{\prime}\left(x\right)}\) אז קיים \(\delta&amp;gt;0\) כך שאם \(0&amp;lt;\left\|x-a\right\|&amp;lt;\delta\) אז מתקיים \(\left\|\frac{f^{\prime}\left(x\right)}{g^{\prime}\left(x\right)}-L\right\|&amp;lt;\varepsilon\). אני טוען שאותו \(\delta\) יוכיח ש-\(\lim_{x\to a}\frac{f\left(x\right)}{g\left(x\right)}=L\); כלומר, אני צריך להראות שאם \(0&amp;lt;\left\|x-a\right\|&amp;lt;\delta\) אז \(\left\|\frac{f\left(x\right)}{g\left(x\right)}-L\right\|&amp;lt;\varepsilon\).&lt;/p&gt;

&lt;p&gt;עכשיו, הוכחנו קודם כי על פי משפט הערך הממוצע, קיים \(c\) כך ש-\(c\in\left(a,x\right)\) (או \(c\in\left(x,a\right)\) אם \(x&amp;lt;a\)) כך ש-\(\frac{f\left(x\right)}{g\left(x\right)}=\frac{f^{\prime}\left(c\right)}{g^{\prime}\left(c\right)}\). מכיוון ש-\(a&amp;lt;c&amp;lt;x\) ו-\(\left\|x-a\right\|&amp;lt;\delta\) אז גם \(\left\|c-a\right\|&amp;lt;\delta\) ולכן \(\left\|\frac{f^{\prime}\left(c\right)}{g^{\prime}\left(c\right)}-L\right\|&amp;lt;\varepsilon\) ולכן \(\left\|\frac{f\left(x\right)}{g\left(x\right)}-L\right\|&amp;lt;\varepsilon\) כמבוקש, מה שמסיים את ההוכחה.&lt;/p&gt;

&lt;p&gt;זה זמן טוב לסיים בו את הפוסט, אבל כרגיל - זה רק קצה הקרחון של השימושים במשפט הערך הממוצע, וזה פשוט ששולי הבלוג הזה צרים מלהכילם.&lt;/p&gt;</content><author><name></name></author><category term="כלל לופיטל" /><category term="משפט הערך הממוצע של לגראנז'" /><category term="משפט הערך הממוצע של קושי" /><category term="משפט רול" /><summary type="html">ביקשו ממני לסגור את אחד החורים המציקים שיש בבלוג - לתאר את משפט הערך הממוצע של לגראנז’, שהוא אחד מהתוצאות הבסיסיות והמעניינות ביותר שמלמדים על נגזרות. כתבתי בשעתו פוסט שמתאר מהן נגזרות והוא הרקע שדרוש כדי להבין את משפט לגראנז’; אבל אל לגראנז’ עצמו לא הגעתי. אז נתחיל עם תזכורת קטנה על מה מדובר.</summary></entry><entry><title type="html">איך מוצאים את הסכום של סדרה חשבונית וסדרה הנדסית?</title><link href="http://localhost:4000/blog/2019/05/30/arithmetic_and_geometric_series" rel="alternate" type="text/html" title="איך מוצאים את הסכום של סדרה חשבונית וסדרה הנדסית?" /><published>2019-05-30T18:16:39+03:00</published><updated>2019-05-30T18:16:39+03:00</updated><id>http://localhost:4000/blog/2019/05/30/arithmetic_and_geometric_series</id><content type="html" xml:base="http://localhost:4000/blog/2019/05/30/arithmetic_and_geometric_series">&lt;p&gt;אני רוצה להקדיש פוסט ייעודי לדברים שכבר הופיעו בבלוג שלל פעמים, בתור הערות אגב בפוסטים אחרים: הסכומים של סדרות חשבוניות והנדסיות. אם אתם לא יודעים מהן הסדרות הללו, עד סוף הפוסט תדעו; אבל אם אתם כבר יודעים, אז אפשר לגשת לעניין - המטרה של הפוסט הזה היא להסביר למה הנוסחאות הבאות הן נכונות:&lt;/p&gt;
&lt;ul&gt;
 	&lt;li&gt;{::nomarkdown}\(S_{n}=\frac{n\left(a_{1}+a_{n}\right)}{2}\){:/nomarkdown} עבור טור חשבוני.&lt;/li&gt;
 	&lt;li&gt;{::nomarkdown}\(S_{n}=a_{1}\frac{q^{n}-1}{q-1}\){:/nomarkdown} עבור טור הנדסי.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;נתחיל עם אגדה ידועה על המתמטיקאי קארל פרידריך גאוס, שתעזור לנו להבין על מה מדובר.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3777&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/05/220px-Carl_Friedrich_Gauss_1840_by_Jensen.jpg&quot; alt=&quot;&quot; width=&quot;220&quot; height=&quot;280&quot; /&gt;&lt;/p&gt;

&lt;p&gt;האגדה אומרת שכאשר גאוס היה בבית הספר היסודי, המורה שלו התעצל ונתן לתלמידים את המשימה המייגעת של חישוב הסכום \(1+2+3+\dots+100\) - כלומר, סכום כל המספרים עד 100. הרעיון היה שהם יבלו חצי יום בעבודה טכנית מייגעת וחסרת כל טעם, והמורה ינוח. הבעיה היא שגאוס הקטן בא אל המורה תוך כמה דקות עם הפתרון. האם זה קרה בגלל שגאוס היה מחשבון אנושי? לא! בדיוק ההפך! גאוס המחיש בצורה הטובה ביותר את גישת &lt;strong&gt;מתמטיקאים הם עצלנים&lt;/strong&gt;. במקום לבצע את החישוב, הוא מצא “דרך קיצור” שנותנת לו את הסכום בלי שיצטרך לחשב את כולו במפורש.&lt;/p&gt;

&lt;p&gt;הטריק של גאוס היה פשוט: הוא שם לב לכך שאם לוקחים את האיבר &lt;strong&gt;הראשון&lt;/strong&gt; בסכום (שהוא 1) ומחברים אותו לאיבר &lt;strong&gt;האחרון&lt;/strong&gt; בסכום (שהוא 100), מקבלים 101. זה בפני עצמו לא מרגש במיוחד, אבל העניין הוא שאותו מספר בדיוק מתקבל אם מחברים את האיבר &lt;strong&gt;השני&lt;/strong&gt; בסכום (שהוא 2) עם האיבר &lt;strong&gt;הלפני אחרון&lt;/strong&gt; בסכום (שהוא 99), וכן הלאה. בעצם, אומר גאוס, אפשר לחלק את כל המספרים בין 1 ל-100 לחמישים זוגות בדיוק, כך שהסכום של כל זוג הוא בדיוק 101:&lt;/p&gt;

&lt;p&gt;\(\left(1,100\right),\left(2,99\right),\left(3,98\right),\dots\)&lt;/p&gt;

&lt;p&gt;אם יש לנו בדיוק 50 זוגות, והסכום של כל אחד מהם הוא בדיוק 101, אז עברנו מביצוע 99 תרגילי חיבור לביצוע תרגיל כפל יחיד: \(50\times101=5050\). זה תרגיל שאפילו אני מסוגל לבצע בראש; לא צריך להיות “מחשבון אנושי”.&lt;/p&gt;

&lt;p&gt;אז הנה השיטה של גאוס בצורה יותר כללית: נניח שאני רוצה לחבר את כל המספרים מ-1 ועד \(n\), כאשר \(n\) הוא מספר טבעי כלשהו (במקרה של גאוס \(n=100\)). אני יכול לחלק את המספרים ל-\(\frac{n}{2}\) זוגות כך שבכל זוג הסכום של שני האיברים הוא \(n+1\), ולכן אני מקבל את הנוסחה&lt;/p&gt;

&lt;p&gt;\(1+2+\dots+n=\frac{n\left(n+1\right)}{2}\)&lt;/p&gt;

&lt;p&gt;אבל רגע אחד, יש כאן משהו מוזר: מה קורה אם \(n\) הוא אי זוגי? נאמר, \(n=9\), כדי לעבוד עם דוגמא קונקרטית פשוטה. במקרה הזה אני אמור לכאורה לחלק את המספרים ל-\(4.5\) זוגות, וזה… חסר משמעות. אז בואו נראה מה קורה אם מחלקים את המספרים מ-1 עד 9 ל”זוגות”:&lt;/p&gt;

&lt;p&gt;\(\left(1,9\right),\left(2,8\right),\left(3,7\right),\left(4,6\right),\left(5\right)\)&lt;/p&gt;

&lt;p&gt;מה קרה פה? ראשית, קיבלנו ארבעה זוגות שסכום כל אחד מהם הוא 10. שנית, קיבלנו את האיבר 5 &lt;strong&gt;לבדו&lt;/strong&gt;. אפשר לחשוב על זה בתור “חצי זוג”; כאילו לקחתי את הזוג \(\left(5,5\right)\) אבל במקום לספור את הסכום שלו, 10, ספרתי רק &lt;strong&gt;חצי &lt;/strong&gt;מהסכום שלו, כלומר 5. זה אומר שהנוסחה שלנו עובדת יפה גם במקרה הזה.&lt;/p&gt;

&lt;p&gt;עכשיו אפשר לקחת את הנוסחה הזו ולהכליל אותה טיפה. הסכום \(1+2+3+\dots+n\) הוא דוגמא פשוטה למשהו שנקרא &lt;strong&gt;טור חשבוני&lt;/strong&gt;: זה סכום של סדרת מספרים, שבה &lt;strong&gt;ההפרש &lt;/strong&gt;בין כל שני איברים סמוכים הוא &lt;strong&gt;קבוע&lt;/strong&gt;. סדרות של מספרים לרוב נכתבות בעזרת אות שמסמנת את הסדרה, ועוד מספר קטן למטה - &lt;strong&gt;האינדקס&lt;/strong&gt; - שבא לומר על איזה מקום בסדרה מדברים כרגע. למשל \(a_{1},a_{2},a_{3},\dots,a_{n}\). את הסכום של סדרה כזו נהוג לסמן ב-\(S_{n}=a_{1}+\dots+a_{n}\).&lt;/p&gt;

&lt;p&gt;שימו לב לעניין טרמינולוגי קטן: המילה &lt;strong&gt;סדרה&lt;/strong&gt; (באנגלית Sequence) מתארת את סדרת האיברים - מה שסימנתי בתור \(a_{1},a_{2},a_{3},\dots,a_{n}\). המילה &lt;strong&gt;טור&lt;/strong&gt; (באנגלית Series) מתארת את הסכום שלהם, מה שסימנתי בתור \(a_{1}+\dots+a_{n}\).&lt;/p&gt;

&lt;p&gt;בסדרה חשבונית, התכונה שמגדירה את הסדרה היא ש-\(a_{k+1}-a_{k}=d\) לכל \(1\le k&amp;lt;n\). המספר \(d\) נקרא &lt;strong&gt;ההפרש&lt;/strong&gt; של הסדרה. מה שנחמד הוא שמספיק להכיר את האיבר הראשון בסדרה ואת \(d\) כדי לדעת מה יהיה ערכו של כל איבר אחר: \(a_{2}=a_{1}+d\) ו-\(a_{3}=a_{2}+d=a_{1}+2d\) וכן הלאה - קל לראות שבאופן כללי אפשר לכתוב \(a_{n}=a_{1}+\left(n-1\right)d\).&lt;/p&gt;

&lt;p&gt;גם בסדרה חשבונית כללית משתמר הכלל שגאוס ראה - שסכום האיבר הראשון והאחרון זהה לסכום האיבר השני והלפני-אחרון וכן הלאה. למה? ובכן, בכל זוג כזה אנחנו הולכים “צעד אחד קדימה” עבור אחד מהאיברים (מהאיבר הראשון אל השני, למשל). בצעד הזה מתווסף \(d\) לסכום; אבל באיבר השני אנחנו הולכים “צעד אחורה” (מהאיבר האחרון אל הלפני אחרון, למשל) ובצעד הזה מורידים \(d\) מהסכום הכללי. לכן, אומר גאוס, בסדרה חשבונית של \(n\) איברים שהאיבר הראשון שלה הוא \(a_{1}\) והאחרון הוא \(a_{n}\), אפשר לחלק את הסדרה ל-\(\frac{n}{2}\) זוגות שסכום כל אחד מהם הוא \(a_{1}+a_{n}\), מה שנותן לנו את הנוסחה:&lt;/p&gt;

&lt;p&gt;\(S_{n}=\frac{n\left(a_{1}+a_{n}\right)}{2}\)&lt;/p&gt;

&lt;p&gt;מכיוון שאנחנו יודעים לבטא את \(a_{n}\) בעזרת \(a_{1}\) ו-\(d\) אפשר גם לכתוב&lt;/p&gt;

&lt;p&gt;\(S_{n}=\frac{n\left(2a_{1}+\left(n-1\right)d\right)}{2}=na_{1}+\frac{n\left(n-1\right)d}{2}\)&lt;/p&gt;

&lt;p&gt;זה מסיים את הסיפור עבור טור חשבוני. בואו נעבור לסוג הנפוץ השני של טור, שעבורו אין לי אנקדוטה גאוסית: &lt;strong&gt;טור הנדסי&lt;/strong&gt;. בסדרה הנדסית, &lt;strong&gt;המנה&lt;/strong&gt; של כל שני איברים סמוכים קבועה: \(\frac{a_{k+1}}{a_{k}}=q\) כאשר \(q\ne0\) הוא מספר שונה מאפס כלשהו ו-\(a_{1}\) גם הוא צריך להיות שונה מאפס. למשל, אם ניקח את \(a_{1}=2\) ואת \(q=3\) נקבל את הסדרה \(2,6,18,54,\dots\). בסדרה הנדסית כזו, האיבר במקום ה-\(n\) נתון על ידי \(a_{n}=a_{1}q^{n-1}\), באופן די דומה למה שקרה בסדרה חשבונית.&lt;/p&gt;

&lt;p&gt;אם \(q=1\) הסדרה שלנו היא “משעממת”: הסדרה הקבועה \(a_{1},a_{1},a_{1},\dots\). הסכום של סדרה כזו הוא \(na_{1}\) ולכן אפשר לראות את המקרה הזה כסגור ולעבור למקרים המעניינים האחרים, שבהם \(q\ne1\).&lt;/p&gt;

&lt;p&gt;בואו נתחיל עם המקרה הפשוט שבו \(a_{1}=1\) ולכן הסדרה שלנו היא \(1,q,q^{2},q^{3},\dots,q^{n}\) שימו לב ש-\(q^{n}\) הוא האיבר ה-\(n+1\)-י בסדרה. עכשיו, מהו הסכום \(1+q+q^{2}+\dots+q^{n}\)? על פניו זה תרגיל לא קל, אבל שוב בא לעזרתנו תעלול מז’אנר “מתמטיקאים הם עצלנים”. אני לא זוכר בעל פה את הנוסחה לטור הנדסי; אני כן זוכר בעל פה את התעלול הזה, שהוא פשוט “להכפיל הכל ב-\(q-1\)”.&lt;/p&gt;

&lt;p&gt;כי מה קורה כשכופלים ב-\(q-1\)? לכאורה מקבלים משהו הרבה יותר מסובך, אבל למעשה רוב האיברים בסכום שנקבל &lt;strong&gt;יבטלו זה את זה&lt;/strong&gt;. נקבל מה שנקרא “טור טלסקופי” (כי הרעיון בו הוא שהוא נראה ארוך אבל אפשר “לכווץ” אותו לממדים זעירים, כמו שטלסקופ יכול להיות ארוך ואפשר לכווץ אותו). כדי לראות את זה, אני אכתוב את כל אברי המכפלה \(\left(q-1\right)\left(1+q+\dots+q^{n}\right)\) בשתי שורות: בשורה הראשונה התוצאה של הכפלת \(q\) בסוגריים הימניים, ובשורה השניה התוצאה של הכפלת \(-1\) בסוגריים הללו:&lt;/p&gt;

&lt;p&gt;\(\begin{array}{cccccc} &amp;amp; q &amp;amp; +q^{2} &amp;amp; +\dots &amp;amp; +q^{n} &amp;amp; +q^{n+1}\\ -1 &amp;amp; -q &amp;amp; -q^{2} &amp;amp; -\dots &amp;amp; -q^{n} \end{array}\)&lt;/p&gt;

&lt;p&gt;האיברים היחידים שלא מבטלים אלו את אלו הם \(q^{n+1}\) (שהתקבל מהכפלה של \(q\) עם האיבר הגדול בסוגריים, \(q^{n}\)) ו-\(-1\) (שהתקבל מהכפלה של \(-1\) עם האיבר הקטן בסוגריים, \(1\)). לכן התוצאה שנקבל היא \(q^{n+1}-1\), כלומר&lt;/p&gt;

&lt;p&gt;\(\left(q-1\right)\left(1+q+\dots+q^{n}\right)=q^{n+1}-1\)&lt;/p&gt;

&lt;p&gt;נחלק ב-\(q-1\) את שני האגפים, תוך הסתמכות על ההנחה שלנו ש-\(q\ne1\), ונקבל את נוסחת הסכום:&lt;/p&gt;

&lt;p&gt;\(1+q+\dots+q^{n}=\frac{q^{n+1}-1}{q-1}\)&lt;/p&gt;

&lt;p&gt;עכשיו בואו נדבר על טור הנדסי כללי. שני דברים משתנים: ראשית, האיבר הראשון אינו בהכרח 1 אלא הוא \(a_{1}\); ושנית, אני שואל את עצמי מה קורה כשיש בדיוק \(n\) איברים בטור. כלומר, אני רוצה לדעת מהו הסכום&lt;/p&gt;

&lt;p&gt;\(a_{1}+a_{1}q+\dots+a_{1}q^{n-1}\)&lt;/p&gt;

&lt;p&gt;קל לטפל בעניין ה-\(a_{1}\) הזה: בואו נוציא אותו כגורם משותף, ונקבל&lt;/p&gt;

&lt;p&gt;\(a_{1}\left(1+q+\dots+q^{n-1}\right)\)&lt;/p&gt;

&lt;p&gt;עכשיו, הביטוי שבסוגריים מאוד קרוב למה שכבר קיבלנו:&lt;/p&gt;

&lt;p&gt;\(1+q+\dots+q^{n}=\frac{q^{n+1}-1}{q-1}\)&lt;/p&gt;

&lt;p&gt;אם נחליף בנוסחה שלעיל את \(n\) ב-\(n-1\) בשני האגפים, נקבל&lt;/p&gt;

&lt;p&gt;\(1+q+\dots+q^{n-1}=\frac{q^{n}-1}{q-1}\)&lt;/p&gt;

&lt;p&gt;ומכאן הנוסחה הכללית לסכום סדרה הנדסית:&lt;/p&gt;

&lt;p&gt;\(S_{n}=a_{1}\frac{q^{n}-1}{q-1}\)&lt;/p&gt;

&lt;p&gt;מה באשר לסכומים של סדרות כלליות ומתוחכמות יותר? למשל, ידעתם שהסכום של \(n\) האיברים הראשונים בסדרת פיבונאצ’י שווה למספר פיבונאצ’י ה-\(n+2\), כל זה פחות 1? כלומר, אם \(F_{1}=F_{2}=1\) ו-\(F_{n}=F_{n-1}+F_{n-2}\) אז \(F_{1}+F_{2}+\dots+F_{n}=F_{n+2}-1\). האם יש לי דרך פשוטה להסביר את זה? ובכן… לא. אפשר להוכיח את זה בקלות באינדוקציה ואפשר לגלות את זה בקלות בעזרת כלי בקומבינטוריקה שנקרא &lt;strong&gt;פונקציות יוצרות&lt;/strong&gt;, אבל אני לא מכיר הסבר טריוויאלי פשוט שנותן את האינטואיציה לכך (אולי אקבל כזה בתגובות). באופן כללי, זו הבעיה עם סדרות מתוחכמות יותר - יש לנו כלים לטפל גם בהן, אבל הסיפור כבר לא עד כדי כך פשוט. לכן אני חושב שאעצור כאן.&lt;/p&gt;</content><author><name></name></author><category term="טור הנדסי" /><category term="טור חשבוני" /><summary type="html">אני רוצה להקדיש פוסט ייעודי לדברים שכבר הופיעו בבלוג שלל פעמים, בתור הערות אגב בפוסטים אחרים: הסכומים של סדרות חשבוניות והנדסיות. אם אתם לא יודעים מהן הסדרות הללו, עד סוף הפוסט תדעו; אבל אם אתם כבר יודעים, אז אפשר לגשת לעניין - המטרה של הפוסט הזה היא להסביר למה הנוסחאות הבאות הן נכונות: {::nomarkdown}\(S_{n}=\frac{n\left(a_{1}+a_{n}\right)}{2}\){:/nomarkdown} עבור טור חשבוני. {::nomarkdown}\(S_{n}=a_{1}\frac{q^{n}-1}{q-1}\){:/nomarkdown} עבור טור הנדסי. נתחיל עם אגדה ידועה על המתמטיקאי קארל פרידריך גאוס, שתעזור לנו להבין על מה מדובר.</summary></entry><entry><title type="html">הוכחה לנוסחת אוילר לגרפים בעזרת גרפים אוילריים</title><link href="http://localhost:4000/blog/2019/04/30/euler_formula_proof_with_eulerian_graphs" rel="alternate" type="text/html" title="הוכחה לנוסחת אוילר לגרפים בעזרת גרפים אוילריים" /><published>2019-04-30T13:34:33+03:00</published><updated>2019-04-30T13:34:33+03:00</updated><id>http://localhost:4000/blog/2019/04/30/euler_formula_proof_with_eulerian_graphs</id><content type="html" xml:base="http://localhost:4000/blog/2019/04/30/euler_formula_proof_with_eulerian_graphs">&lt;p&gt;המטרה שלי בפוסט הזה היא לקשר שני דברים בסיסיים בתורת הגרפים שאני מאוד מחבב אישית: &lt;strong&gt;נוסחת אוילר&lt;/strong&gt; לגרפים מישוריים, והמושג של &lt;strong&gt;גרף אוילרי&lt;/strong&gt;. ספציפית, אני הולך לתת הוכחה לנוסחת אוילר שמתבססת על גרפים אוילריים, תוך הסתייגות הולמת שזו לא באמת הוכחה פורמלית עד הסוף ואם ממש מתעקשים אפשר גם להציג אותה בלי המושג של גרף אוילרי אבל איפה הכיף פה. באנו היום לכייף.&lt;/p&gt;

&lt;p&gt;כפי שאפשר לנחש, הפוסט הזה לא נועד לעמוד בפני עצמו והוא מניח שאתם מכירים את נוסחת אוילר לגרפים מישוריים וגרפים אוילריים. יש לי &lt;a href=&quot;https://gadial.net/2010/01/31/euler_formula_and_platonic_solids/&quot;&gt;כאן&lt;/a&gt; פוסט על נוסחת אוילר &lt;a href=&quot;https://gadial.net/2008/05/06/eulerian_graphs/&quot;&gt;וכאן&lt;/a&gt; פוסט על גרפים אוילריים, אבל אני כן אזכיר את מה שצריך לדעת. חוץ מגרפים. גרפים אני באמת הולך להניח שאתם יודעים וזהו.&lt;/p&gt;

&lt;p&gt;נוסחת אוילר מדברת על גרפים &lt;strong&gt;מישוריים&lt;/strong&gt;: גרפים שאפשר לצייר במישור בלי ששתי קשתות יחתכו זו את זו (הצמתים הם נקודות והקשתות הן קווים שמחברים את הנקודות; לאו דווקא קווים ישרים למרות שאפשר להראות שכל גרף מישורי אפשר לצייר עם קווים ישרים שכאלה). בשביל לדבר על נוסחת אוילר צריך גם לדרוש שהגרף המישורי יהיה &lt;strong&gt;קשיר&lt;/strong&gt; - שיש מסלול שמחבר כל שני צמתים בו.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;גרף אוילרי&lt;/strong&gt; הוא גרף שאפשר לצייר מבלי להרים את העפרון מהדף - כזה שיש בו מסלול שעובר דרך כל הקשתות בדיוק פעם אחת. הנה דוגמא לגרף שיש בו גם את זה וגם את זה:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3771&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/04/pasted1.png&quot; alt=&quot;&quot; width=&quot;394&quot; height=&quot;580&quot; /&gt;&lt;/p&gt;

&lt;p&gt;הגרף הזה הוא בעצם ציור הבית מחידת ה”האם אפשר לצייר בית עם איקס בתוכו מבלי להרים את העפרון מהדף” למעט זה שבמקום להשלים את האיקס בתוכו, הקשת שמחברת את הפינה הימנית-תחתונה והפינה השמאלית-עליונה עוברת &lt;strong&gt;מחוץ&lt;/strong&gt; לבית כדי לא לחתוך את הקשת שעוברת בתוך הבית. זה מראה שהגרף הזה הוא &lt;strong&gt;מישורי&lt;/strong&gt;, בנוסף לכך שהוא אוילרי. כפי שאפשר לנחש, הוא הולך לככב בהמשך הפוסט שלנו.&lt;/p&gt;

&lt;p&gt;כשיש לנו ציור של גרף מישורי אפשר לדבר לא רק על הצמתים והקשתות שלו אלא גם על &lt;strong&gt;הפאות&lt;/strong&gt; שלו - השטחים הסגורים שנתחמים על ידי הקשתות (המילה “פאות” מגיעה מההקשר המקורי של נוסחת אוילר, עבור פאונים; לא אדבר על כך בפוסט הזה):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3772&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/04/pasted2.png&quot; alt=&quot;&quot; width=&quot;405&quot; height=&quot;570&quot; /&gt;&lt;/p&gt;

&lt;p&gt;בתמונה הנוכחית צבעתי את הפאות בצבעים עליזים - ורוד, ירוק, כחול, צהוב ולבן. רגע, איפה הלבן כאן? ובכן, גם השטח ש”מחוץ” לגרף נחשב לאחת מהפאות שלו, “הפאה החיצונית”. כלומר, הצביעה העליזה שלי מראה לנו שלגרף יש חמש פאות. בנוסף לכך יש לו חמישה צמתים (הנקודות הכחולות) ויש לו שמונה קשתות (הקווים השחורים העבים שמחברים צמתים). אם נסמן את מספר הצמתים ב-\(V\), את מספר הקשתות ב-\(E\) ואת מספר הפאות ב-\(F\) נגלה שמתקיים&lt;/p&gt;

&lt;p&gt;\(V-E+F=2\)&lt;/p&gt;

&lt;p&gt;והקשר הזה בין מספר הצמתים, הקשתות והפאות מתקיים &lt;strong&gt;תמיד&lt;/strong&gt;, בכל גרף מישורי קשיר; זו נוסחת אוילר, שהיא ללא ספק אחת מהנוסחאות החביבות עלי במתמטיקה. המטרה שלי בפוסט הזה היא להוכיח שהיא אכן מתקיימת תמיד, בכל גרף מישורי קשיר (חייבים קשירות כי אחרת אפשר להגדיל את מספר הצמתים \(V\) בלי להשפיע על מספר הקשתות או הפאות, סתם על ידי הוספת צמתים מבודדים), אבל &lt;strong&gt;הוכחה&lt;/strong&gt; היא מילה די גדולה בהקשר הזה - שנתפשר על “המחשה יפה”?&lt;/p&gt;

&lt;p&gt;רגע, למה בעצם אני לא יכול לתת הוכחה של ממש? ובכן, כל המושג של “גרף מישורי” הוא די קשה מבחינה פורמלית. מה זה אומר “לצייר את הגרף במישור כך שאין חיתוכים”? צריך לערב כאן עולם מושגי חדש לגמרי - המישור \(\mathbb{R}^{2}\) ומה זה אומר “לצייר” בו משהו - זה אומר ליצור עקומות; עקומה היא פונקציה רציפה \(f:\left[0,1\right]\to\mathbb{R}^{2}\), ועכשיו צריך לדבר על חיתוך של עקומות, ועל מה זו בעצם פאה - רכיב קשירות נפרד של המישור כשמסירים ממנו את האיזורים שמכוסים על ידי עקומות? כל הדברים הללו מובילים אותנו אל משפט מפלצתי שנקרא &lt;strong&gt;משפט ז’ורדן &lt;/strong&gt;ואומר (בנפנוף ידיים) שאם מציירים עיגול במישור אז הוא מפרק את המישור ל”בפנים” וה”בחוץ” של העיגול. זה משפט קשה עם הוכחה קשה. אז לא, אני לא אכנס לפורמליזם הזה פה ואפילו לא אנסה - בדיוק בשביל זה הבלוג נקרא “לא מדויק”.&lt;/p&gt;

&lt;p&gt;הרעיון ב”הוכחה” שלי הוא פשוט ויפה וניתן לתיאור בפסקה אחת לפני שנדגים אותו בצורה מפורטת. אנחנו נצייר את הגרף המישורי שלנו מבלי להרים את העט מהדף, ונעקוב כל הזמן אחרי מספר הפאות הנוכחי. כל “צעד” שלנו כולל ציור של קשת אחת, ולכן אחרי \(E\) צעדים הציור יושלם. כשאנחנו רק מתחילים והציור ריק, יש לנו רק פאה אחת - הפאה החיצונית. מתי נוצרות פאות חדשות? בדיוק בצעדים שמחזירים אותנו לצומת שבה כבר היינו. כמה צעדים כאלו יש? אם יש \(E\) צעדים בסך הכל ולכן אנחנו מבקרים בסך הכל ב-\(E+1\) צמתים במהלך הציור - הפלוס אחד מגיע מכך שאנחנו נמצאים בצומת כלשהי כבר בהתחלה, עוד לפני שציירנו קשת אחת. יש בסך הכל \(V\) צמתים ולכן אנחנו מבקרים ב-\(E+1-V\) צמתים יותר מפעם אחת. לכן מספר הפאות &lt;strong&gt;שמתווספות&lt;/strong&gt; אל האחת הראשונית יהיה \(E+1-V\), כלומר \(F-1=E+1-V\), ואחרי העברת אגפים נקבל \(V-E+F=2\).&lt;/p&gt;

&lt;p&gt;איבדתן אותי? לא לדאוג, מייד תבוא דוגמא. לא איבדתן אותי אבל מעצבן אתכן שה”הוכחה” שלי עובדת רק אם הגרף המישורי שלי הוא גם במקרה על הדרך באופן ממוזל גרף אוילרי אבל בבירור רוב הגרפים המישוריים אינם כאלו? אז אני אגלה כבר עכשיו שזה פתיר בקלות רבה - קחו גרף מישורי כלשהו ופשוט שכפלו כל קשת פעמיים. גם לזה נחזור עם תמונות בהמשך.&lt;/p&gt;

&lt;p&gt;בואו נעקוב אחרי תהליך הציור של התמונה לעיל, עם ספירה של מספר הקשתות והפאות בכל רגע נתון. כל חמשת הצמתים יופיעו כל הזמן - כלומר, \(V=5\) הולך להיות קבוע. בהתחלה יש רק את הצמתים, ודמיינו שאנחנו עומדים בצומת הימני-תחתון ומחכים בהתרגשות לתחילת המסע שלנו בגרף:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3764&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/04/pasted3.png&quot; alt=&quot;&quot; width=&quot;262&quot; height=&quot;458&quot; /&gt;&lt;/p&gt;

&lt;p&gt;כאן \(E=0\) ו-\(F=1\) (כי הפאה החיצונית, הלבנה).&lt;/p&gt;

&lt;p&gt;עכשיו נבצע את הצעד הראשון:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3765&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/04/pasted4.png&quot; alt=&quot;&quot; width=&quot;250&quot; height=&quot;497&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ועכשיו \(E=1\) ו-\(F=1\) נשאר כמו קודם - מכיוון שהקשת הגיעה לצומת שטרם ביקרנו בו, לא יצרנו פאה חדשה. אנחנו רואים שלבקר בצומת שטרם ביקרנו בו זה משעמם, אז בואו נבצע את כל יתר הצעדים הנדרשים כדי שנבקר &lt;strong&gt;בכל&lt;/strong&gt; הצמתים; מרגע זה והלאה, כל צעד נוסף יצור פאה חדשה:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3766&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/04/pasted5.png&quot; alt=&quot;&quot; width=&quot;236&quot; height=&quot;455&quot; /&gt;&lt;/p&gt;

&lt;p&gt;כרגע \(E=4\) (כמספר הצמתים פחות אחד - לא מקרי, כמובן, הקשר \(E=V-1\) מתקיים בכל &lt;strong&gt;עץ&lt;/strong&gt;) ו-\(F=1\). כלומר, כבר כרגע מתקיימת הנוסחה \(V-E+F=2\), וזה לא מפתיע כי הגרף שקיבלנו כרגע הוא גם מישורי וגם &lt;strong&gt;קשיר&lt;/strong&gt; (זוכרות? קשירות הייתה הכרחית בשביל נוסחת אוילר, בדיוק בגלל שצמתים מבודדים כמו בתמונות הקודמות לא משפיעים על \(E\) ועל \(F\) ואפשר להוסיף כמה מהם שרוצים). מה שיקרה מכאן ואילך הוא שכל צעד &lt;strong&gt;ישמר&lt;/strong&gt; את הקשר הזה, \(V-E+F=2\); כי כל צעד גם יוסיף קשת אחת (יגדיל את \(E\) ב-1) וגם יצור פאה חדשה (יגדיל את \(F\) ב-1). בואו נראה את זה קורה בפעם הראשונה:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3767&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/04/pasted6.png&quot; alt=&quot;&quot; width=&quot;243&quot; height=&quot;448&quot; /&gt;&lt;/p&gt;

&lt;p&gt;מה שנחמד פה הוא שהפאה שיצרנו לא מופיעה בתמונה הסופית, פשוט כי הצעד הבא מפרק אותה לשתי פאות:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3768&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/04/pasted7.png&quot; alt=&quot;&quot; width=&quot;220&quot; height=&quot;449&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ונראה לי שהרעיון ברור אז אני אצייר את שתי הקשתות הבאות ביחד:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3769&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/04/pasted8.png&quot; alt=&quot;&quot; width=&quot;366&quot; height=&quot;553&quot; /&gt;&lt;/p&gt;

&lt;p&gt;זה מסיים את ה”הוכחה”, אבל עדיין צריך להתייחס למקרה שבו הגרף המישורי שלנו איננו אוילרי, מה שמחזיר אותנו לשאלה בסיסית קצת יותר - מתי גרף הוא &lt;strong&gt;כן&lt;/strong&gt; אוילרי? כאן נדרשים שני דברים. ראשית, שהגרף יהיה קשיר; אבל אנחנו מניחים שהגרף המישורי שלנו קשיר, כך שזה לא רלוונטי. שנית, צריך ש&lt;strong&gt;הדרגה&lt;/strong&gt; של כל צומת תהיה זוגית, פרט אולי לשני צמתים בדיוק. דרגה של צומת היא מספר הקשתות שנוגעות בו; מכיוון שבמסלול אוילרי בכל פעם שבה אנחנו נכנסים לצומת ו”שורפים” את הקשת שאיתה נכנסנו אנחנו גם יוצאים ממנו ו”שורפים” את הקשת שאיתה יצאנו, קל לראות שמספר הקשתות שמתאימות לכל צומת חייב להיות זוגי למעט בצמתי ההתחלה והסיום. האתגר הגדול יותר הוא להראות שזה גם &lt;strong&gt;תנאי מספיק&lt;/strong&gt; לכך שיהיה מסלול אוילרי בגרף, אבל אני לא אעשה את זה כאן הפעם אלא רק אשתמש בזה.&lt;/p&gt;

&lt;p&gt;בגלל שהקריטריון הזה לאוילריות של גרף הוא כל כך פשוט, אנחנו יכולים לנצל אותו ולהפוך גרף לאוילרי בקלי קלות - פשוט נכפיל את מספר הקשתות. הנה דוגמא:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3770&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/04/pasted9.png&quot; alt=&quot;&quot; width=&quot;876&quot; height=&quot;366&quot; /&gt;&lt;/p&gt;

&lt;p&gt;הגרף הימני הוא הגרף המפורסם של “בעיית הגשרים של קניגסברג” שאוילר פתר. כל הצמתים שם מדרגה אי זוגית ולכן הגרף אינו אוילרי, למרות שהוא בבירור מישורי ובבירור מקיים את נוסחת אוילר (\(V=4\) ו-\(E=7\) ו-\(F=5\)). הגרף השמאלי הוא מה שקורה לגרף הימני כשאני לוקח כל קשת ומפצל אותה לשתיים. ההשפעה של הפיצול הזה על הגרף היא זו:&lt;/p&gt;
&lt;ol&gt;
 	&lt;li&gt;מספר הקשתות החדש בגרף הוא פי 2 מאשר בגרף הישן. אסמן זאת {::nomarkdown}\(E^{\prime}=2E\){:/nomarkdown}.&lt;/li&gt;
 	&lt;li&gt;מספר הצמתים בגרף החדש זהה למספר הצמתים בגרף הישן. אסמן זאת {::nomarkdown}\(V^{\prime}=V\){:/nomarkdown}.&lt;/li&gt;
 	&lt;li&gt;עבור כל קשת בגרף המקורי יצרנו פאה חדשה, של השטח ש&quot;כלוא&quot; בין שתי הקשתות החדשות שהחליפו את הקשת הזו - אני מסמן את הפאות החדשות בירוק. כלומר, {::nomarkdown}\(F^{\prime}=F+E\){:/nomarkdown}.&lt;/li&gt;
 	&lt;li&gt;הגרף החדש עכשיו אוילרי ולכן מקיים את נוסחת אוילר: {::nomarkdown}\(V^{\prime}-E^{\prime}+F^{\prime}=2\){:/nomarkdown}.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;כל מה שנשאר לעשות הוא להציב במשוואה של 4 את המשוואות של 1-3. נקבל:&lt;/p&gt;

&lt;p&gt;\(V-2E+\left(F+E\right)=2\)&lt;/p&gt;

&lt;p&gt;כלומר \(V-E+F=2\), שזה מה שרצינו להוכיח, וסיימנו.&lt;/p&gt;

&lt;p&gt;כפי שאמרתי קודם, ההוכחה הזו לא באמת נותנת נקודת מבט שונה מהותית על הנושא ביחס להוכחות הסטנדרטיות יותר שמשתמשות באינדוקציה וכדומה. סוג הטיעונים כמעט זהה. ההבדל העיקרי הוא שההוכחה הזו, לתחושתי, פשוט כיפית יותר.&lt;/p&gt;</content><author><name></name></author><category term="גרף אוילרי" /><category term="גרף מישורי" /><category term="נוסחת אוילר" /><summary type="html">המטרה שלי בפוסט הזה היא לקשר שני דברים בסיסיים בתורת הגרפים שאני מאוד מחבב אישית: נוסחת אוילר לגרפים מישוריים, והמושג של גרף אוילרי. ספציפית, אני הולך לתת הוכחה לנוסחת אוילר שמתבססת על גרפים אוילריים, תוך הסתייגות הולמת שזו לא באמת הוכחה פורמלית עד הסוף ואם ממש מתעקשים אפשר גם להציג אותה בלי המושג של גרף אוילרי אבל איפה הכיף פה. באנו היום לכייף.</summary></entry><entry><title type="html">משפטי נקודת השבת של בנך וברואר</title><link href="http://localhost:4000/blog/2019/03/23/banach_and_brouwer_fixed_point_theorem" rel="alternate" type="text/html" title="משפטי נקודת השבת של בנך וברואר" /><published>2019-03-23T16:42:33+02:00</published><updated>2019-03-23T16:42:33+02:00</updated><id>http://localhost:4000/blog/2019/03/23/banach_and_brouwer_fixed_point_theorem</id><content type="html" xml:base="http://localhost:4000/blog/2019/03/23/banach_and_brouwer_fixed_point_theorem">&lt;h2&gt;מבוא&lt;/h2&gt;
&lt;p&gt;בואו נתחיל עם סיפור קצרצר בן פסקה אחת של חורחה לואיס בורחס בשם “על הדיוק במדע” שאני מביא פה בתרגום יורם ברונובסקי:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;…באימפריה זו הגיעה אמנות כתיבת המפות למידת שלמות כזו, שמפתו של מחוז אחד השתרעה על פני עיר שלמה ואילו מפתה של האימפריה כולה - על פני המחוז כולו. ברבות הימים לא סיפקו עוד מפות ענק אלה את התשובות וועדות כותבי המפות החלו להכין את מפת האימפריה שגודלה כגודל האימפריה עצמה, והיא זהה עמה בכל נקודה ונקודה. הדורות הבאים היו אדוקים פחות במדע כתיבת המפות, הם גרסו שמפה נרחבת זו היא מיותרת והפקידו אותה לאכזריות השמש והחורף. במדבריות המערב שרדו כמה חורבות של המפה, שם שוכנים חיות בר וקבצנים, בארץ כולה לא היו שרידים נוספים של מדע כתיבת הארץ.&lt;/p&gt;

  &lt;p&gt;(מתוך “מסעות אנשי החיל” לסוארס מיראנדה, ספר רביעי, פרק מ”ה, לרידה, 1658.)&amp;lt;/blockquote&amp;gt;
לא, אל תחפשו את “מסעות אנשי החיל” לסוארס מיראנדה, הוא קיים בערך כמו ספר מפורסם אחר של אחד, ס. מורגנשטרן.&lt;/p&gt;

  &lt;p&gt;איך כל זה קשור למתמטיקה? ובכן, על משמעות כלליות מהסיפור אפשר לדבר בפעם אחרת, הפעם הבאתי אותו כי המוטיבציה שלי לכתיבת הפוסט היא דבר אחר, דומה, שגם כן מערב מפות: ההבחנה שאם ניקח מפה של ארץ כלשהי (לא בהכרח 1:1 כמו המפה של בורחס) ונניח אותה על הקרקע של הארץ שמתוארת בה, אז תהיה נקודה על המפה שנמצאת &lt;strong&gt;בדיוק&lt;/strong&gt; מעל הנקודה על הקרקע הפיזית שהנקודה הזו במפה מתארת. תמיד. וגם אם נזיז קצת את המפה - עדיין תהיה. וכן, גם אם ננסה בכוונה להניח את המפה על הקרקע כך שזה לא יקרה, זה יקרה. וגם אם נסובב את המפה - זה יקרה. ומה שנחמד פה כל כך הוא שהתוצאה הזו היא המחשה יפה של &lt;strong&gt;משפט נקודת השבת של בנך&lt;/strong&gt;; והמשפט הזה גם מצביע על הדרך שבה אפשר למצוא את הנקודה שבה זה קורה.&lt;/p&gt;

  &lt;p&gt;משפט נקודת השבת של בנך הוא הדבר העיקרי שאני רוצה להראות בפוסט הזה, ברמת הניסוח המלא וההוכחה. על הדרך אני גם אנצל את ההזדמנות ואסביר כמעט כל מושג שבו אני משתמש, כי המשפט הזה הוא הזדמנות טובה עבורנו לחזור על מושגי הבסיס הללו.&lt;/p&gt;

  &lt;p&gt;אפשר לחשוב על משפט נקודת השבת של בנך בתור “כמעט מקרה פרטי” של משפט מפורסם עוד יותר, &lt;strong&gt;משפט נקודת השבת של ברואר&lt;/strong&gt; (למה רק “כמעט”? אדבר על ההבדלים המדויקים בהמשך). גם למשפט של ברואר יש אילוסטרציות נחמדות: נניח שאתם מערבבים כוס משקה, אז מובטח שתהיה נקודה אחת בכוס שאחרי כל הערבובים חזרה למקום שבו התחילה. או אילוסטרציה אחרת: קחו שני דפים מאותו הגודל, שימו אחד על השני, ואז קמטו את הדף שלמעלה כמה שתרצו - עדיין תהיה נקודה אחת לפחות בדף המקומט שנמצאת בדיוק מעל הנקודה שמתאימה לה בדף שמתחת. על המשפט של ברואר אני אגניב כמה מילים בסוף אבל לא אוכיח אותו הפעם, כי זו לא הוכחה כמעט-מיידית כמו של בנך.&lt;/p&gt;
  &lt;h2&gt;משפט נקודת השבת של בנך&lt;/h2&gt;
  &lt;p&gt;מה הרעיון במפה? מפה היא עותק מוקטן של פני השטח במציאות (אלא אם אנחנו בסיפור של בורחס). אם תרצו, אנחנו &lt;strong&gt;מכווצים&lt;/strong&gt; את המרחב שלנו אל תת-מרחב ספציפי, במובן זה שה&lt;strong&gt;מרחק&lt;/strong&gt; בין נקודות הופך לקטן יותר. משפט נקודת השבת של בנך עוסק בדיוק בסיטואציה הזו - העתקה ממרחב לעצמו שהיא &lt;strong&gt;מכווצת&lt;/strong&gt;. זה דורש ממני להגדיר מה הכוונה ב”מרחב” ואיך אני מודד “מרחק” וכדומה, ויש לי תשובות שונות ומשונות לזה בהתאם להיכרות שיש לכם עם מתמטיקה. נתחיל עם הדוגמא הפשוטה: המרחב שלנו הוא פשוט &lt;strong&gt;המישור&lt;/strong&gt;, \(X=\mathbb{R}^{2}\), אוסף הנקודות מהצורה \(\left(a,b\right)\) כאשר \(a,b\in\mathbb{R}\). האופן שבו מודדים מרחק בין שתי נקודות במישור הוא על ידי הנוסחה \(d\left(\left(a_{1},a_{2}\right),\left(b_{1},b_{2}\right)\right)=\sqrt{\left(a_{1}-b_{1}\right)^{2}+\left(a_{2}-b_{2}\right)^{2}}\) (זה בעצם &lt;strong&gt;משפט פיתגורס&lt;/strong&gt; בפעולה).&lt;/p&gt;

  &lt;p&gt;זה נותן לנו מרחב קונקרטי להתייחס אליו, אבל למה לעצור שם? האם המשפט לא יעבוד גם עבור תת-קבוצה של המרחב הזה, נאמר ריבוע היחידה \(X=\left[0,1\right]\times\left[0,1\right]\)? והאם הוא לא יעבוד עבור \(X=\mathbb{R}^{3}\)? ומה אם אנחנו מודדים מרחק בדרך קצת שונה, למשל \(d\left(\left(a_{1},a_{2}\right),\left(b_{1},b_{2}\right)\right)=\left\|a_{1}-b_{1}\right\|+\left\|a_{2}-b_{2}\right\|\)? המשפט ימשיך לעבוד בכל המקרים הללו, ולכן כדי לדבר על כולן בבת אחת אנחנו מדברים על מושג שנקרא &lt;strong&gt;מרחב מטרי&lt;/strong&gt;. מרחב מטרי \(\left(X,d\right)\) כולל קבוצה \(X\) ופונקציית מרחק \(d:X^{2}\to\mathbb{R}^{\ge0}\) כך שלכל \(a,b,c\in X\):&lt;/p&gt;
  &lt;ol&gt;
 	&lt;li&gt;{::nomarkdown}\(d\left(a,b\right)=0\){:/nomarkdown} אם ורק אם {::nomarkdown}\(a=b\){:/nomarkdown}&lt;/li&gt;
 	&lt;li&gt;{::nomarkdown}\(d\left(a,b\right)=d\left(b,a\right)\){:/nomarkdown} (סימטריה)&lt;/li&gt;
 	&lt;li&gt;{::nomarkdown}\(d\left(a,b\right)\le d\left(a,c\right)+d\left(c,b\right)\){:/nomarkdown} (אי-שוויון המשולש)&lt;/li&gt;
&lt;/ol&gt;
  &lt;p&gt;ההגדרה הפשוטה הזו מאפשרת דיבור אחיד על כל המקרים שציינתי קודם ואינספור מקרים אחרים, וזה ההקשר שבו נכון לתאר את משפט נקודת השבת של בנך; אבל למי שמתקשים עם הדיבור האבסטרקטי על מרחבים מטריים, אפשר לחשוב כל הזמן על המקרה הקונקרטי \(X=\mathbb{R}^{2}\) ו-\(d\left(\left(a_{1},a_{2}\right),\left(b_{1},b_{2}\right)\right)=\sqrt{\left(a_{1}-b_{1}\right)^{2}+\left(a_{2}-b_{2}\right)^{2}}\) שהזכרתי קודם. עובד באותה מידה.&lt;/p&gt;

  &lt;p&gt;דרישה אחת מהמרחב כדי שהמשפט יעבוד היא שהוא יהיה &lt;strong&gt;שלם&lt;/strong&gt;. מרחב מטרי שלם הוא מרחב שבו כל סדרת קושי מתכנסת, אבל אם זה לא אומר לכם שום דבר כרגע זה לא צריך לעצור אתכם - בהמשך נבין בדיוק מה זו סדרת קושי ולמה היא מעניינת אותנו. \(\mathbb{R}^{2}\) הוא מרחב שלם, כך שהמשפט יהיה תקף לגביו. דוגמא למרחב לא שלם היא \(\mathbb{Q}\) - שם המחסור בנקודות כמו \(\sqrt{2}\) ו-\(\pi\) יוצר בעיה של ממש (אפשר לקבל משהו בסגנון “נקודת השבת &lt;strong&gt;צריכה&lt;/strong&gt; להיות \(\sqrt{2}\) אבל היי, רגע, מה הולך פה, לאן היא נעלמה?”)&lt;/p&gt;

  &lt;p&gt;עכשיו צריך להכניס לתמונה פונקציה, \(f:X\to X\). אם רוצים לקשר את זה לדוגמת המפה שאיתה פתחתי, אפשר לחשוב על פונקציה שפועלת כך: בהינתן נקודה בארץ שהמפה מתארת (הארץ הזו היא \(X\)), הפונקציה מאתרת את הנקודה המתאימה על המפה, הולכת אל הנקודה הזו ומחזירה את הנקודה על הקרקע של הארץ “האמיתית” שנוגעת בנקודה הזו במפה. באופן הזה קיבלנו פונקציה מ-\(X\) אל \(X\) (ולא מ-\(X\) אל “מפה שמתארת את \(X\)”).&lt;/p&gt;

  &lt;p&gt;עכשיו, פונקציה היא &lt;strong&gt;מכווצת&lt;/strong&gt; אם היא מקטינה את המרחק בין נקודות, אבל לא סתם ברמה “כלשהי” אלא ברמה שנותנת חסם כפלי כלשהו - “מקטינה פי 2” או “מקטינה פי שבע שמיניות” וכן הלאה. פורמלית צריך להיות קיים קבוע \(0&amp;lt;q&amp;lt;1\) כך שלכל \(a,b\in X\) מתקיים \(d\left(f\left(a\right),f\left(b\right)\right)\le q\cdot d\left(a,b\right)\) (באופן כללי פונקציה שבה המרחק בין פלטים של הפונקציה חסום על ידי קבוע &lt;strong&gt;כלשהו&lt;/strong&gt; כפול המרחק בין הקלטים נקראת &lt;strong&gt;ליפשיצית&lt;/strong&gt;, וכאשר הקבוע הזה קטן מאחד אז היא נקראת “מכווצת”). ומה היה קורה אם לא היה קבוע כזה אלא “סתם” היה מתקיים \(d\left(f\left(a\right),f\left(b\right)\right)\le d\left(a,b\right)\) לכל \(a,b\in X\)? ובכן, לא רק שההוכחה שתכף אציג לא הייתה עובדת, גם המשפט כלל לא היה נכון.&lt;/p&gt;

  &lt;p&gt;אבל מה המשפט בעצם? עוד לא ניסחתי אותו! ובכן, אם \(f\) היא פונקציה מכווצת שכזו ממרחב מטרי שלם לעצמו, אז קיימת נקודה &lt;strong&gt;יחידה&lt;/strong&gt; \(a^{*}\in X\) כך ש-\(f\left(a^{*}\right)=a^{*}\). הפתעה! (טוב, אולי העובדה שהנקודה הזו &lt;strong&gt;יחידה&lt;/strong&gt; היא מפתיעה) אבל יותר מכך, אפשר תמיד למצוא אותה באופן הבא: ניקח נקודה \(a_{0}\in X\) באופן &lt;strong&gt;שרירותי לחלוטין&lt;/strong&gt; (לא משנה מאיפה נתחיל) ונגדיר סדרה \(a_{n+1}=f\left(a_{n}\right)\), אז מובטח לנו שיתקיים \(\lim_{n\to\infty}a_{n}=a^{*}\) (פורמלית: לכל \(\varepsilon&amp;gt;0\) ממשי קיים \(N\) טבעי כך שאם \(n&amp;gt;N\) אז \(d\left(a_{n},a^{*}\right)&amp;lt;\varepsilon\)). כפי שנראה, אפשר יהיה גם להגיד משהו על &lt;strong&gt;קצב ההתכנסות&lt;/strong&gt; של הסדרה הזו אל \(a^{*}\).&lt;/p&gt;

  &lt;p&gt;עיקר ההוכחה של המשפט היא חישוב טכני לא נוראי במיוחד של המרחק בין שתי נקודות &lt;strong&gt;כלשהן&lt;/strong&gt; בסדרה שכזו. כלומר, נניח ש-\(n&amp;lt;m\) ונחשב חסם עבור \(d\left(a_{n},a_{m}\right)\). הרעיון פה הוא שעבור שתי נקודות שבאות זו אחר זו בסדרה קל לנו לתת חסם מפורש, ואז אפשר להעריך את המרחק בין \(a_{n}\) ו-\(a_{m}\) על ידי שימוש באי-שוויון המשולש כדי לחסום את המרחק ביניהן על ידי נקודות ביניים שהן כל האיברים מ-\(a_{n}\) עד \(a_{m}\).&lt;/p&gt;

  &lt;p&gt;נתחיל עם דוגמאות פשוטות: את המרחק \(d\left(a_{0},a_{1}\right)\) אין לנו איך לחסום; זו “נקודת המוצא” שלנו. ככל ש-\(a_{0}\) יותר קרוב ל-\(a_{1}\) (כלומר, ככל ש-\(a_{0}\) יותר קרוב אל \(f\left(a_{0}\right)\)) כך החסם על ההתכנסות של הסדרה יהיה טוב יותר.&lt;/p&gt;

  &lt;p&gt;את המרחק \(d\left(a_{1},a_{2}\right)\) לעומת זאת אפשר לחסום: \(a_{1}=f\left(a_{0}\right)\) ואילו \(a_{2}=f\left(a_{1}\right)\) ולכן&lt;/p&gt;

  &lt;p&gt;\(d\left(a_{1},a_{2}\right)=d\left(f\left(a_{0}\right),f\left(a_{1}\right)\right)\le qd\left(a_{0},a_{1}\right)\)&lt;/p&gt;

  &lt;p&gt;באופן דומה:&lt;/p&gt;

  &lt;p&gt;\(d\left(a_{2},a_{3}\right)=d\left(f\left(a_{1}\right),f\left(a_{2}\right)\right)\le qd\left(a_{1},a_{2}\right)\le q^{2}d\left(a_{0},a_{1}\right)\)&lt;/p&gt;

  &lt;p&gt;וכבר אפשר להמשיך עם זה באינדוקציה ולקבל את הטענה הכללית שנכונה לכל \(k\ge0\):&lt;/p&gt;

  &lt;p&gt;\(d\left(a_{k},a_{k+1}\right)\le q^{k}d\left(a_{0},a_{1}\right)\)&lt;/p&gt;

  &lt;p&gt;חמושים בידע הנוסף הזה אפשר להעריך את \(d\left(a_{n},a_{m}\right)\) גם עבור נקודות לא סמוכות. הרעיון הוא להסתכל על כל סדרת הנקודות \(a_{n},a_{n+1},a_{n+2},\dots,a_{m-1},a_{m}\) (הנחנו ש-\(n&amp;lt;m\)) - מאי-שוויון המשולש אנו יודעים שמתקיים&lt;/p&gt;

  &lt;p&gt;\(d\left(a_{n},a_{m}\right)\le d\left(a_{n},a_{n+1}\right)+\dots+d\left(a_{m-1},a_{m}\right)\)&lt;/p&gt;

  &lt;p&gt;אפשר לכתוב את אותו הדבר בקיצור כך:&lt;/p&gt;

  &lt;p&gt;\(d\left(a_{n},a_{m}\right)\le\sum_{i=0}^{m-n-1}d\left(a_{n+i},a_{n+i+1}\right)\)&lt;/p&gt;

  &lt;p&gt;וכעת, ממה שמצאנו קודם אנו יודעים ש-\(d\left(a_{n+i},a_{n+i+1}\right)\le q^{n+i}d\left(a_{0},a_{1}\right)\) ולכן נקבל&lt;/p&gt;

  &lt;p&gt;\(d\left(a_{n},a_{m}\right)\le\sum_{i=0}^{m-n-1}q^{n+i}d\left(a_{0},a_{1}\right)=q^{n}d\left(a_{0},a_{1}\right)\cdot\sum_{i=0}^{m-n-1}q^{i}\)&lt;/p&gt;

  &lt;p&gt;הסכום שנשאר לנו הוא טור הנדסי רגיל. אני תמיד אוהב להזכיר איך אנחנו יודעים מה הסכום של טור הנדסי: אם אני צריך לחשב את \(1+q+q^{2}+\dots+q^{n}\) אני כופל ב-\(\left(q-1\right)\) ומקבל הרבה איברים שמצטמצמים ובסוף נשאר \(q^{n+1}-1\). נחלק ב-\(q-1\) שבו כפלתי, ונקבל שסכום הטור הוא \(\frac{q^{n+1}-1}{q-1}\). לכן במקרה שלנו:&lt;/p&gt;

  &lt;p&gt;\(\sum_{i=0}^{m-n-1}q^{i}=\frac{q^{m-n}-1}{q-1}\)&lt;/p&gt;

  &lt;p&gt;אפשר לפשט את זה טיפה עבורנו - \(\sum_{i=0}^{m-n-1}q^{i}&amp;lt;\sum_{i=0}^{\infty}q^{i}=\frac{1}{1-q}\) (תחשבו שאני מציב 0 במקום \(q^{m-n}\)), ולכן נקבל&lt;/p&gt;

  &lt;p&gt;\(d\left(a_{n},a_{m}\right)\le\frac{d\left(a_{0},a_{1}\right)}{1-q}\cdot q^{n}\)&lt;/p&gt;

  &lt;p&gt;וזו כבר תוצאה מצויינת. תזכרו ש-\(0&amp;lt;q&amp;lt;1\), ולכן ככל ש-\(n\) גדול יותר כך \(q^{n}\) קטן יותר. לכן מה שקיבלנו הוא שהמרחק בין \(a_{n}\) לבין &lt;strong&gt;כל&lt;/strong&gt; נקודה שבאה אחריה בסדרה שווה למספר הקבוע \(\frac{d\left(a_{0},a_{1}\right)}{1-q}\) כפול משהו (\(q^{n}\)) שהולך וקטן ככל שאנחנו לוקחים \(a_{n}\) גדול יותר. חישוב לא מסובך מראה שלכל \(\varepsilon&amp;gt;0\) אנחנו מסוגלים למצוא \(N\) כך שאם \(n&amp;gt;N\) מתקיים \(\frac{d\left(a_{0},a_{1}\right)}{1-q}\cdot q^{n}&amp;lt;\varepsilon\). כלומר, לכל \(m&amp;gt;n&amp;gt;N\) יתקיים \(d\left(a_{n},a_{m}\right)&amp;lt;\varepsilon\). זה מראה שהסדרה \(\left\{ a_{n}\right\} \) היא &lt;strong&gt;סדרת קושי&lt;/strong&gt;.&lt;/p&gt;

  &lt;p&gt;סדרת קושי, אינטואיטיבית, היא סדרה שככל שמתקדמים בה יותר כך המרחק בין כל שני איברים בה (לאו דווקא כאלו שסמוכים זה לזה בסדרה) הולך וקטן. פורמלית זה בדיוק מה שתיארנו: לכל \(\varepsilon\) קיים \(N\) כך שלכל \(m&amp;gt;n&amp;gt;N\) מתקיים \(d\left(a_{n},a_{m}\right)&amp;lt;\varepsilon\). החשיבות של התכונה הזו של “להיות סדרת קושי” היא בכך שהיא מצביעה על כך שהסדרה &lt;strong&gt;אמורה להתכנס&lt;/strong&gt; לגבול קונקרטי; כלומר, “צריך” להיות \(a^{*}\) כך שלכל \(\varepsilon&amp;gt;0\) קיים \(N\) כך שאם \(n&amp;gt;N\) אז \(d\left(a_{n},a^{*}\right)&amp;lt;\varepsilon\). ה”צריך” הזה לא תמיד מתקיים בפועל; במקרה של \(\mathbb{R}\) הוא מתקיים, אבל במקרה של \(\mathbb{Q}\), למשל, הוא לאו דווקא מתקיים (תסתכלו על הסדרה \(3,3.1,3.14,3.141,\dots\) ש”אמורה להתכנס אל \(\pi\)” אבל הרי \(\pi\) אינו רציונלי למרות שאברי הסדרה כן). מרחב מטרי שבו כל סדרת קושי היא מתכנסת נקרא &lt;strong&gt;מרחב מטרי שלם&lt;/strong&gt;, והנחנו ש-\(X\) הוא מרחב מטרי שלם כחלק מתנאי משפט נקודת השבת של בנך.&lt;/p&gt;

  &lt;p&gt;לסיכום, הראינו ש-\(\left\{ a_{n}\right\} \) היא סדרת קושי ולכן קיים \(a^{*}\in X\) כך ש-\(a_{n}\to a^{*}\). אבל מה זה עוזר לנו, בעצם? האם זה מוכיח ש-\(a^{*}\) היא נקודת שבת? ובכן, כן, אבל הנימוק יצריך מאיתנו לראות את היעילות של מושג בסיסי נוסף: &lt;strong&gt;רציפות&lt;/strong&gt;.&lt;/p&gt;

  &lt;p&gt;הנה מה שאני &lt;strong&gt;רוצה&lt;/strong&gt; להגיד: אנחנו יודעים ש-\(\lim_{n\to\infty}a_{n}=a^{*}\). עכשיו, את מהסדרה \(a_{0},a_{1},a_{2},\dots\) אפשר לסלק את האיבר הראשון, ואז לכתוב את הסדרה שנותרה בתור \(f\left(a_{0}\right),f\left(a_{1}\right),\dots\). כלומר, הסדרות \(\left\{ a_{n}\right\} \) ו-\(\left\{ f\left(a_{n}\right)\right\} \) הן אותה סדרה למעט האיבר הראשון, והאיבר הראשון לא באמת משפיע על גבול הסדרה. לכן גם \(\lim_{n\to\infty}f\left(a_{n}\right)=a^{*}\).&lt;/p&gt;

  &lt;p&gt;כעת, הייתי &lt;strong&gt;רוצה&lt;/strong&gt; להגיד משהו כזה: \(\lim_{n\to\infty}f\left(a_{n}\right)=f\left(\lim_{n\to\infty}a_{n}\right)\). אם הייתי יכול לומר את זה, אז הייתי מקבל:&lt;/p&gt;

  &lt;p&gt;\(a^{*}=\lim_{n\to\infty}f\left(a_{n}\right)=f\left(\lim_{n\to\infty}a_{n}\right)=f\left(a^{*}\right)\)&lt;/p&gt;

  &lt;p&gt;מה שהיה מוכיח ש-\(a^{*}\) היא אכן נקודת שבת של \(f\). אז בואו נתמקד שוב במה שאני &lt;strong&gt;רוצה&lt;/strong&gt; שיקרה:&lt;/p&gt;

  &lt;p&gt;\(\lim_{n\to\infty}f\left(a_{n}\right)=f\left(\lim_{n\to\infty}a_{n}\right)\)&lt;/p&gt;

  &lt;p&gt;במילים: הגבול של סדרת הפלטים של \(f\) על \(a_{n}\) הוא אותו דבר כמו הפלט של \(f\) על הגבול של \(a_{n}\). הפעולות של “חישוב הגבול של הסדרה” ו”הפעלת \(f\)” הן &lt;strong&gt;קומוטטיביות&lt;/strong&gt; - אפשר להחליף את הסדר ביניהן ועדיין לקבל את אותה התוצאה. אם \(f\) היא &lt;strong&gt;פונקציה רציפה&lt;/strong&gt; אז הדבר הזה מתקיים. מה זו פונקציה רציפה? בנפנוף ידיים כלשהו - פונקציה שעבור קלטים קרובים מספיק מחזירה פלטים שהם גם כן קרובים.&lt;/p&gt;

  &lt;p&gt;הנה הגדרה פורמלית: \(f\) רציפה בנקודה \(x_{0}\) אם לכל \(\varepsilon&amp;gt;0\) קיים \(\delta&amp;gt;0\) כך ש-\(d\left(x,x_{0}\right)&amp;lt;\delta\) (“קלטים קרובים”) גורר \(d\left(f\left(x\right),f\left(x_{0}\right)\right)&amp;lt;\varepsilon\) (“פלטים קרובים”). שימו לב שדיברתי פה על רציפות בנקודה &lt;strong&gt;מסויימת&lt;/strong&gt;; אומרים על \(f\) שהיא רציפה בכל המרחב \(X\) אם היא רציפה לכל \(x_{0}\in X\). בהגדרה הזו, ה-\(\delta\) שמוצאים בתגובה ל-\(\varepsilon\) יכול להיות תלוי גם בנקודה \(x_{0}\); יש הגדרה חזקה יותר של רציפות שנקראת &lt;strong&gt;רציפות במידה שווה&lt;/strong&gt; שבה עבור \(\varepsilon\) אפשר למצוא \(\delta\) ש”עובד לכל הנקודות ב-\(X\) בו זמנית”; לא אצטרך את ההגדרה הזו כאן.&lt;/p&gt;

  &lt;p&gt;רציפות היא תכונה חשובה עם שלל משמעויות שנובעות ממנה, אבל כאן אני אסתפק בזו שרלוונטית לנו: \(\lim_{n\to\infty}f\left(a_{n}\right)=f\left(\lim_{n\to\infty}a_{n}\right)\). כזכור, אנחנו מסמנים \(a^{*}=\lim_{n\to\infty}a_{n}\), כך שמה שאשתמש בו הוא הרציפות של \(f\) בנקודה \(a^{*}\). כדי להוכיח \(f\left(a^{*}\right)=\lim_{n\to\infty}f\left(a_{n}\right)\) אני לוקח \(\varepsilon&amp;gt;0\) וצריך למצוא \(N\) כך שלכל \(n&amp;gt;N\) מתקיים \(d\left(f\left(a^{*}\right),f\left(a_{n}\right)\right)&amp;lt;\varepsilon\). ובכן, מכיוון ש-\(f\) רציפה, קיים \(\delta&amp;gt;0\) כך שאם \(d\left(a^{*},a_{n}\right)&amp;lt;\delta\) אז \(d\left(f\left(a^{*}\right),f\left(a_{n}\right)\right)&amp;lt;\varepsilon\). כעת, מכיוון ש-\(a^{*}=\lim_{n\to\infty}a_{n}\) אז קיים \(N\) כך שאם \(n&amp;gt;N\) אז מתקיים \(d\left(a^{*},a_{n}\right)&amp;lt;\delta\) - ומכאן ש-\(d\left(f\left(a^{*}\right),f\left(a_{n}\right)\right)&amp;lt;\varepsilon\), כמו שרצינו.&lt;/p&gt;

  &lt;p&gt;לסיכום: הראינו שאם \(f\) רציפה אז \(a^{*}\) היא אכן נקודת שבת. אבל למה \(f\) רציפה? זו תכונה שמשותפת לכל פונקציה ליפשיצית: אם \(d\left(f\left(a\right),f\left(b\right)\right)\le q\cdot d\left(a,b\right)\) עבור \(0&amp;lt;q\) אז בהינתן \(\varepsilon&amp;gt;0\) נבחר \(\delta=\frac{\varepsilon}{q}\) ואז עבור \(a,b\) כך ש-\(d\left(a,b\right)&amp;lt;\delta\) יתקיים&lt;/p&gt;

  &lt;p&gt;\(d\left(f\left(a\right),f\left(b\right)\right)\le q\cdot d\left(a,b\right)&amp;lt;q\cdot\frac{\varepsilon}{q}=\varepsilon\)&lt;/p&gt;

  &lt;p&gt;זה מסיים את שלב ה&lt;strong&gt;קיום&lt;/strong&gt; של משפט נקודת השבת של בנך. הראינו שאם לוקחים נקודה שרירותית כלשהי ומפעילים את \(f\) עליה שוב ושוב, מתכנסים אל נקודת שבת. למה לא ייתכן שנתכנס אל שתי נקודות שבת שונות אם נתחיל במקומות שונים? הטיעון כאן הוא כמעט טריוויאלי: כי אם \(f\) לא משנה שתי נקודות, אז המרחק בין התמונות שלהן לא יהיה קטן מהמרחק ביניהן, בסתירה לכך ש-\(f\) מכווצת. פורמלית, אם \(a^{*},b^{*}\) הן שתי נקודות שבת אז&lt;/p&gt;

  &lt;p&gt;\(d\left(a^{*},b^{*}\right)=d\left(f\left(a^{*}\right),f\left(b^{*}\right)\right)\le qd\left(a^{*},b^{*}\right)\le d\left(a^{*},b^{*}\right)\)&lt;/p&gt;

  &lt;p&gt;בפרט, \(qd\left(a^{*},b^{*}\right)=d\left(a^{*},b^{*}\right)\) ומכיוון ש-\(0&amp;lt;q&amp;lt;1\) זה קורה רק אם \(d\left(a^{*},b^{*}\right)=0\) כלומר אם \(a^{*}=b^{*}\). זה מסיים את משפט נקודת השבת של בנך.&lt;/p&gt;
  &lt;h2&gt;משפט נקודת השבת של ברואר&lt;/h2&gt;
  &lt;p&gt;משפט נקודת השבת של ברואר אומר שכל פונקציה רציפה מכדור היחידה ה-\(n\) ממדי לעצמו היא בעלת נקודת שבת. ההוכחה שלו היא מסובכת יחסית ולא אציג אותה בפוסט הזה, אבל בואו ננסה להבין במה הוא דומה ושונה למשפט נקודת השבת של בנך.&lt;/p&gt;

  &lt;p&gt;ראשית, המשפט של ברואר מפורסם יותר ושימושי יותר במתמטיקה, ולכן בכלל הזכרתי אותו למרות שמטרת הפוסט הייתה משפט נקודת השבת של בנך; אני לא חושב שנכון לדבר על משפטי נקודות שבת בלי להזכיר את ברואר בכלל.&lt;/p&gt;

  &lt;p&gt;שנית, ברואר מדבר על נקודת שבת בפונקציה רציפה &lt;strong&gt;כלשהי&lt;/strong&gt;. אצל בנך הדרישה הרבה יותר קיצונית: לא רק שהפונקציה צריכה להיות רציפה, היא צריכה להיות ליפשיצית, עם קבוע ליפשיץ קטן מ-1 (“מכווצת”). במובן זה ברואר מכסה מחלקה רחבה בהרבה של פונקציות.&lt;/p&gt;

  &lt;p&gt;עוד הבדל, הפעם לטובת בנך, הוא שמשפט בנך תקף במרחב מטרי שלם כלשהו, לא רק במרחב מטרי שחי ב-\(\mathbb{R}^{n}\). ברואר מתעסק בתנאים מגבילים יותר. אפשר טיפה למתוח את מה שברואר אומר - אם למרחב טופולוגי כלשהו יש את התכונה שלכל פונקציה רציפה מעליו יש נקודת שבת, אז כך גם לכל תמונה הומיאומורפית שלו (מרחב אחר כך שיש בינם התאמה חח”ע ועל שמשמרת את הטופולוגיה של המרחב). זה אומר שאפשר להשתמש בברואר לכל קבוצה קומפקטית קמורה ב-\(\mathbb{R}^{n}\), אבל עדיין אנחנו “חיים” ב-\(\mathbb{R}^{n}\); אם תרצו, ברואר הוא אחד ממשפטי האפיון הבסיסיים של “מה זה \(\mathbb{R}^{n}\) בכלל ומה מייחד אותו כמרחב”.&lt;/p&gt;

  &lt;p&gt;ועוד הבדל לטובת בנך הוא שמשפט ברואר הוא לא קונסטרוקטיבי - הוא לא נותן לנו דרך למצוא את נקודת השבת, רק מוכיח שהיא קיימת. זאת בשונה ממשפט בנך, שמראה דרך מפורשת “לבנות” אותה בתור גבול של סדרה. למעשה, העובדה שהמשפט המפורסם שלו עצמו לא קונסטרוקטיבי הייתה אחת מהדברים שגרמו לברואר לאמץ את הגישה ה&lt;strong&gt;אינטואיציוניסטית&lt;/strong&gt; לפילוסופיה של המתמטיקה, שבה הוכחות לא קונסטרוקטיביות כאלו אינן מתקבלות בברכה (וכמובן, ראויה לפוסט משל עצמה שמי יודע אם אי פעם אכתוב).&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name></name></author><category term="משפט נקודת השבת של בנך" /><category term="משפט נקודת השבת של ברואר" /><category term="נקודת שבת" /><summary type="html">מבוא בואו נתחיל עם סיפור קצרצר בן פסקה אחת של חורחה לואיס בורחס בשם “על הדיוק במדע” שאני מביא פה בתרגום יורם ברונובסקי: …באימפריה זו הגיעה אמנות כתיבת המפות למידת שלמות כזו, שמפתו של מחוז אחד השתרעה על פני עיר שלמה ואילו מפתה של האימפריה כולה - על פני המחוז כולו. ברבות הימים לא סיפקו עוד מפות ענק אלה את התשובות וועדות כותבי המפות החלו להכין את מפת האימפריה שגודלה כגודל האימפריה עצמה, והיא זהה עמה בכל נקודה ונקודה. הדורות הבאים היו אדוקים פחות במדע כתיבת המפות, הם גרסו שמפה נרחבת זו היא מיותרת והפקידו אותה לאכזריות השמש והחורף. במדבריות המערב שרדו כמה חורבות של המפה, שם שוכנים חיות בר וקבצנים, בארץ כולה לא היו שרידים נוספים של מדע כתיבת הארץ.</summary></entry><entry><title type="html">האם כל המתמטיקה בעצם מבוססת על כשלים לוגיים?</title><link href="http://localhost:4000/blog/2019/03/23/math_based_on_logical_fallacies" rel="alternate" type="text/html" title="האם כל המתמטיקה בעצם מבוססת על כשלים לוגיים?" /><published>2019-03-23T08:41:47+02:00</published><updated>2019-03-23T08:41:47+02:00</updated><id>http://localhost:4000/blog/2019/03/23/math_based_on_logical_fallacies</id><content type="html" xml:base="http://localhost:4000/blog/2019/03/23/math_based_on_logical_fallacies">&lt;p&gt;להיט עכשיו בפייסבוק העברי הוא צילום המסך הזה של פוסט שלא חשוב על ידי מי נכתב, כי הוא מופץ במטרה ללעוג לכותב:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3755&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/03/DivideByZero.png&quot; alt=&quot;&quot; width=&quot;738&quot; height=&quot;753&quot; /&gt;&lt;/p&gt;

&lt;p&gt;אותי פחות מעניין ללעוג לכותב ויותר לשאול שאלות ולנסות לענות להן. למשל:&lt;/p&gt;
&lt;ol&gt;
 	&lt;li&gt;למה אין כאן סתירה? (התקציר: כי מחלקים באפס)&lt;/li&gt;
 	&lt;li&gt;מאיפה בעצם ה&quot;תרגיל&quot; הזה הגיע ומאיפה בא הסיפור על ניוטון? (התקציר: אין לי מושג)&lt;/li&gt;
 	&lt;li&gt;האם אפשר לומר משהו מעניין מתמטית על התרגיל הזה? (קצת)&lt;/li&gt;
 	&lt;li&gt;האם כל המתמטיקה בעצם מבוססת על כשלים לוגיים? (ובכן... הישארו עמנו?)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;וכעת לתשובה קצת יותר מפורטת. ראשית, התרגיל. אם נעקוב אחרי השלבים שלו בקפידה נראה שכולם תקינים במובן זה שכל שורה נובעת לוגית מהשורה שמעליה, למעט שורה אחת: המעבר מ-&lt;/p&gt;

&lt;p&gt;\(\left(x-3\right)\left(x+5\right)=\left(x-3\right)\left(x+4\right)\)&lt;/p&gt;

&lt;p&gt;אל&lt;/p&gt;

&lt;p&gt;\(x+5=x+4\)&lt;/p&gt;

&lt;p&gt;מעבר כזה נקרא &lt;strong&gt;צמצום&lt;/strong&gt;, וכדי לבצע אותו צריך לוודא שמה שמצמצמים בו לא שווה לאפס. למה? ובכן, כי לכאורה מה שעושים בצמצום הוא לחלק באפס, וכידוע אסור לחלק באפס. אבל אני אפילו לא זקוק לטענה הזו. צמצום באופן כללי הוא המעבר ממשוואה מהצורה&lt;/p&gt;

&lt;p&gt;\(a\cdot x=a\cdot y\)&lt;/p&gt;

&lt;p&gt;אל המשוואה&lt;/p&gt;

&lt;p&gt;\(x=y\)&lt;/p&gt;

&lt;p&gt;“מעבר” ממשוואה אחת לשניה פירושו: אם קיים פתרון למשוואה &lt;strong&gt;הראשונה&lt;/strong&gt;, אז הוא יהיה פתרון גם למשוואה &lt;strong&gt;השניה&lt;/strong&gt;. זה האופן שבו אנחנו פותרים משוואות: לוקחים משוואה מסובכת ומפעילים עליה שורה של מניפולציות ש&lt;strong&gt;משמרות&lt;/strong&gt; את הפתרונות של המשוואה המקורית. המקרה של כפל באפס מקלקל לנו את זה, כי אפס כפול כל דבר שווה לאפס. לכן אם \(a=0\) נקבל ש-\(a\cdot x=0\) תמיד, לא משנה מהו \(x\), ולכן גם \(a\cdot x=a\cdot y\) מתקיים תמיד בלי תלות בטיב הקשר בין \(x,y\).&lt;/p&gt;

&lt;p&gt;עוד נקודה שאני רוצה לחדד טיפה היא שזה לא אסון אם מקבלים \(1=0\). זה לא &lt;strong&gt;בהכרח&lt;/strong&gt; אומר שהגענו לסתירה במתמטיקה, אלא שהגענו למשהו שנראה כמו סתירה להנחות שלנו ולכן קרוב לודאי שאחת מהן לא נכונה. הרי את ה”תרגיל” למעלה היה אפשר להתחיל מהשורה הלפני אחרונה:&lt;/p&gt;

&lt;p&gt;\(x+5=x+4\)&lt;/p&gt;

&lt;p&gt;שממנה אכן ניתן להסיק, על ידי חיסור \(x+4\) משני האגפים (פעולה שמשמרת פתרונות), ש-\(1=0\). עכשיו, את \(1=0\) לא צריך לקרוא בתור “סתירה במתמטיקה!!!!! אההההה!!!!!” אלא בתור “משוואה שלא קיים לה פתרון” - כלומר, זו “משוואה” שבה לא משנה אילו ערכים נציב ב”נעלמים”, הם לא יהפכו את המשוואה לנכונה (מכיוון שפשוט &lt;strong&gt;אין בה נעלמים&lt;/strong&gt;). המסקנה היא שגם למשוואה הקודמת, \(x+5=x+4\) לא היה פתרון, בגלל תכונת “שימור הפתרונות” שהזכרתי; ש&lt;strong&gt;אם &lt;/strong&gt;המשוואה \(x+5=x+4\) הייתה פתירה, אז גם \(1=0\) הייתה פתירה.&lt;/p&gt;

&lt;p&gt;במקרה של סדרת המשוואות למעלה, ה”סתירה” מתקבלת מכך שהתחלנו ממשהו שנראה לגיטימי ופתיר - \(x=3\) - ואיכשהו “איבדנו” את הפתרון הזה בדרך; וזה התרחש בגלל המעבר הלא חוקי שתיארתי, כי אם \(x=3\) אז \(x-3=0\) ולכן הצמצום בשורה&lt;/p&gt;

&lt;p&gt;\(\left(x-3\right)\left(x+5\right)=\left(x-3\right)\left(x+4\right)\)&lt;/p&gt;

&lt;p&gt;הוא בדיוק צמצום של אפס-כפול-משהו.&lt;/p&gt;

&lt;p&gt;כשפותרים משוואות בעולם האמיתי, כשמבצעים צמצום כזה מתבצעת &lt;strong&gt;חלוקה למקרים&lt;/strong&gt;. מוסיפים את ההנחה שמה שמצמצמים בו שונה מאפס וממשיכים לפתור עם זה, ומטפלים במקרה שבו הוא שווה אפס בנפרד. כלומר, פתרון תקין לתרגיל היה מגיע אל “&lt;strong&gt;או&lt;/strong&gt; ש-\(x=3\) והוא פתרון של המשוואה, &lt;strong&gt;או&lt;/strong&gt; ש-\(x\ne3\) ובמקרה זה אין פתרון למשוואה” שהוא כמובן תקין. בקיצור, קשה מאוד למצוא סתירה כלשהי במתמטיקה עם התרגיל הזה (מפתיע!)&lt;/p&gt;

&lt;p&gt;בדיון שבו פורסם הטקסט הזה, האם לא העירו שיש חלוקה באפס? כמובן שהעירו. התשובה הייתה מעניינת: שאין פה חלוקה ב-0 אלא “חלוקה בפולינום \(x-3\)”, שזה… נכון? זה באמת מה שקורה פה, אם כי כמובן שזה לא משפיע על הבעיה בתרגיל. אני רוצה לחדד את הנקודה הזו כי היא מעניינת.&lt;/p&gt;

&lt;p&gt;כשאנחנו פותרים משוואות עם נעלמים אנחנו בדרך כלל משחקים משחק “נדמה לי”. אנחנו אומרים “נניח ש-\(x\) הוא מספר קונקרטי שפותר את המשוואה, אנחנו פשוט עדיין לא יודעים מה הוא אז אנחנו כותבים אות במקומו. אבל כל המניפולציות שאנחנו עושים הן מניפולציות שעושים עם מספרים”. כל זה נכון ותקין לחלוטין, אבל בשלב כלשהו בהיסטוריה של האלגברה, המתמטיקאים החליטו שיהיה מעניין גם לאמץ נקודת מבט &lt;strong&gt;נוספת&lt;/strong&gt; על זה, ולחשוב על יצורים כמו \(x^{2}+2x-15\) - מה שנקרא &lt;strong&gt;פולינומים&lt;/strong&gt; - בתור אובייקטים אלגבריים בפני עצמם (&lt;a href=&quot;https://gadial.net/2018/03/29/polynomial_rings/&quot;&gt;הנה פוסט שלם&lt;/a&gt; בנושא למי שלא רוצים להסתפק במה שאכתוב כאן). מה זה “אובייקט אלגברי”? זה משהו שאפשר להגדיר עליו כללי חשבון עם כפל וחיבור וכדומה שמקיימים תכונות נחמדות כמו חוקי החילוף והפילוג וכדומה. בדרך ההתבוננות הזו, \(x^{2}+2x-15\) הוא פשוט דרך כתיבה “מעניינת” לסדרת המספרים \(\left(1,2,-15\right)\) (סדרת &lt;strong&gt;המקדמים&lt;/strong&gt; של הפולינום). זו חשיבה קצת שונה מהחשיבה שפולינום הוא בסך הכל כתיב מקוצר לתרגיל כלשהו (“לוקחים מספר, מעלים אותו בריבוע, מוסיפים לו את עצמו פעמיים ומחסרים 15 מהתוצאה”).&lt;/p&gt;

&lt;p&gt;חיבור של פולינומים הוא פשוט חיבור של שתי סדרות המספרים שמגדירות אותם, “איבר איבר”. הנה דוגמא: לפולינום \(x^{2}+2x-15\) אני אחבר את הפולינום \(x+5\). כדי לעשות את זה, אני יכול לכתוב את שני הפולינומים הללו בתור סדרות מקדמים: \(\left(1,2,-15\right)\) ו-\(\left(0,1,5\right)\). עכשיו אני יכול לחבר את שתי הסדרות:&lt;/p&gt;

&lt;p&gt;\(\left(1,2,-15\right)+\left(0,1,5\right)=\left(1+0,2+1,-15+5\right)=\left(1,3,-10\right)\)&lt;/p&gt;

&lt;p&gt;קיבלתי את הפולינום \(x^{2}+3x-10\). עכשיו, בשביל מה כל זה היה טוב? למה לא פשוט חיברתי “כרגיל” תוך שימוש בזה ש-\(2x+x=3x\) וכדומה? כי כך הדגמתי שאפשר לדבר על הפולינומים הללו בלי להזדקק בכלל לדיבורים על \(x\), שהוא לכאורה מה שלשמו נתכנסנו פה - ה”נעלם” שלנו. אולי עכשיו מתעוררת בכם שאלה אחרת - אם אפשר פשוט לדבר על סדרות של מספרים, למה לא מדברים עליהן וזהו ובמקום זה משתמשים בכתיב עם \(x\)? אה, טוב ששאלתם - כי &lt;strong&gt;הכפל&lt;/strong&gt; הוא פעולה מעניינת יותר מאשר “איבר איבר”, ויותר קל להבין אותה כשיש איקס מול העיניים.&lt;/p&gt;

&lt;p&gt;בואו נראה דוגמא פשוטה: הפולינומים \(x-3\) ו-\(x+5\). אני רוצה לכפול אותם; בתור סדרות הם \(\left(1,5\right)\) ו-\(\left(1,-3\right)\) וכפל “איבר איבר” של הסדרות הללו נותן \(\left(1,-15\right)\) כלומר את \(x-15\), אבל זה לא מתאים למה שאנחנו חושבים עליו כשכופלים פולינומים:&lt;/p&gt;

&lt;p&gt;\(\left(x+5\right)\left(x-3\right)=x^{2}+5x-3x-15=x^{2}+2x-15\)&lt;/p&gt;

&lt;p&gt;מה קרה פה? קיבלנו פולינום &lt;strong&gt;ממעלה גבוהה יותר&lt;/strong&gt; מזו של אלו שהכפלנו - יצרנו סדרת מקדמים &lt;strong&gt;ארוכה יותר&lt;/strong&gt;, וזה משהו שכפל “איבר איבר” לא יכול לבצע בכלל. ומאיפה הגיע ה-\(2x\) הזה, הרי בסדרת המקדמים המקורית אין שום דבר שמזכיר את 2? הוא הגיע מהחישוב היחסית מסובך \(1\cdot5+\left(-3\right)\cdot1\) שבו כפלנו את המקדם &lt;strong&gt;השני&lt;/strong&gt; באחד הפולינומים במקדם &lt;strong&gt;הראשון&lt;/strong&gt; בפולינום השני, ואת הסמטוחה הזו חיברנו אל המקדם &lt;strong&gt;הראשון&lt;/strong&gt; בפולינום הראשון שמוכפל במקדם &lt;strong&gt;השני&lt;/strong&gt; בפולינום השני… יש כאן פעולה שנקראת &lt;strong&gt;קונבולוציה&lt;/strong&gt; של סדרות, שהיא פעולה הרבה יותר מתוחכמת מאשר “כפל איבר איבר”. נשמע מפחיד? לא הבנתם איך זה עובד? לא נורא! אתם כמו האדם שדיבר פרוזה כל ימיו ולא ידע זאת; אם אתם יודעים לכפול פולינומים אתם יודעים לחשב קונבולוציות (אם אתם מכירים מטריצות, הסיפור פה די דומה: אובייקט אלגברי “חדש” שבו פעולת החיבור היא “איבר-איבר” משעממת אבל פעולת הכפל היא מחוכמת ומכניסה אותנו לעולם חדש לגמרי).&lt;/p&gt;

&lt;p&gt;אם כן, פולינומים הם יצורים מתמטיים עצמאיים, עם פעולות חיבור וכפל משלהם, וגם סוג של פעולת חילוק - חלוקה עם שארית, כמו שיש במספרים שלמים (הדמיון לא מקרי; שלמים ופולינומים הם דוגמאות מרכזיות למשהו שנקרא &lt;strong&gt;תחומים אוקלידיים&lt;/strong&gt; ו&lt;a href=&quot;https://gadial.net/2018/03/01/euclidean_domains_and_pids/&quot;&gt;כתבתי עליו פעם פוסט&lt;/a&gt;). בגישה הזו, אם יש לי את המשוואה&lt;/p&gt;

&lt;p&gt;\(\left(x-3\right)p\left(x\right)=\left(x-3\right)q\left(x\right)\)&lt;/p&gt;

&lt;p&gt;שמתארת שוויון בין שני פולינומים, אז בהחלט &lt;strong&gt;אפשר&lt;/strong&gt; לחלק ב-\(x-3\), וזו בהחלט &lt;strong&gt;לא&lt;/strong&gt; חלוקה באפס, ולכן בהחלט &lt;strong&gt;כן&lt;/strong&gt; מקבלים \(p\left(x\right)=q\left(x\right)\). אז למה \(x+5=x+4\) עדיין לא מתקיים?&lt;/p&gt;

&lt;p&gt;ובכן, כי בפולינומים השוויון \(x=3\) שפתח את כל הסיפור הזה &lt;strong&gt;לא מתקיים&lt;/strong&gt;. בתור פולינומים, יש לנו בשני האגפים יצורים שונים: באגף שמאל הפולינום \(\left(1,0\right)\) ובאגף ימין הפולינום \(\left(3\right)\). אלו סדרות מקדמים מאורכים שונים, עם ערכים שונים בתוכן. ברור שאין קשר. המשמעות &lt;strong&gt;האינטואיטיבית&lt;/strong&gt; שיש לנו, של “\(x\) הוא נעלם שאנחנו מציבים בו 3” לא קיימת אוטומטית כשמדברים על פולינומים. לכן התשובה “לא חילקתי באפס, חילקתי ב-\(x-3\)” רק מקלקלת את הטיעון עוד יותר, כי היא מצביעה על הונאה &lt;strong&gt;כבר בשורה הראשונה&lt;/strong&gt; של התרגיל.&lt;/p&gt;

&lt;p&gt;אפשר לחפור אפילו יותר עמוק כאן אם רוצים. האמת היא שמתמטיקאים בהחלט &lt;strong&gt;רוצים&lt;/strong&gt; לפעמים לבצע חשבון של פולינומים תחת ההנחה הנוספת ש-\(x=3\). בשביל זה הם עוברים לדבר על משהו שנקרא &lt;strong&gt;חוג מנה&lt;/strong&gt; של פולינומים. בלי להיכנס יותר מדי להגדרות (&lt;a href=&quot;https://gadial.net/2017/12/26/ideals_of_rings/&quot;&gt;הנה פוסט בנושא&lt;/a&gt; אם כן רוצים הגדרות), הרעיון בחוג מנה שבו \(x=3\) הוא פשוט: פעולות החיבור והכפל של הפולינומים יהיו זהות לאלו שהצגתי קודם, למעט זה שאחרי שמבצעים אותם, מחלקים את התוצאה בפולינום \(x-3\) ולוקחים רק את השארית. בחוג מנה כזה, הפולינום \(x-3\) הוא &lt;strong&gt;שקול לאפס&lt;/strong&gt; (כלומר, ביצוע חשבון איתו נותן את אותה תוצאה כמו ביצוע חשבון עם אפס) ולכן כמו קודם, אי אפשר לצמצם בו ואנחנו חוזרים לטיעון שהתחלנו איתו. אי אפשר להתחמק מזה - גם כשהולכים למתמטיקה גבוהה יותר מהתיכונית, אנחנו עדיין רואים שהמתמטיקאים נזהרו מאוד &lt;strong&gt;לא&lt;/strong&gt; ליצור סתירות שעליהן הם מתבססים.&lt;/p&gt;

&lt;p&gt;אגב, אם כבר הגעתי לכאן, אני רוצה להזכיר חוג מנה חביב במיוחד של פולינומים: זה שמתקבל על ידי חלוקה ב-\(x^{2}+1\). אפשר לחשוב על איבר כללי בחוג הזה בתור פולינום מהצורה \(a+bx\). בואו נכפול בשביל הכיף את \(x\) עם עצמו: נקבל \(x^{2}\), שאם מחלקים אותו ב-\(x^{2}+1\) עם שארית מקבלים את השארית \(-1\). כלומר בחוג הפולינומים הזה מתקיימת המשוואה \(x^{2}=-1\). עכשיו בואו נשתמש בסימון קצת שונה: במקום \(x\) נכתוב \(i\). קיבלנו חוג פולינומים שכל איבר בו הוא מהצורה \(a+bi\) כאשר \(i\) מקיים \(i^{2}=-1\); החוג הזה נקרא &lt;strong&gt;המספרים המרוכבים&lt;/strong&gt; והוא אחת מקבוצות המספרים המעניינות והחשובות במתמטיקה. וזו הדרך הפורמלית הטובה ביותר להגדיר אותה שאני מכיר (&lt;a href=&quot;https://gadial.net/2018/04/03/field_extensions_intro/&quot;&gt;הנה פוסט&lt;/a&gt; שמרחיב על זה).&lt;/p&gt;

&lt;p&gt;ועוד הערה אם אני כבר כאן - אפשר לדבר על חוגי מנה גם בהקשרים אחרים, למשל של שלמים, ואתם כבר מכירים חוגי מנה שכאלו - המפורסם שבהם הוא מה שקורה בשעון. אנחנו חושבים על השעות בשעון בתור המספרים מ-0 עד 23, כאשר 24 זה כבר “שוב פעם 0”. אם השעה היא 18 ואנחנו שואלים מה תהיה השעה עוד עשר שעות, אנחנו מחשבים \(18+10=28\) ואז מחסרים 24 מהתוצאה - כלומר, מחלקים ב-24 ולוקחים את השארית, 4. זה נקרא &lt;strong&gt;חשבון מודולו &lt;/strong&gt;&lt;strong&gt;24&lt;/strong&gt; (&lt;a href=&quot;https://gadial.net/2013/05/13/modular_arithmetic/&quot;&gt;הנה פוסט שלי&lt;/a&gt; על חשבון מודולרי). חשבון כזה יכול להיות טריקי יותר מחשבון “רגיל”: למשל, \(4\cdot6=0\) בחשבון הזה. למספרים כאלו ששונים מאפס אבל המכפלה שלהם עדיין יוצאת אפס קוראים &lt;strong&gt;מחלקי אפס&lt;/strong&gt;, והם עוד דוגמא למספרים &lt;strong&gt;שלא מקיימים את כלל הצמצום&lt;/strong&gt;. למשל, אם יש לי את המשוואה&lt;/p&gt;

&lt;p&gt;\(4x=4y\)&lt;/p&gt;

&lt;p&gt;כשהמשוואה הזו היא מודולו 24, אני לא יכול להסיק ש-\(x=y\). הנה דוגמא נגדית: \(x=4,y=10\). אלו שני מספרים ששניהם קטנים מ-24 (כלומר, הם לא שקולים מודולו 24 וצריכים להיחשב “אותו דבר”) אבל המכפלה של שניהם ב-4 מניבה 16. שימו לב שאני פדנט ומתעקש לא לדבר על “אסור לחלק ב-4” אלא אומר משהו יותר בסיסי, שאסור &lt;strong&gt;לצמצם&lt;/strong&gt; את 4 משני האגפים - הסיבה לכך היא שיש חוגים במתמטיקה שבהם אין משמעות ל”חלוקה” באיבר אבל עדיין אפשר לדבר על היכולת לצמצם אותו משני האגפים.&lt;/p&gt;

&lt;p&gt;זה מסיים את ההתייחסות הפרטנית שלי ל”כשל” שאיתו פתחתי. עדיין נשארו לנו כמה שאלות. הראשונה, מאיפה הוא הגיע בכלל. דברים כאלו בדרך כלל מופצים באינטרנט הרחב הרבה לפני שהם מעוברתים ומגיעים אלינו. במקרה הנוכחי אין לי מושג מה המקור. כמובן, תעלולים שמערבים חלוקה באפס כדי להגיע ל”סתירה” הם עתיקי יומין ורואים אחד כזה כל כמה חודשים, אבל את האחד הספציפי הזה? עוד לא ראיתי. והסיפור עם ניוטון ו-1704? הוא חדש לי לגמרי. מאיפה הגיעה השנה 1704 דווקא? ניסיתי להתחקות על עקבות הסיפור הזה באינטרנט בעזרת מספר הקסם 1704 וחברים אבל לא מצאתי כלום. אולי אתם תצליחו יותר ממני? לפעמים סיפורים כאלו מובילים לספרים של ממש, כאלו שאפשר למצוא בחנויות וכתבו אנשים מכובדים ומהוגנים ומשלמים עבורם כסף, ואז הבידור גדול שבעתיים.&lt;/p&gt;

&lt;p&gt;זה משאיר לנו רק את השאלה האחרונה - האם כל המתמטיקה אכן מבוססת על כשלים לוגיים? כמובן, לא הכשל הלוגי &lt;strong&gt;הזה&lt;/strong&gt; עם ה-\(1=0\) שהוסק בצורה שגויה, אבל האם יש לנו הוכחה שהמתמטיקה נמצאת על בסיס יציב וחף מכשלים?&lt;/p&gt;

&lt;p&gt;התשובה היא שאנחנו &lt;strong&gt;מאמינים&lt;/strong&gt; שהמתמטיקה כיום חפה מכשלים כאלו, אבל אין לנו &lt;strong&gt;הוכחה משכנעת&lt;/strong&gt; לכך, וכרגע נראה שהוכחה כזו &lt;strong&gt;לעולם לא תתקיים&lt;/strong&gt;. הייתה תקופה בתולדות המתמטיקה שבה הבעיה הזו נראתה אקוטית הרבה יותר מאשר היום - שיא התקופה הזו היה בתחילת המאה ה-20, כאשר בבסיס של המתמטיקה דאז &lt;strong&gt;באמת&lt;/strong&gt; התגלו סתירות ונדרשה עבודת תיקון לא מעטה בשביל להתגבר עליהן. האופטימיות של התקופה גרמה למתמטיקאים לקוות שאפשר יהיה להתגבר עליהן “אחת ולתמיד” - למצוא ביסוס למתמטיקה שדורש הנחות יסוד &lt;strong&gt;מאוד פשוטות&lt;/strong&gt;, שיהיה “ברור מאליו” שהן נכונות ואפשר יהיה להוכיח שלא יכולות להוביל לסתירות. השאיפה הזו נקראת &lt;strong&gt;התוכנית של הילברט&lt;/strong&gt; והיא… נכשלה. לא במובן זה שנמצאו סתירות במתמטיקה, אלא במובן זה שנמצאה הוכחה - “&lt;strong&gt;משפט אי השלמות השני של גדל&lt;/strong&gt;” - שאי אפשר יהיה לתת בסיס פשוט שכזה והוכחות של ממש ש”המתמטיקה נטולת סתירות” ייאלצו להיות מסובכות ועם הנחות לא מוכחות משל עצמן. שימו לב לנקודה העדינה פה: זה שאי אפשר להוכיח שאין סתירות במתמטיקה &lt;strong&gt;לא אומר&lt;/strong&gt; שיש סתירות במתמטיקה; זה רק אומר שזו טענה שאין לנו דרך להוכיח בצורה “פשוטה”. יש טענות מתמטיות רבות אחרות שאין דרך להוכיח בצורה “פשוטה”; למעשה, משפט אי השלמות &lt;strong&gt;הראשון&lt;/strong&gt; של גדל נותן לנו דרך שיטתית לבנות טענות כאלו, ובהתבסס עליו אפשר להוכיח את המשפט השני. &lt;a href=&quot;https://gadial.net/2009/05/03/godel_incompleteness_yes/&quot;&gt;יש לי פוסט&lt;/a&gt; על משפטי גדל, אבל אם כל נושא היסודות הרעועים-כן-או-לא של המתמטיקה מעניין אתכם, אני ממליץ על הספר “משפטי גדל ובעיית היסודות של המתמטיקה” של ארנון אברון שמכסה את הנושא בצורה בהירה ומעניינת מאוד.&lt;/p&gt;

&lt;p&gt;ולאלו שעדיין מחפשים “סתירות” במתמטיקה - למה אתם עושים את זה בעצם? למה לשחק עם משוואות טיפשיות כשאתם יכולים לשחק עם דברים מגניבים כמו &lt;a href=&quot;https://gadial.net/2010/05/02/congruent_numbers_and_elliptic_curves/&quot;&gt;עקומים אליפטיים&lt;/a&gt;? המתמטיקה מגניבה. אל תחפשו בה סתירות אלא כיף! תתעוררו, אנשים!&lt;/p&gt;</content><author><name></name></author><category term="חוגי פולינומים" /><category term="סתירות לוגיות במתמטיקה" /><summary type="html">להיט עכשיו בפייסבוק העברי הוא צילום המסך הזה של פוסט שלא חשוב על ידי מי נכתב, כי הוא מופץ במטרה ללעוג לכותב:</summary></entry><entry><title type="html">בעיית איסוף הקופונים</title><link href="http://localhost:4000/blog/2019/02/13/coupon_collector_problem" rel="alternate" type="text/html" title="בעיית איסוף הקופונים" /><published>2019-02-13T16:34:18+02:00</published><updated>2019-02-13T16:34:18+02:00</updated><id>http://localhost:4000/blog/2019/02/13/coupon_collector_problem</id><content type="html" xml:base="http://localhost:4000/blog/2019/02/13/coupon_collector_problem">&lt;p&gt;הנה לכם סיפור על איך בעיות מתמטיות צצות מעצמן. זה לא מכבר יצא לאוויר העולם משחק הוידאו Super Smash Bros. Ultimate שהוא נצר לשושלת ארוכה ומפוארת של משחקי מכות שמאחדים דמויות משלל משחקים בלתי קשורים בעליל על מנת שירביצו אחד לשני באווירה של כאוס מוחלט בשלל זירות שונות ומשונות שנלקחות גם כן משלל משחקים בלתי קשורים בעליל. המשחק הנוכחי החליט לקחת את המופרכות הזו לשיאים חדשים על ידי כך שיאגד את כל הדמויות והזירות מכל המשחקים שיצאו עד כה בסדרה, ויוסיף עוד. כתוצאה מכך יש לא פחות מ-103 זירות במשחק. מסך בחירת הזירות נראה כך:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3748&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/02/gw44pdhlx3i11.png&quot; alt=&quot;&quot; width=&quot;1600&quot; height=&quot;900&quot; /&gt;&lt;/p&gt;

&lt;p&gt;עם כל כך הרבה זירות, למי יש זמן לבחור בכלל? אני תמיד בוחר בסימן השאלה למעלה שבוחר אחת מ-103 הזירות באקראי, כך שיש הסתברות שווה לכל אחת מהזירות. והנה שמתי לב שגם עכשיו, אחרי חודשיים של משחק, עדיין קורה שאני משחק בזירה שאני לא זוכר שראיתי קודם. זה העלה אצלי את השאלה הבאה: תוך כמה סיבובים של המשחק אפשר לראות את כל הזירות?&lt;/p&gt;

&lt;p&gt;ובכן, זו שאלה מוכרת בתורת ההסתברות שנקראת “בעיית איסוף הקופונים” (שם שלא הכרתי עד עכשיו). הרעיון אצל איסוף הקופונים דומה: נניח שחברת דגני בוקר יוצאת במבצע שבו בכל אריזה שלה יש קופון שנבחר באקראי מבין כמה אפשריים, ומי שאוסף את כל הקופונים זוכה בפרס - כמה אריזות דגנים צריך לקנות? כמובן, בניסוח הזה של הבעיה צריך לחדד את העובדה שלכל קופון יש הסתברות שווה להופיע; אם זה לא המצב, אז הניתוח המתמטי מסובך בהרבה, מעבר למה שאני רוצה לכסות בפוסט הזה.&lt;/p&gt;

&lt;p&gt;בואו נתמודד עם בעיית הזירות האקראיות שלי; בשלב הראשון האתגר יהיה בכלל לנסח את השאלה בצורה נכונה. מה שברור מייד הוא שצריך &lt;strong&gt;לפחות&lt;/strong&gt; 103 סיבובים של המשחק כדי לראות את כל הזירות. אם הייתי עובר על הזירות באופן שיטתי, זה גם כל מה שהייתי צריך; אבל אני מפקיד את השליטה בידי הגורל העיוור שמגריל לי זירה בכל פעם, ולכן בהחלט ייתכן שלא משנה כמה משחקים אשחק, &lt;strong&gt;תהיה זירה שלא אראה אף פעם&lt;/strong&gt;. היא פשוט אף פעם לא תעלה בגורל. ההסתברות לכך היא אפסית ובהמשך נראה שהיא לא באמת משפיעה על החישוב, אבל לא חייבים ללכת לקיצוניות: נניח שב-102 הסיבובים הראשונים באמת ראיתי זירה חדשה בכל פעם, ואז במשחק ה-103 פתאום הוגרלה זירה שכבר ראיתי. זה כבר אומר שבמקרה הזה, אזדקק לפחות ל-104 סיבובים. אז מספר &lt;strong&gt;מדויק&lt;/strong&gt; לא הולך לענות לשאלה שלי, כי מספר הסיבובים תלוי במזל שלנו. השאלה המדויקת יותר היא מה יהיה &lt;strong&gt;מספר הסיבובים הממוצע&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;למה אני מתכוון בממוצע? נניח שניתן ל-10,000 שחקנים לשחק במשחק ולספר לנו כמה סיבובים חלפו עד שהם ראו את כל הזירות, ואז ניקח את הממוצע החשבוני של התוצאות הללו - כלומר, נחבר את כולן ונחלק במספר השחקנים, שהוא 10,000: מה המספר שנקבל אז? על פי רוב נקבל מספרים שהם כמעט זהים; &lt;strong&gt;חוק המספרים הגדולים&lt;/strong&gt; בהסתברות מבטיח לנו את זה.&lt;/p&gt;

&lt;p&gt;כמובן, אין טעם באמת לתת לשחקנים לשחק; אפשר לעשות משהו מהיר יותר - סימולציה במחשב. אז הנה קוד בשפת פייתון שעושה בדיוק את זה:&lt;/p&gt;

&lt;p&gt;[python]
import random&lt;/p&gt;

&lt;p&gt;def experiment(n):
    visited = [False] * n
    visited_count = 0
    rounds = 0
    while visited_count &amp;lt; n:
        rounds += 1
        i = random.randrange(n)
        if not visited[i]:
            visited[i] = True
            visited_count += 1         &lt;br /&gt;
    return rounds&lt;/p&gt;

&lt;p&gt;tries = 10000
N = 103
total = 0
for i in range(tries):
    total += experiment(N)
print(total / tries)
[/python]&lt;/p&gt;

&lt;p&gt;כשהרצתי את הקוד לקח לו רגע לסיים ובסוף קיבלתי את התוצאה \(535.3524\). בהרצה נוספת קיבלתי \(540.0647\). זה כבר מעורר את החשד ש-10,000 זה לא מספיק ואולי עדיף 100,000 הרצות בשביל תוצאה מדויקת יותר. אז הרצתי גם 100,000 פעמים, זה לקח יותר זמן וקיבלתי \(537.58746\). האם אפשר יותר מדויק, יותר מהר? ובכן, כן! אם נכניס לתמונה את תורת ההסתברות. כמו כן, כדי לפשט לעצמנו קצת את החיים נפסיק לדבר על המספר 103 דווקא ונדבר על מספר \(N\) כללי.&lt;/p&gt;

&lt;p&gt;יש לי &lt;a href=&quot;https://gadial.net/2010/07/29/probability_intro/&quot;&gt;פוסטים מפורטים יותר&lt;/a&gt; בבלוג על תורת ההסתברות כך שלא אחזור על כל הפרטים כעת, אבל הנה הרעיון. כשאנחנו באים למדל משהו באמצעות תורת ההסתברות אנחנו קודם כל מגדירים &lt;strong&gt;מרחב מדגם&lt;/strong&gt; שכולל את כל התוצאות האפשריות של ההגרלה שאנחנו מבצעים. במקרה הנוכחי אפשר לחשוב על הסיטואציה כאילו אנחנו מגרילים סדרה של זירות (שיכולה להיות סופית או אינסופית), כך שכל סדרה מסתיימת אחרי שכל זירה הופיעה לפחות פעם אחת. סדרה אינסופית מצביעה על כישלון - שיש זירה אחת לפחות שלא נראתה אף פעם. אפשר להראות שההסתברות של סדרה אינסופית שכזו היא אפס; זה לא אומר שאין סיכוי שהיא תופיע, רק שהסיכוי הזה &lt;strong&gt;זניח&lt;/strong&gt; (הסבר מלא יותר יצטרך להיכנס לעובי הקורה הטכני של מרחבי הסתברות רציפים).&lt;/p&gt;

&lt;p&gt;עכשיו אפשר להגדיר על מרחב ההסתברות שלנו &lt;strong&gt;משתנה מקרי&lt;/strong&gt;. משתנה מקרי זו פונקציה שלוקחת תוצאה ממרחב המדגם ומחזירה ערך מספרי כלשהו שהיא מסמלת - במקרה הזה, אפשר להתאים לכל סדרה פשוט את האורך שלה. נסמן את המשתנה המקרי הזה ב-\(X\). עכשיו אפשר לשאול שאלה כמו “מה ההסתברות שאם נגריל סדרה כלשהי, הערך של \(X\) יהיה לפחות 17?”. ואפשר גם לשאול מה יהיה הערך &lt;strong&gt;הממוצע&lt;/strong&gt; של \(X\). בתורת ההסתברות קוראים לערך ממוצע כזה &lt;strong&gt;התוחלת&lt;/strong&gt; של \(X\), מסמנים אותו ב-\(E\left[X\right]\) והוא מוגדר ככה: \(E\left[X\right]=\sum_{a}a\cdot\text{P}\left(X=a\right)\), כלומר - זה סכום משוקלל של כל הערכים \(a\) שהמשתנה המקרי עשוי להחזיר, כשהמשקל של כל \(a\) כזה הוא ההסתברות ש-\(X\) יחזיר אותו.&lt;/p&gt;

&lt;p&gt;מה שאני רוצה לעשות מכאן והלאה הוא לחשב את \(E\left[X\right]\) עבור בעיית הקופונים שלנו. לצורך כך אני אעזר בתכונה מועילה במיוחד: &lt;strong&gt;לינאריות התוחלת&lt;/strong&gt;. מה שלינאריות התוחלת אומרת הוא פשוט מאוד: \(E\left[X+Y\right]=E\left[X\right]+E\left[Y\right]\). כלומר: אם יש לנו שני משתנים מקריים, \(X,Y\), ואנחנו בונים משתנה מקרי חדש שהוא סכום של שניהם (כלומר: לכל איבר במרחב המדגם הוא מפעיל את \(X,Y\) על האיבר הזה, מקבל תוצאות ומחבר אותן) אז התוחלת של המשתנה החדש תהיה הסכום של התוחלות של המשתנים. ההוכחה של לינאריות התוחלת לא קשה, אבל לא אציג אותה כאן.&lt;/p&gt;

&lt;p&gt;איך זה עוזר לנו? ראשית, אם זה עובד לשני משתנים, זה עובד לכל מספר סופי של משתנים: אם \(X=X_{1}+X_{2}+\dots+X_{N}\) אז \(E\left[X\right]=E\left[X_{1}\right]+E\left[X_{2}\right]+\dots+E\left[X_{N}\right]\). שנית, אני טוען שאת ה-\(X\) שלנו של בעיית הקופונים אכן אפשר להציג בתור סכום שכזה. הרעיון? המשתנה \(X_{i}\) סופר את מספר הסיבובים שנדרשו כדי להעלות את מספר הזירות שראינו עד כה מ-\(i-1\) אל \(i\).&lt;/p&gt;

&lt;p&gt;בצורה הזו ברור ש-\(X\) הוא אכן הסכום המבוקש: \(X\) הוא מספר הסיבובים הכולל שנדרש כדי להעלות את מספר הזירות שראינו מ-0 אל \(N\); זה שווה לזמן שנדרש כדי לעלות מ-0 אל 1, ועוד הזמן שנדרש לעלות מ-1 אל 2 וכן הלאה עד אשר הגענו מ-\(N-1\) אל \(N\).&lt;/p&gt;

&lt;p&gt;כל מה שנותר לעשות הוא לחשב את \(E\left[X_{i}\right]\) - תוחלת הזמן שנדרשת כדי להעלות את מספר הזירות שראינו כבר מ-\(i-1\) אל \(i\). אלא שאת זה קל לעשות כי \(X_{i}\) הוא &lt;strong&gt;משתנה גאומטרי&lt;/strong&gt;, וזה מושג מוכר ואהוב מתורת ההסתברות. משתנה גאומטרי מתעסק בשאלה “אם מטילים שוב ושוב את אותה הקוביה, כמה זמן יעבור עד שנקבל 1”? באופן כללי יותר, משתנה גאומטרי מדבר על הסיטואציה שבה יש ניסוי עם הסתברות \(p\) להצליח, ואנחנו חוזרים עליו שוב ושוב עד אשר הוא מצליח וסופרים כמה נסיונות נדרשו לנו.&lt;/p&gt;

&lt;p&gt;את התוחלת של הדבר הזה אפשר לחשב בעזרת הנוסחה \(E\left[X\right]=\sum_{a}a\cdot\text{P}\left(X=a\right)\) והיכרות כלשהי עם סכומים אינסופיים. ההוכחה תהיה קצת טכנית ואפשר לדלג עליה מבלי לפגוע בהמשך הפוסט.&lt;/p&gt;

&lt;p&gt;\(\text{P}\left(X=1\right)\) הוא \(p\) (ההסתברות שנצליח בניסוי הראשון).&lt;/p&gt;

&lt;p&gt;\(\text{P}\left(X=2\right)\) הוא \(\left(1-p\right)p\) (ההסתברות &lt;strong&gt;שניכשל&lt;/strong&gt; בניסוי הראשון - זה ה-\(\left(1-p\right)\) - כפול ההסתברות שנצליח בניסוי השני).&lt;/p&gt;

&lt;p&gt;\(\text{P}\left(X=3\right)\) הוא \(\left(1-p\right)^{2}p\) ומכאן כבר אפשר לראות את הכיוון הכללי:&lt;/p&gt;

&lt;p&gt;\(E\left[X\right]=\sum_{n=1}^{\infty}n\text{P}\left[X=n\right]=\sum_{n=1}^{\infty}n\cdot p\cdot\left(1-p\right)^{n-1}=p\sum_{n=1}^{\infty}n\left(1-p\right)^{n-1}\)&lt;/p&gt;

&lt;p&gt;וכעת מגיע להטוט לא טריוויאלי. בואו נכתוב שוב את הטור שיש לנו, אבל עם סימונים קצת שונים:&lt;/p&gt;

&lt;p&gt;\(\sum_{n=1}^{\infty}nx^{n-1}\)&lt;/p&gt;

&lt;p&gt;אלו מכם שמכירים חדו”א אולי מזהים שהאיבר שנמצא בתוך הטור נראה כמו &lt;strong&gt;נגזרת&lt;/strong&gt; לפי \(x\) של פונקציה. כלומר, אפשר לכתוב&lt;/p&gt;

&lt;p&gt;\(\sum_{n=1}^{\infty}nx^{n-1}=\sum_{n=1}^{\infty}\left(x^{n}\right)^{\prime}=\left(\sum_{n=1}^{\infty}x^{n}\right)^{\prime}\)&lt;/p&gt;

&lt;p&gt;המעבר האחרון, שבו “הוצאתי את הנגזרת החוצה מהסכום” הוא לא טריוויאלי ודורש הצדקות בחדו”א - אבל במקרה הזה, זה עובד. עכשיו מה שקיבלנו בתוך הסכום הוא &lt;strong&gt;טור גאומטרי&lt;/strong&gt; בסיסי שאנחנו יודעים את הנוסחה שלו:&lt;/p&gt;

&lt;p&gt;\(\sum_{n=1}^{\infty}x^{n}=\frac{x}{1-x}\)&lt;/p&gt;

&lt;p&gt;הנוסחה הזו עובדת רק עבור \(\left\|x\right\|&amp;lt;1\), אבל מכיוון שנציב \(x=1-p\) ואנחנו מניחים ש-\(p&amp;gt;0\) זו לא בעיה.&lt;/p&gt;

&lt;p&gt;לבסוף, צריך עדיין &lt;strong&gt;לגזור&lt;/strong&gt; את \(\frac{x}{1-x}\). הנגזרת יוצאת \(\frac{\left(1-x\right)+x}{\left(1-x\right)^{2}}=\frac{1}{\left(1-x\right)^{2}}\), וכשנציב \(x=1-p\) חזרה נקבל&lt;/p&gt;

&lt;p&gt;\(p\sum_{n=1}^{\infty}n\left(1-p\right)^{n-1}=\frac{p}{\left(1-\left(1-p\right)\right)^{2}}=\frac{p}{p^{2}}=\frac{1}{p}\)&lt;/p&gt;

&lt;p&gt;וכעת אפשר לחזור אל בעיית הקופונים שלנו. ראינו כבר ש-\(E\left[X\right]=E\left[X_{1}\right]+E\left[X_{2}\right]+\dots+E\left[X_{N}\right]\). נשאר רק להבין - לכל \(X_{i}\), מהו \(p\) שלו? מה ההסתברות להצליח?&lt;/p&gt;

&lt;p&gt;הניסוי של \(X_{i}\) מצליח אם אנחנו מעלים בגורל זירה חדשה שטרם עלתה בגורל. עד כה עלו בגורל \(i-1\) זירות, מה שאומר שנותרו עוד \(N-\left(i-1\right)\) זירות. מספר הזירות הכולל הוא \(N\), ולכן ההסתברות להעלות בגורל את אחת מהזירות החדשות היא \(\frac{N-\left(i-1\right)}{N}\). כלומר:&lt;/p&gt;

&lt;p&gt;\(E\left[X_{i}\right]=\frac{1}{p_{i}}=\frac{N}{N-\left(i-1\right)}\)&lt;/p&gt;

&lt;p&gt;כלומר:&lt;/p&gt;

&lt;p&gt;\(E\left[X_{1}\right]=\frac{N}{N}=1\)&lt;/p&gt;

&lt;p&gt;\(E\left[X_{2}\right]=\frac{N}{N-1}\)&lt;/p&gt;

&lt;p&gt;וכן הלאה עד \(E\left[X_{N}\right]=\frac{N}{N-\left(N-1\right)}=\frac{N}{1}\).&lt;/p&gt;

&lt;p&gt;וקיבלנו:&lt;/p&gt;

&lt;p&gt;\(E\left[X\right]=\sum_{i=0}^{N-1}\frac{N}{N-i}=N\sum_{i=0}^{N-1}\frac{1}{N-i}=N\sum_{i=1}^{N}\frac{1}{i}\)&lt;/p&gt;

&lt;p&gt;וכאן אנחנו פוגשים חברים ותיקים (של חלקנו…). הסכום \(\sum_{i=1}^{N}\frac{1}{i}\) (ובסימון אחר: \(1+\frac{1}{2}+\frac{1}{3}+\dots+\frac{1}{N}\)) הוא כל כך חשוב שהוא זוכה לאות מיוחדת משלו: \(H_{N}=\sum_{i=1}^{N}\frac{1}{i}\), והמספר הזה נקרא &lt;strong&gt;המספר ההרמוני&lt;/strong&gt; ה-\(N\)-י. אלו מספרים מוכרים ואהובים שצצים במתמטיקה בשלל הזדמנויות, כך שלומר שפתרון בעיית הקופונים הוא שתוחלת הזמן עבור \(N\) קופונים היא \(N\cdot H_{N}\) היא פתרון קביל בהחלט.&lt;/p&gt;

&lt;p&gt;אבל בואו ננסה לשכנע אתכם עוד קצת שזה אחלה פתרון.&lt;/p&gt;

&lt;p&gt;כזכור, התחלתי את הדיון עם סוגייה קונקרטית - כמה סיבובים של Super Smash Bros. Ultimate צריך בתוחלת כדי לראות את כל הזירות? ועוד לפני שהכנסתי את תורת ההסתברות לתמונה ניסיתי לתת תשובה “אמפירית” לשאלה הזו על ידי קוד שמבצע סימולציות ומחשב ממוצעים. הקוד הזה &lt;strong&gt;עובד&lt;/strong&gt;, אבל יש לו שני חסרונות ברורים:&lt;/p&gt;
&lt;ol&gt;
 	&lt;li&gt;לוקח לו הרבה זמן לרוץ, יחסית.&lt;/li&gt;
 	&lt;li&gt;התוצאה שהוא מחזיר היא &lt;strong&gt;קירוב&lt;/strong&gt; של התוחלת, לא הערך המדויק שלה.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;הנוסחה שמצאתי עכשיו, \(N\cdot H_{N}\), לא נותנת קירוב של התוחלת אלא את התוחלת עצמה, במדויק; אבל עוד יותר חשוב מכך, אפשר לחשב אותה &lt;strong&gt;מהר&lt;/strong&gt;, בשורה אחת של פייתון:&lt;/p&gt;

&lt;p&gt;[python]
print(N * sum(1 / k for k in range(1,N+1)))
[/python]&lt;/p&gt;

&lt;p&gt;השורה הזו מחזירה את המספר \(537.3294902186476\) שהוא התוחלת ה”נכונה”; אפשר לראות שתוצאת הניסוי שעשיתי קודם יצאה קרובה מאוד (537 ומשהו) אבל בשביל זה הייתי צריך להקפיץ את מספר החזרות על הניסוי מ-10,000 (שלא נתן משהו עד כדי כך מדויק) אל 100,000 וזה לקח הרבה יותר זמן. הפתרון המדויק שמצאתי הוא &lt;strong&gt;יעיל יותר לחישוב&lt;/strong&gt; ולכן טוב יותר. אני מדגיש את הנקודה הזו כי הפתרון הזה הוא לא “נוסחה סגורה” - יש בו סכום שתלוי ב-\(N\), ועשויה להיות רתיעה מסכומים כאלו למי שרגילים לתרגילים מקומבינטוריקה בסיסית שבהם לתת נוסחה שכזו לפעמים גורם להורדת נקודות כי זה לא פתרון פשוט “מספיק”. ובכן, אם אתם סובלים (כמו שאני סבלתי) מטראומה כזו מסכומים - אל! סכומים יכולים להיות מאוד מועילים לפעמים (ודוגמא טובה מאוד היא &lt;strong&gt;עקרון ההכלה וההפרדה&lt;/strong&gt; &lt;a href=&quot;https://gadial.net/2011/12/31/inclusion_exclusion_principle/&quot;&gt;שכתבתי עליו כבר פוסט&lt;/a&gt;, ומאפשר להמיר בעיות חישוביות קשות למדי במשימות חישוביות הרבה יותר קלות למרות שהוא מתבסס על סכום).&lt;/p&gt;

&lt;p&gt;אבל יש לנוסחה שהגענו אליה עוד יתרון - קיים לה &lt;strong&gt;קירוב&lt;/strong&gt; טוב מאוד, שנובע מכמה טוב אנחנו מבינים מספרים הרמוניים. אפשר להראות (אין לי מושג איך - צריך יהיה לכתוב על זה פעם פוסט!) שמספרים הרמוניים מתנהגים “בערך” כמו הלוגריתם הטבעי. קצת יותר בפירוט:&lt;/p&gt;

&lt;p&gt;\(H_{N}\approx\ln N+\gamma+\frac{1}{2N}\)&lt;/p&gt;

&lt;p&gt;כאשר \(\gamma=0.5772156649\dots\) נקרא &lt;strong&gt;קבוע אוילר-מסקרוני&lt;/strong&gt; והוא מספר מעניין בפני עצמו (למשל: עד היום אנחנו לא יודעים אם הוא רציונלי או לא).&lt;/p&gt;

&lt;p&gt;אם נכפיל את הנוסחה הזו ב-\(N\), נקבל את הקירוב הבא לבעיית הקופונים:&lt;/p&gt;

&lt;p&gt;\(N\ln N+\gamma N+\frac{1}{2}\)&lt;/p&gt;

&lt;p&gt;וזו נוסחה ש&lt;strong&gt;מאוד קל&lt;/strong&gt; לחשב ביעילות, גם אם הערך של \(N\) הוא אדיר (בן מאות ספרות - מה שמונע לגמרי חישוב של הסכום \(1+\frac{1}{2}+\dots+\frac{1}{N}\)). ככל ש-\(N\) גדול יותר כך הקירוב יהיה טוב יותר; עד כמה הוא טוב עבור \(N=103\)? ובכן, הבה וננסה:&lt;/p&gt;

&lt;p&gt;[python]
import numpy
gamma = 0.5772156649
print(N * numpy.log(N) + gamma * N + 1/2)
[/python]&lt;/p&gt;

&lt;p&gt;הקוד הזה, עבור \(N=103\), מניב את התוצאה \(537.3302992723525\) שהיא קרובה להפליא אל התוצאה המדויקת, והחישוב שלה כמובן מהיר יותר. אם אני אנסה להריץ את החישובים הקודמים עבור \(N=1000000000000000\) אני אכשל בצורה מזעזעת (הקוד ירוץ וירוץ ולעולם לא יסיים) אבל עם הקירוב הזה אני עדיין אקבל תוצאה תוך חלקיק שניה - ואני יודע שזו תהיה תוצאה שלא אוכל להבדיל בינה ובין התוצאה ה”אמיתית”.&lt;/p&gt;

&lt;p&gt;זה סוגר את בעיית הקופונים הבסיסית, אבל כמובן שמכאן והלאה המתמטיקאים משתוללים עם שלל וריאציות: מה אם לא כל קופון הוא בעל אותה הסתברות להיבחר? מה אם אנחנו לא קונים קופונים אלא מנסים להשלים את כל המדבקות באלבום של “חבורת הזבל” (כן! היה משהו כזה!) ובכל חבילת מדבקות שאנחנו קונים יש שש מדבקות ולא רק אחת? וכן הלאה וכן הלאה. אבל אני לא אתעסק בזה עכשיו ומקווה שתסלחו לי; יש לי 537 סיבובים של Super Smash Bros. Ultimate לשחק בהם.&lt;/p&gt;</content><author><name></name></author><category term="בעיית איסוף הקופונים" /><category term="הסתברות" /><category term="מספרים הרמוניים" /><category term="קבוע אוילר מסקרוני" /><summary type="html">הנה לכם סיפור על איך בעיות מתמטיות צצות מעצמן. זה לא מכבר יצא לאוויר העולם משחק הוידאו Super Smash Bros. Ultimate שהוא נצר לשושלת ארוכה ומפוארת של משחקי מכות שמאחדים דמויות משלל משחקים בלתי קשורים בעליל על מנת שירביצו אחד לשני באווירה של כאוס מוחלט בשלל זירות שונות ומשונות שנלקחות גם כן משלל משחקים בלתי קשורים בעליל. המשחק הנוכחי החליט לקחת את המופרכות הזו לשיאים חדשים על ידי כך שיאגד את כל הדמויות והזירות מכל המשחקים שיצאו עד כה בסדרה, ויוסיף עוד. כתוצאה מכך יש לא פחות מ-103 זירות במשחק. מסך בחירת הזירות נראה כך:</summary></entry><entry><title type="html">אז מה זה מחשב קוונטי?</title><link href="http://localhost:4000/blog/2019/02/11/what_is_quantum_computer" rel="alternate" type="text/html" title="אז מה זה מחשב קוונטי?" /><published>2019-02-11T17:09:19+02:00</published><updated>2019-02-11T17:09:19+02:00</updated><id>http://localhost:4000/blog/2019/02/11/what_is_quantum_computer</id><content type="html" xml:base="http://localhost:4000/blog/2019/02/11/what_is_quantum_computer">&lt;p&gt;בשנים האחרונות מחשבים קוונטיים עולים יותר ויותר לכותרות ואני רוצה בפוסט הזה להסביר על מה מדובר בצורה שגם מי שלא מכירים את התחום בכלל יוכלו להבין. כבר יש לי סדרת פוסטים בנושא שמתחילה &lt;a href=&quot;https://gadial.net/2014/07/17/quantum_computing_intro/&quot;&gt;כאן&lt;/a&gt; ונכנסת לפרטים הטכניים, אבל פה אני רוצה לתת סקירה כללית יותר, וגם להתייחס יותר להיבטים הפרקטיים של הנושא. אז מה זה מחשב קוונטי ובשביל מה צריך אותו?&lt;/p&gt;

&lt;p&gt;אם להצטמצם לפסקת מחץ אחת, אז מחשב קוונטי הוא מחשב שמתבסס על גישה ל&lt;strong&gt;ייצוג ועיבוד מידע&lt;/strong&gt; שהיא שונה &lt;strong&gt;דרסטית&lt;/strong&gt; מזו של מחשב רגיל, ומתבססת באופן ישיר על תופעות פיזיקליות שנופלות תחת המסגרת של &lt;strong&gt;תורת הקוונטים&lt;/strong&gt; בפיזיקה (ומכאן השם “מחשב קוונטי”). לגישה השונה הזו יש יתרונות וחסרונות. היתרונות הם שיש &lt;strong&gt;דברים מסויימים&lt;/strong&gt; שמחשב קוונטי יכול, תיאורטית, לבצע במהירות גדולה יותר במידה דרסטית (של “כמה דקות” מול “מיליוני שנים”), ולכן דה-פקטו הוא יוכל לבצע חישובים מסויימים שלא יהיה ניתן לבצע בשום דרך אחרת; והחסרונות הם שקשה &lt;strong&gt;משמעותית יותר&lt;/strong&gt; לבנות ולהפעיל מחשבים כאלו, עד לרמה שבה גם כיום אנחנו לא בטוחים שנוכל לבנות מחשב קוונטי שיהיה שימושי לנו בפועל (מחשבים קוונטיים מתפקדים קיימים כך כיום, אבל הם עדיין בסיסיים ביותר ולא שימושיים לצרכים מעשיים).&lt;/p&gt;

&lt;p&gt;לפני שנדבר על מחשב קוונטי אני רוצה לומר כמה דברים על מה שמחשב רגיל עושה. מחשבים הם יצורים מופלאים שמלווים אותנו כיום ברוב תחומי החיים ואנחנו משתמשים בהם לשלל מטרות שונות, אבל בבסיסם הם עושים משהו מאוד פשוט: מחשב מקבל &lt;strong&gt;קלט&lt;/strong&gt;, מבצע &lt;strong&gt;עיבוד&lt;/strong&gt; של הקלט ומחזיר &lt;strong&gt;פלט&lt;/strong&gt;. הקלט והפלט הם &lt;strong&gt;מידע דיגיטלי&lt;/strong&gt;: המחשב רואה אותם בסך הכל בתור סדרות של &lt;strong&gt;ביטים&lt;/strong&gt;, כאשר “ביט” הוא בסך הכל משהו שיכול להיות הסימן 0 או הסימן 1. הנה דוגמא פשוטה: אנחנו מדברים אל המחשב שלנו והוא כותב את הטקסט של מה שאמרנו.&lt;/p&gt;

&lt;p&gt;מה הלך פה? לא דיברנו ישירות אל המחשב אלא אל מיקרופון, שהוא התקן שלקח את גלי הקול שהפקנו מהפה שלנו והמיר אותם למידע דיגיטלי - לסדרה של ביטים. המחשב קיבל את הסדרה הזו וביצע עיבוד שלה - הריץ עליה מה שנקרא &lt;strong&gt;אלגוריתם&lt;/strong&gt;, שהוא סדרה של פקודות שמיועדות להשיג מטרה מסויימת; במקרה הנוכחי המטרה היא לפענח את מה שאמרנו ולתרגם אותו למילים. יש אלגוריתמים רבים ושונים שמיועדים למטרה הזו וחלקם מתוחכמים למדי, אבל בסופו של דבר הפלט הוא זהה: סדרה של ביטים שמייצגת מילים. את המידע הזה המחשב העביר הלאה, אל המסך שלנו, והמסך מתרגם את המידע הדיגיטלי הזה לקרני אור שהעיניים שלנו מסוגלות לקלוט. אני לא חושב על המיקרופון ועל המסך בתור חלק מהמחשב אלא בתור עזרים חיצוניים שמשמשים ל”תיווך” בינינו ובין המחשב. המחשב עצמו הוא רק היצור שאחראי לקחת סדרה אחת של ביטים ולהמיר אותה בסדרה אחרת של ביטים.&lt;/p&gt;

&lt;p&gt;האופן שבו מחשב עובד הוא מרתק - גם האלגוריתם המחוכם ביותר בעולם בסופו של דבר מתורגם לפעולות פשוטות להחריד שהמחשב עושה על הביטים. ברמה של “קח שני ביטים, אם שניהם 0 תחזיר 0 ואחרת תחזיר 1” (זה נקרא פעולת &lt;strong&gt;או לוגי&lt;/strong&gt;). כל חישוב הוא סדרה ארוכה של הפעלות של הפעולות הפשוטות הללו, שנקראות &lt;strong&gt;שערים לוגיים&lt;/strong&gt;. כמובן שאפשר לתאר את הסיטואציה בצורה יותר מורכבת אבל זה מספיק לעת עתה כדי להבין מה זה חישוב “רגיל”.&lt;/p&gt;

&lt;p&gt;כדי להסביר מה מחשב קוונטי בעצם &lt;strong&gt;עושה&lt;/strong&gt;, אני זקוק לחתולים. תודה ל&lt;a href=&quot;https://noa.null.co.il/&quot;&gt;נועה ליברמן-פלשקס&lt;/a&gt; שאיירה לי את המחשב הקוונטי הראשון בעולם שנבנה באמצעות חתולים!&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_3740” align=”alignnone” width=”1000”]&lt;img class=&quot;wp-image-3740 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/02/Catputer-color-A.jpg&quot; alt=&quot;שלושה חתולים יושבים על מה שנראה דומה למחשב קוונטי אמיתי&quot; width=&quot;1000&quot; height=&quot;1000&quot; /&gt; מחשב קוונטי מבוסס חתולים! (איור: נועה ליברמן-פלשקס)[/caption]&lt;/p&gt;

&lt;p&gt;מה הולך פה? יש לנו משהו מוזר שכולל שלושה חתולים, שאתן להם שמות במקום סתם לקרוא להם א’, ב’, ג’: ארצ’יבלד, בהמות וגריזלדה (מלמעלה למטה). כרגע שלושתם נראים חייכנים ומרוצים מהחיים, אבל חכו חכו, עוד רגע המחשב יופעל ויקרה להם משהו מוזר מאוד!&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_3741” align=”alignnone” width=”1000”]&lt;img class=&quot;wp-image-3741 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/02/Catputer-color-B.jpg&quot; alt=&quot;המחשב הקוונטי שהפך לענן שמתוכו מציצות שתי גרסאות של כל חתול - &amp;quot;נחמדה&amp;quot; ו&amp;quot;מוזרה&amp;quot;&quot; width=&quot;1000&quot; height=&quot;1000&quot; /&gt; ותהא סופרפוזיציה חתולית! (איור: נועה ליברמן-פלשקס)[/caption]&lt;/p&gt;
&lt;h2&gt;סופרפוזיציה, או: מה הולך פה בכלל?&lt;/h2&gt;
&lt;p&gt;אם במחשב רגיל יחידת המידע הבסיסית נקראת &lt;strong&gt;ביט&lt;/strong&gt;, אז במחשב קוונטי יחידת המידע הבסיסית נקראת &lt;strong&gt;קיוביט&lt;/strong&gt;. להבדיל מביט שיכול להיות או 0 או 1 וזהו, קיוביט יכול להיות &lt;strong&gt;סופרפוזיציה&lt;/strong&gt; של הערכים 0 ו–1. סופרפוזיציה היא התופעה הבסיסית שביסוד תורת הקוונטים, והיא מה שהופך מחשבים קוונטיים לשונים כל כך ממחשבים רגילים. לכן אנחנו צריכים להבין מה המושג הזה אומר ומה הוא לא אומר. אני מייצג בתמונה סופרפוזיציה בתור “ענן של מהומה” אבל צריך להסביר מה קורה בתוך הענן הזה.&lt;/p&gt;

&lt;p&gt;בואו נסתכל על גריזלדה הלבנה. בתוך הענן למעלה אפשר לראות את הגרסה ה”נחמדה” שלה שראינו גם בתמונה הראשונה. מצד שני, למטה מימין יש גם גרסה “מוזרה” שלה (גריזלדה מייצגת קיוביט: אפשר לחשוב על הגרסה ה”חייכנית” בתור הערך 0 של הקיוביט, ועל הגרסה ה”מוזרה” בתור הערך 1 שלו). הסופרפוזיציה היא &lt;strong&gt;תערובת&lt;/strong&gt; של שתי הגרסאות האפשריות של גריזלדה (וגם של החתולים האחרים שעוד נגיע אליהם). הסיבה לכך שאני משתמש בחתולים מלכתחילה היא הניסוי המחשבתי שנקרא &lt;strong&gt;החתול של שרדינגר&lt;/strong&gt; שבו מתוארת סופרפוזיציה באמצעות חתולים, אבל שם המצבים האפשריים של החתול הם “חי” ו”מת” ואני בוודאי לא רוצה לצייר לכם חתולים מתים.&lt;/p&gt;

&lt;p&gt;בסיטואציה “קלאסית” (המילה “קלאסית” באה לדבר על התיאור של המציאות שנותנת הפיזיקה הקלאסית, זו שלפני מכניקת הקוונטים) היינו מצפים שגריזלדה תהיה “נחמדה” או “מוזרה” אבל לא שתי האפשרויות בו זמנית. בסיטואציה קוונטית המצב מורכב יותר: גריזלדה עדיין &lt;strong&gt;לא בשתי האפשרויות בו זמנית&lt;/strong&gt; אלא בתערובת כלשהי שלהן. מה זה אומר “תערובת”? זה מה שהמתמטיקאים משתמשים בביטוי “צירוף לינארי” כדי לתאר אותו. זה אומר שהתיאור המתמטי המדויק של מה שעובר על גריזלדה יכול להיראות כך:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3742&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/02/grizelda_superposition.jpg&quot; alt=&quot;&quot; width=&quot;434&quot; height=&quot;90&quot; /&gt;&lt;/p&gt;

&lt;p&gt;לא חייבים להבין את הסימונים עד הסוף אלא רק את העיקרון - בתמונה רואים את שני &lt;strong&gt;המצבים&lt;/strong&gt; האפשריים של גריזלדה - “נחמדה” ו”מוזרה”, כשהם נמצאים בין סימון שנראה כמו \(\left\|\cdot\right\rangle \) והוא מופיע כאן כי זה הסימון המקובל בפיזיקה (השם שלו הוא ket) כל אחד מהמצבים הללו מוכפל במספר \(\frac{\sqrt{2}}{2}\), שהוא &lt;strong&gt;המקדם&lt;/strong&gt; של המצב. המקדמים הללו הם אלו שקובעים את ה”אופי” של הסופרפוזיציה; מספרים שונים מובילים לסופרפוזיציות שמתנהגות שונה. במקרה הנוכחי שני המספרים זהים וזה אומר ששני המצבים הם “בעלי אותו משקל” מבחינת הסופרפוזיציה, אבל באופן כללי זה ממש לא חייב להיות המצב.&lt;/p&gt;

&lt;p&gt;יש תפיסות שגויות נפוצות לגבי מהי סופרפוזיציה, אז הנה כמה אמירות נחרצות:&lt;/p&gt;
&lt;ul&gt;
 	&lt;li&gt;גריזלדה היא &lt;strong&gt;לא&lt;/strong&gt; נחמדה ומוזרה &lt;strong&gt;בו זמנית&lt;/strong&gt;. סופרפוזיציה פירושה שהיא לא זה ולא זה אלא &lt;strong&gt;תערובת&lt;/strong&gt; של שני אלו.&lt;/li&gt;
 	&lt;li&gt;גריזלדה היא &lt;strong&gt;לא&lt;/strong&gt; נחמדה בהסתברות כלשהי ומוזרה בהסתברות אחרת. סופרפוזיציה פירושה שהיא בתערובת של שני אלו ואין פה הסתברות (תהיה הסתברות בהמשך).&lt;/li&gt;
 	&lt;li&gt;גריזלדה היא &lt;strong&gt;לא&lt;/strong&gt; נחמדה או מוזרה ופשוט חסר לנו מידע שיאפשר לדעת מה משני אלו נכון. היא &lt;strong&gt;באמת&lt;/strong&gt; בתערובת של שני אלו, זה לא רק מידע חסר.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;כל זה נשמע מוזר מאוד ובוודאי שלא תואם את הנסיון היומיומי שלנו עם חתולים. זה מכיוון שחתולים אכן לא מקיימים סופרפוזיציות שאנחנו שמים אליהן לב. סופרפוזיציה היא משהו שמתרחש בסדרי גודל קטנים בהרבה משל חתול; בדברים כמו אלקטרון בודד, למשל. גם בסדרי גודל כאלו סופרפוזיציה עדיין נשמעת כמו דבר מוזר מאוד, אבל קשה להתווכח עם המציאות - המציאות היא שסופרפוזיציה היא משהו שאכן קורה.&lt;/p&gt;

&lt;p&gt;ליתר דיוק, מה שקורה בפועל הוא שאם אנחנו בונים מודל מתמטי שמנסה לתאר סיטואיציה מציאותית כלשהי, והמודל הזה נבנה בעזרת התיאור המתמטי של תורת הקוונטים, אז הניבויים שהמודל הזה יתן לנו יהיו מדוייקים בצורה יוצאת דופן. האם זה אומר שמה ש”באמת קורה שם בפועל” הוא התיאור המתמטי של תורת הקוונטים? ומה התיאור הזה בכלל אומר? מה זה \(\frac{\sqrt{2}}{2}\) “מוזרה”? כאן אנחנו נכנסים לשאלת ה&lt;strong&gt;פרשנות&lt;/strong&gt; של תורת הקוונטים שראויה לפוסט נפרד.&lt;/p&gt;

&lt;p&gt;נחזור אל הסופרפוזיציה שלנו. עד כה דיברתי על סופרפוזיציה של גריזלדה ותו לא - היו שני “מצבי גריזלדה” ודיברתי על תערובת שלהם. אבל בפועל יש במהומה הזו עוד שני חתולים - ארצ’יבלד ובהמות. כמו אצל גריזלדה, גם אצלם יש שני מצבים שונים והסופרפוזיציה היא תערובת שלהם, אבל המצב הוא יותר מסובך מכך. מערכת קוונטית יכולה לקיים תכונה שנקראת &lt;strong&gt;שזירה&lt;/strong&gt; שפירושה שאי אפשר לחשוב עליה כאילו היא מורכבת משתי מערכות שיושבות זו לצד זו בלי קשר ביניהן, אלא היא מורכבת מבלאגן אחד גדול. במקרה שלנו, זה אומר שאי אפשר להסתכל בנפרד על הסופרפוזיציה של ארצ’יבלד והסופרפוזיציה של בהמות והסופרפוזיציה של גריזלדה; בפועל הסופרפוזיציה מערבת את &lt;strong&gt;כל הצירופים האפשריים&lt;/strong&gt; שלהם.&lt;/p&gt;

&lt;p&gt;זו נקודה שבה האיור למעלה פשוט &lt;strong&gt;משקר&lt;/strong&gt; כדי לא להוסיף יותר מדי בלאגן. באיור למעלה רואים רק גרסה אחת של כל מצב אפשרי של כל חתול. אבל בסיטואציה שכוללת שזירה, המצבים הבסיסיים שמהם המערכת מורכבת יכולים לכלול כל שלשה שבה משתתף אחד משני המצבים של החתולים. כלומר: מצב בסיס אחד הוא שלושת החתולים כשכולם “נחמדים” ומצב בסיס אחר הוא שלושת כשכולם “מוזרים” ומצב בסיס אחד הוא כשארצ’יבלד “נחמד” ואילו בהמות וגריזלדה “מוזרים” וכן הלאה - אם סופרים מגיעים לכך שישנם &lt;strong&gt;שמונה&lt;/strong&gt; מצבי בסיס שונים. הנה תיאור מתמטי של העניין:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3743&quot; src=&quot;https://gadial.net/wp-content/uploads/2019/02/semifull.png&quot; alt=&quot;&quot; width=&quot;657&quot; height=&quot;297&quot; /&gt;&lt;/p&gt;

&lt;p&gt;אם הייתי רוצה שהאיור של המחשב הקוונטי בפעולה יהיה מדויק, הייתי צריך לדרוש שהוא יכלול ייצוג לכל השלשות הללו, אבל אז מרוב מהומה לא היה אפשר להבין שום דבר.&lt;/p&gt;

&lt;p&gt;עד כאן לא ברור למה סופרפוזיציה היא דבר טוב. מה בכלל עושים איתה? ובכן, בחישוב קוונטי קורים שני דברים עיקריים:&lt;/p&gt;
&lt;ul&gt;
 	&lt;li&gt;על הסופרפוזיציה מופעלים &lt;strong&gt;שערים קוונטיים&lt;/strong&gt; שגורמים לה לשינויים. אפשר לחשוב על זה בתור מקל שאנחנו דוחפים לענן וגורמים לו למהומות בפנים.&lt;/li&gt;
 	&lt;li&gt;על הסופרפוזיציה מופעלת &lt;strong&gt;מדידה&lt;/strong&gt;, שגורמת לסופרפוזיציה &lt;strong&gt;לקרוס&lt;/strong&gt;. קריסה כזו פירושה שאחד ממצבי הבסיס שמרכיבים את הסופרפוזיציה נבחר באופן &lt;strong&gt;אקראי&lt;/strong&gt; (כשההסתברות שלו להיבחר נקבעת על פי המקדם שלו; ליתר דיוק, הערך המוחלט בריבוע של המקדם שלו) ואז הסופרפוזיציה מוחלפת במצב הבסיס הזה.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;

&lt;p&gt;תדמיינו מדידה בתור תהליך שבו גורמים לענן של האיור השני להיעלם ולמחשב לחזור לסיטואציה של האיור הראשון, שבו רואים את החתולים בצורה מובחנת זה מזה; רק שבאיור הראשון כולם נחמדים ואילו מדידה בהחלט עשויה להקריס את הסופרפוזיציה למצב שבו גריזלדה מוזרה ושני האחרים נחמדים, למשל. הנקודה היא שאחרי הקריסה אנחנו יכולים &lt;strong&gt;לדעת&lt;/strong&gt; לאיזה מצב קרסנו; זה השלב היחיד שבו אנחנו מפיקים מידע מהחישוב הקוונטי.&lt;/p&gt;

&lt;p&gt;זו נקודה שבה חישוב קוונטי שונה מהותית מחישוב רגיל. בחישוב רגיל המידע שלנו מיוצג על ידי &lt;strong&gt;ביטים&lt;/strong&gt;, וזהו. אין סופרפוזיציות שלהם. חישוב רגיל אפשר לעצור בכל רגע ולקרוא את ערכי הביטים שמשתתפים בחישוב. בחישוב קוונטי זה לא יכול לקרות - אין לנו דרך כלשהי לראות מה קורה “בתוך הענן” של הסופרפוזיציה; הדרך היחידה שלנו להפיק מידע היא לבצע מדידה, והיא הורסת את הסופרפוזיציה ולא מחזירה לנו את המידע המלא שייצג אותה. מה שמאפיין סופרפוזיציה הוא &lt;strong&gt;המקדמים&lt;/strong&gt; של כל אברי הבסיס; מדידה בסך הכל מחזירה לנו איבר בסיס, בלי שום מידע על ערכי המקדמים.&lt;/p&gt;

&lt;p&gt;שימו לב כיצד נפלנו מאיגרא רמא לבירא עמיקתא; לפני רגע החישוב הקוונטי שלנו היה קסום; המידע שלנו יוצג על ידי משהו מדהים שנקרא סופרפוזיציה ויכול לעשות הכל. עכשיו פתאום קרסנו לכך שאנחנו לא יכולים להפיק כמעט שום מידע מהחישוב הקוונטי - רק לקבל אברי בסיס בהסתברויות אלו ואחרות. מה שנקרא &lt;strong&gt;חישוב קוונטי&lt;/strong&gt; זה בדיוק מה שיודע לנצל את המתח שבין שני הקצוות הללו כדי להפיק משהו שימושי. המטרה המרכזית שלנו בחישוב קוונטי היא לייצר &lt;strong&gt;הסתברות טובה לקרוס למצב מועיל&lt;/strong&gt;. בנפנוף ידיים לא מדויק לגמרי אפשר לומר שחישוב קוונטי מנסה לגרום לתוצאות הרעות האפשריות של החישוב לבטל זו את זו, ולתוצאות הטובות לחזק זו את זו. השם הפיזיקלי של ביטולים הדדיים וחיזוקים הדדיים שכאלו הוא &lt;strong&gt;התאבכות&lt;/strong&gt;, על שם התופעה הדומה והמוכרת יותר שיש בגלים.&lt;/p&gt;

&lt;p&gt;הסברים לגבי האופן שבו משתמשים בהתאבכות כדי “לחזק פתרונות חיוביים” דורשים כבר פוסטים נפרדים שייכנסו לעובי הקורה של אלגוריתמים ספציפיים, אבל אני כן רוצה לומר את הפאנצ’ליין: כדי לבצע התאבכויות שכאלו בצורה טובה אנחנו מתבססים בצורה חזקה מאוד על כך שהמקדמים שמופיעים בתוך סופרפוזיציה יכולים להיות &lt;strong&gt;מספרים שליליים&lt;/strong&gt; או אפילו &lt;strong&gt;מספרים מדומים&lt;/strong&gt; (מספר מדומה הוא מספר שכאשר מעלים אותו בריבוע מקבלים מספר שלילי). אם כל המקדמים היו חייבים להיות חיוביים, לא היינו מסוגלים להשיג את האפקט המופלא הזה.&lt;/p&gt;

&lt;p&gt;למה אני חושב שחשוב להדגיש את זה? כי זו הנקודה שבה חישוב קוונטי נפרד מחישוב הסתברותי “רגיל”. לא אכנס כאן לפרטים הפורמליים, אבל אפשר לתאר חישובים הסתברותיים בניסוח דומה לניסוח הסופרפוזיציה שנתתי קודם, אבל המקדמים יהיו חייבים להיות אי שליליים. יוצא שההבדל המהותי בין חישוב קוונטי וחישוב קלאסי טמון במורכבות של הייצוג של מידע קוונטי - מורכבות שבאה לידי ביטוי במשפט כמו “המקדמים יכולים להיות שליליים” שהוא די סתום כל עוד לא נכנסים לפרטים הטכניים. זו אחת הסיבות שבגללה קשה להסביר חישוב קוונטי על רגל אחת; הרבה תיאורים פופולריים של חישוב קוונטי מתארים אותו בתור משהו שיכול להתקיים בחישובים הסתברותיים או מקביליים “קלאסיים”.&lt;/p&gt;
&lt;h2&gt;האלגוריתם של שור וחברים, או: בשביל מה זה טוב בכלל?&lt;/h2&gt;
&lt;p&gt;כל מה שסיפרתי עד כה מראה לנו שחישוב קוונטי הוא &lt;strong&gt;מסובך יותר&lt;/strong&gt; מחישוב רגיל. מסובך יותר ברמה התיאורטית, זאת אומרת - קשה יותר להבין מה הולך שם. חישוב קוונטי מסובך יותר גם ברמה הפרקטית ועל כך אדבר בהמשך - הרבה יותר קשה לבנות ולהפעיל מחשב קוונטי מאשר מחשב רגיל - ומאוד לא סביר שיום אחד נזנח את השימוש במחשבים רגילים לטובת מחשבים קוונטיים. מה כן נעשה? נשתמש במחשבים קוונטיים כדי לפתור בצורה יעילה בעיות &lt;strong&gt;ספציפיות&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;ההיסטוריה של תחום החישוב הקוונטי היא סבוכה ואני לא אכנס לכולה כאן, אבל אחת מנקודות ההתחלה של התחום הייתה בהרצאה שהעביר ריצ’ארד פיינמן בכנס ב-MIT בשנת 1981. מבלי להיכנס לפרטים, המסר הבסיסי שלו היה זה: לבצע סימולציה של מערכות קוונטיות במחשבים זה דבר קשה, וכנראה שהקושי הזה הוא אינהרנטי ולא רק נובע מכך שעדיין לא מצאנו שיטה טובה לבצע סימולציה כזו במחשב. אם כן, אומר פיינמן, אם קשה לסמלץ את הטבע במחשב, למה שלא נשתמש בטבע עצמו לצורך החישוב הזה? למה לא לבנות מחשב שמתבסס על ייצוג מידע שנעזר באפקטים קוונטיים?&lt;/p&gt;

&lt;p&gt;נקודת הציון הבאה בתולדות התחום שאני רוצה להזכיר הגיעה למעלה מעשור אחר כך, בשנת 1994, כשהמתמטיקאי פיטר שור הציע אלגוריתם למחשבים קוונטיים שיכול לבצע ביעילות &lt;strong&gt;פירוק לגורמים&lt;/strong&gt; של מספרים. לפרק לגורמים מספר פירושו להציג אותו בתור מכפלה של מספרים קטנים יותר: למשל, את 60 אפשר לכתוב גם בתור 2 כפול 30 (ואפשר להמשיך ולפרק את 30 ולקבל בסוף ש-60 הוא 2 כפול 2 כפול 3 כפול 5).&lt;/p&gt;

&lt;p&gt;בינינו, זה לא נראה מרשים כל כך להצליח לפרק את 60 לגורמים, אבל מה עם 49046953? אני יכול לגלות לכם שהוא שווה למכפלה של 6451 ב-7603, אבל האם הייתם יכולים לגלות זאת לבדכם, בלי אינטרנט ובלי מחשב? כמה עבודה הייתה נדרשת מכם? וזה עבור מספר שהוא מכפלה של שני מספרים בני 4 ספרות; עכשיו תחשבו מה קורה עם מספר שהוא מכפלה של שני מספרים בני 500 ספרות כל אחד. זה לא משהו שאדם יכול לעשות, וגם למחשבים אין שום סיכוי לעשות את זה ללא אלגוריתם מתוחכם.&lt;/p&gt;

&lt;p&gt;עכשיו, יש לנו אלגוריתמים מתוחכמים לפירוק לגורמים, אפילו &lt;strong&gt;ממש &lt;/strong&gt;מתוחכמים, שמתבססים על מתמטיקה מתקדמת ומרהיבה; אבל אפילו הדברים הכי מתוחכמים שיש לנו עדיין מתקשים מאוד להתמודד עם פירוק לגורמים של מכפלת מספרים בני 500 ספרות. &lt;strong&gt;וזה דבר טוב&lt;/strong&gt;, כי שיטת ההצפנה של RSA, שהיא אחת משיטות ההצפנה הנפוצות והחשובות ביותר כיום, מסתמכת בדיוק על כך שפירוק לגורמים הוא &lt;strong&gt;קשה&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;ואז הגיע פיטר שור ואמר - אם יהיה לי מחשב קוונטי מתפקד, אני יכול לפרק לגורמים מאוד מהר גם מכפלה של מספרים בני 500 ספרות. לא אכנס כאן לפירוט לגבי ה&lt;strong&gt;איך&lt;/strong&gt; שהוא עושה את זה; זה אלגוריתם יפהפה ולא טריוויאלי שמתבסס על מה שתיארתי קודם - “חיזוק” של ההסתברות לקבל תוצאה מועילה ו”ביטול הדדי” של תוצאות לא מועילות. מה שחשוב כאן הוא האפקט שהיה לעצם קיום האלגוריתם - החישוב הקוונטי קפץ למודעות של עולם מדעי המחשב בתור משהו שאם יתממש בפועל יוביל להשלכות לא טריויאליות.&lt;/p&gt;

&lt;p&gt;והאם הוא התממש בפועל? ובכן, עדיין לא. אנחנו עדיין רחוקים בצורה קיצונית ממחשב קוונטי שיכול להפעיל את אלגוריתם שור על מספרים מסדרי הגודל המדוברים פה. זה בכלל לא עומד על הפרק; אבל דברים אחרים כן, למשל סימולציה של מערכות פיזיקליות (הדבר המקורי שפיינמן דיבר עליו, כזכור). גם כאן אנחנו עדיין לא שם, אבל מקווים שאנחנו נמצאים כבר מעבר לפינה.&lt;/p&gt;

&lt;p&gt;יש עוד כמה תוצאות מעניינות ששווה להזכיר כאן. ראשית, האלגוריתם של שור לא “מוכיח” שחישוב קוונטי עדיף על פני חישוב רגיל, כי לא הצלחנו עד היום לשלול את האפשרות שקיים אלגוריתם קלאסי יעיל לפירוק לגורמים ופשוט לא הצלחנו למצוא אותו. אבל בינינו, אף אחד לא חושב שזה המצב; האתגר הוא רק איך להוכיח שאין ולא יהיה אלגוריתם קלאסי יעיל לפירוק לגורמים.&lt;/p&gt;

&lt;p&gt;אם כן, שור לא “מוכיח” עליונות תיאורטית, אבל יש כאלו שכן. דוגמא אחת היא האלגוריתם של גרובר, שעוסק בבעיה הבאה: יש לנו רשימה &lt;strong&gt;לא ממוינת&lt;/strong&gt; של פריטים ואנחנו רוצים למצוא מתוכה פריט שיש לו תכונה טובה מסויימת. איך אפשר למצוא אותו? לא קשה להשתכנע שאם ברשימה יש \(N\) פריטים אז לא משנה באיזה אלגוריתם קלאסי נשתמש, החיפוש עשוי לדרוש קריאה מפורשת של כל אחד מ-\(N\) הפריטים ברשימה. אבל מצד שני, אם הייתה לנו דרך לבצע קריאה שמערבת &lt;strong&gt;סופרפוזיציה&lt;/strong&gt; של האיברים ברשימה, אז האלגוריתם של גרובר מראה כיצד אפשר להסתפק ב-\(\sqrt{N}\) קריאות. זה שיפור שפשוט &lt;strong&gt;לא ניתן לבצע&lt;/strong&gt; בחישוב קלאסי, אבל מצד שני אפשר לטעון שהסיטואציה די שונה כי בחישוב קלאסי אפשר לדגום רק פריט אחד בכל פעם בעוד שבחישוב קוונטי אפשר לדגום “את כולם בבת אחת” בזכות היכולת לפעול על סופרפוזיציה.&lt;/p&gt;

&lt;p&gt;יש דוגמאות קצת יותר חותכות לעליונות התיאורטית של מחשב קוונטי על מחשב רגיל - לא מזמן &lt;a href=&quot;https://gadial.net/2018/10/23/quantum_advantage_with_shallow_circuits/&quot;&gt;דיברתי בבלוג&lt;/a&gt; על מאמר של חוקרים מיבמ ואוניברסיטת מינכן שמראה יתרון של ממש של מודל מסויים של מחשב קוונטי על מודל מסויים של מחשב רגיל, בבעיה שעשויה להרגיש קצת מלאכותית ולא אכנס לפרטים שלה. השורה התחתונה היא שאין לנו ממש ספק בכך שברמה התיאורטית, מחשב קוונטי יכול להיות עדיף על מחשב רגיל בחישובים מסויימים, ולכן לכל הפחות בתור מודל תיאורטי הוא מעניין. אבל מה קורה בפועל?&lt;/p&gt;
&lt;h2&gt;על מחשבים קוונטים בכאן והעכשיו&lt;/h2&gt;
&lt;p&gt;את הדיון על חישובים התחלתי עם מחשב רגיל שמקבל קלט של 0 ו-1 ועושה עליו כל מני מניפולציות. זה טוב ויפה ברמת התיאוריה, אבל מה מחשבים עושים &lt;strong&gt;באמת&lt;/strong&gt;? יש כאן בעצם שתי שאלות - הראשונה, איך הם מייצגים ביטים; השניה, איך הם מבצעים עליהם חישובים. זו שאלת &lt;strong&gt;המימוש&lt;/strong&gt; של מחשבים.&lt;/p&gt;

&lt;p&gt;מה שצריך להבין הוא שאפשר להציע הרבה מימושים שונים לאותו קונספט בדיוק של “קבלו ביטים, בצעו מניפולציות, החזירו ביטים”. אפשר, למשל, לתת לבן אדם לעשות את החישובים עם נייר ועט או עם חשבוניה. זה יהיה איטי ויסבול מהרבה טעויות, אבל זה יעבוד, וזה אכן נעשה בעבר. הסופר טרי פראצ’ט לקח את הרעיון הזה רחוק יותר - בספרי “עולם הדיסק” יש מחשב שמתבסס על חוות נמלים. למרות שזה רעיון מרהיב, אני לא מכיר דרך טובה לייצג מידע ולבצע עליו מניפולציות באמצעות נמלים.&lt;/p&gt;

&lt;p&gt;רעיון שונה הוצע על ידי המתמטיקאי בן המאה ה-19 צ’ארלס בבאג’, שתכנן מכונה מכנית שנקראה &lt;strong&gt;המנוע האנליטי&lt;/strong&gt;. המנוע האנליטי כבר היה מחשב לכל דבר ועניין, למעט הבעיה הקטנה שבנייתו מעולם לא נסתיימה. זה לא מנע מבבאג’ להיחשב למי שהמציא את המחשב הראשון, והשותפה שלו עדה לאבלייס הפכה למתכנתת הראשונה בזכות תוכנית מחשב שכתבה כדי להדגים את השימושיות של המנוע האנליטי בחישובים לא טריוויאליים (חישוב &lt;a href=&quot;https://gadial.net/2012/03/02/bernoulli_numbers/&quot;&gt;&lt;strong&gt;מספרי ברנולי&lt;/strong&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;להבדיל מכל אלו, מחשבים מודרניים מתבססים על &lt;strong&gt;חשמל&lt;/strong&gt;. ביטים מיוצגים על ידי מתח חשמלי; בתיאור פשטני, מתח נמוך מתאר לנו 0 ומתח גבוה מתאר לנו 1, ואפשר לבצע מניפולציות של שינוי מתחים חשמליים בעזרת תעלולי אלקטרוניקה. המימוש הזה של מחשבים בעזרת חשמל הוא לא פחות ממדהים - החישובים שהוא מאפשר הם מהירים ביותר, וצריכת האנרגיה שנדרשת לשם כך היא נמוכה למדי. זה לא קרה בן רגע; המחשבים החשמליים הראשונים היו מפלצות ענק עם צריכת אנרגיה מטורפת וקצב חישוב איטי יחסית. השינוי הגדול בתחום נזקף לזכותם של מהנדסי החשמל ובפרט לזכות המצאת הטרנזיסטור, שהחליף את שפופרות הואקום שעליהם התבססו המחשבים הראשונים.&lt;/p&gt;

&lt;p&gt;עם מחשבים קוונטיים אנחנו נמצאים כרגע בשלב שפופרות הואקום, וזה עוד בהערכה אופטימית; יש שיגידו שאנחנו בקושי בשלב הבבאג’ של התחום. יש כיום כמה גישות שונות לגמרי לשאלה “איך לייצג קיוביט”. לכל אחת יתרונות וחסרונות משלה, ואף אחת מהן לא עובדת טוב במיוחד. גישה אחת לדוגמא נקראת “&lt;strong&gt;יונים כלואים&lt;/strong&gt;” - הרעיון הוא לקחת כמה אטומים, להטעין אותם במטען חשמלי (זה מה שנקרא &lt;strong&gt;יון&lt;/strong&gt;), לשים אותם בתוך מיכל ואקום ו”לכלוא” אותם שם בעזרת שדות אלקטרומגנטיים ולקרר אותם באמצעות לייזרים. מרגע שהשתלטנו על אטומים אינדיבידואליים כאלו, אפשר להשתמש בתכונות שונות שלהן (למשל ספין) על מנת לייצג קיוביטים, וכדי להפעיל “שערים קוונטיים” על הדברים הללו מפגיזים אותם בשדה אלקטרומגנטי מתאים. זה נשמע מגניב בצורה שלא תאומן - וזה עובד, אבל זה עדיין לא עובד טוב כשאנחנו רוצים הרבה קיוביטים.&lt;/p&gt;

&lt;p&gt;מימוש אחר למחשב קוונטי מתבסס על &lt;strong&gt;זרם על-מוליך&lt;/strong&gt;. על-מוליכות היא תופעה של חומרים מסויימים שאחרי שמקררים אותם מספיק, ההתנגדות החשמלית שלהם יורדת לאפס. זרם חשמלי שרץ בתוך על-מוליך שכזה הוא בעל תכונות מופלאות למדי, ובין היתר אפשר לנצל אותו בתור קיוביט (את כל הזרם!). זו השיטה הנפוצה כרגע בתעשיה - המחשבים הקוונטיים של גוגל, מיקרוסופט, אינטל, יבמ ואחרים מתבססים עליה. זה עובד! אבל זה עדיין לא עובד טוב כשאנחנו רוצים הרבה קיוביטים.&lt;/p&gt;

&lt;p&gt;הנה סדרי גודל: כיום מדברים על מחשבים של כמה עשרות קיוביטים, ברמות איכות משתנות; בשביל מימוש יעיל של האלגוריתם של שור מדברים על מיליוני קיוביטים. בקיצור, אנחנו ממש לא שם. האם בקרוב נגיע &lt;strong&gt;לאנשהו&lt;/strong&gt;? האם יהיה לנו מחשב קוונטי שעושה דברים מעניינים שמחשבים רגילים לא יכולים? פעם האמנתי שזה לא יקרה בעשורים הקרובים, ועכשיו אני בהחלט פתוח לאפשרות שזה יקרה בשנים הקרובות. אבל אנחנו עדיין לא שם.&lt;/p&gt;

&lt;p&gt;למה בעצם זה כל כך קשה? ובכן, מחשב קוונטי הוא רגיש מאוד ל&lt;strong&gt;רעשים&lt;/strong&gt;. “רעש” פירושו התערבות כלשהי של משהו מבחוץ על ההתנהלות התקינה של המחשב. מחשב “רגיל” גם כן מושפע ללא הרף מרעשים, אבל הוא הרבה יותר חסין להם. אם מחשב רגיל מחשיב רמת מתח של 20 בתור &lt;strong&gt;אפס&lt;/strong&gt; ורמת מתח של 100 בתור &lt;strong&gt;אחד&lt;/strong&gt;, ופתאום בא רעש מבחוץ ומשנה את רמת המתח מ-100 אל 70, אז המחשב עדיין יוכל לזהות אותה בתור &lt;strong&gt;אחד&lt;/strong&gt;. לעומת זאת במחשב קוונטי אם בא רעש מבחוץ ומתערב בסופרפוזיציה, או מכריח אותה “להימדד”, אז החישוב אבוד. ורעשים כאלו הם בלתי נמנעים. על מנת לצמצם אותם ככל הניתן, מחשבים קוונטיים עובדים כיום בטמפרטורות נמוכות ביותר שקרובות לאפס המוחלט; זה משפר את זמן החישוב עד לרגע שבו הכל קורס ונחרב, אבל בסופו של דבר הכל קורס ונחרב, ומדובר פה על סדר גודל של שניות (מימוש כמו זה של יונים כלואים הוא יותר עמיד, אבל יש לו בעיות משל עצמו).&lt;/p&gt;

&lt;p&gt;מה יקרה בעתיד? הייתי מביע משאלה שנעבור למחשב קוונטי מבוסס חתולים, אבל בכנות, חבל על החתולים. אלא אם אלו יהיו חתולים יוניים על-מוליכים שכלואים על ידי שדות אלקטרומגנטיים בשפופרות ואקום, כי זה פשוט נשמע מוצלח מדי מכדי לוותר על זה.&lt;/p&gt;</content><author><name></name></author><category term="מחשב קוונטי" /><summary type="html">בשנים האחרונות מחשבים קוונטיים עולים יותר ויותר לכותרות ואני רוצה בפוסט הזה להסביר על מה מדובר בצורה שגם מי שלא מכירים את התחום בכלל יוכלו להבין. כבר יש לי סדרת פוסטים בנושא שמתחילה כאן ונכנסת לפרטים הטכניים, אבל פה אני רוצה לתת סקירה כללית יותר, וגם להתייחס יותר להיבטים הפרקטיים של הנושא. אז מה זה מחשב קוונטי ובשביל מה צריך אותו?</summary></entry><entry><title type="html">משפט ארבעת הצבעים (חלק ג’)</title><link href="http://localhost:4000/blog/2019/01/07/four_color_theorem_real_proofs" rel="alternate" type="text/html" title="משפט ארבעת הצבעים (חלק ג')" /><published>2019-01-07T00:32:53+02:00</published><updated>2019-01-07T00:32:53+02:00</updated><id>http://localhost:4000/blog/2019/01/07/four_color_theorem_real_proofs</id><content type="html" xml:base="http://localhost:4000/blog/2019/01/07/four_color_theorem_real_proofs">&lt;p&gt;&lt;a href=&quot;https://gadial.net/2018/12/04/four_color_theorem_kempe_proof/&quot;&gt;בפוסט הקודם&lt;/a&gt; הצגתי את ההוכחה של קאמפ למשפט ארבעת הצבעים, והסברתי כיצד היא נכשלת. בפוסט הזה אני רוצה לסקור בצורה זריזה יחסית ובלי להיכנס לעומק הפרטים את ההוכחות למשפט ארבעת הצבעים שכן קיימות. למה לא להיכנס לעומק הפרטים? ראשית, כי אני לא מבין אותם; ושנית, כי הם מורכבים יחסית ואני לא חושב שאפשר להציג אותם בצורה טובה בבלוג. תחת זאת אקשר אל שלושת המאמרים הרלוונטיים כך שתוכלו לנסות ולקרוא אותם בעצמכם אם תרצו.&lt;/p&gt;

&lt;p&gt;בואו נזכיר את לוח הזמנים. המשפט “נולד” בשנת 1852 כשפרנסיס גאתרי המציא אותו ואחר כך אחיו סיפר על כך לדה-מורגן. בשנת 1879 הציע קאמפ את ההוכחה שלו, ובשנת 1890 הייווד הראה מדוע היא אינה עובדת. כמעט 100 שנים עברו מאז, עד אשר בשנת 1976 הכריזו וולפגנג האקן וקנת אפל שיש ברשותם הוכחה (“Every planar map is four colorable”). &lt;a href=&quot;https://projecteuclid.org/euclid.ijm/1256049011&quot;&gt;הנה&lt;/a&gt; החלק הראשון של המאמר שלהם, ו&lt;a href=&quot;https://projecteuclid.org/euclid.ijm/1256049012&quot;&gt;הנה&lt;/a&gt; החלק השני. ב-1996 התפרסמה הוכחה חדשה, דומה לזו של אפל והאקן אבל פשוטה יותר, של רוברטסון, סנדרס סימור ותומס. &lt;a href=&quot;https://www.researchgate.net/publication/2430062_A_New_Proof_Of_The_Four-Colour_Theorem&quot;&gt;הנה&lt;/a&gt; המאמר שלהם (A New” Proof Of The Four-Colour Theorem”). לבסוף, בשנת 2005 פרסם ז’ורז’ גונתייה מאמר שבו הוא מתאר הוכחה &lt;strong&gt;פורמלית&lt;/strong&gt; למשפט ארבעת הצבעים - כלומר, הוכחה שניתנת לבדיקה באופן מלא על ידי תוכנת מחשב. במקרה הזה, המערכת Coq שהיא מערכת בדיקת הוכחות פורמליות מוכרת ומכובדת. &lt;a href=&quot;http://www.ams.org/notices/200811/tx081101382p.pdf&quot;&gt;הנה&lt;/a&gt; המאמר שלו (“Formal Proof - the Four Color Theorem”).&lt;/p&gt;

&lt;p&gt;כל ההוכחות הללו מבוססות על אותו עיקרון בסיסי של קאמפ - למצוא קבוצה של &lt;strong&gt;קונפיגורציות&lt;/strong&gt; (שאפשר לחשוב עליהן בתור תת-גרפים אבל זה קצת מטעה) שהיא&lt;/p&gt;
&lt;ul&gt;
 	&lt;li&gt;&quot;בלתי נמנעת&quot;, כלומר &lt;strong&gt;כל&lt;/strong&gt; גרף שהוא דוגמא נגדית מינימלית למשפט ארבעת הצבעים חייב להכיל קונפיגורציה כלשהי מהקבוצה.&lt;/li&gt;
 	&lt;li&gt;&quot;ניתנת לצמצום&quot;, כלומר אם קונפיגורציה כלשהי מופיעה בתוך גרף, אז הוא לא יכול להיות דוגמא נגדית מינימלית למשפט ארבעת הצבעים (כי אפשר להשתמש בקונפיגורציה כדי להחליף את הדוגמא הנגדית הזו באחת פשוטה יותר).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;במאמר של קנת ואפל קבוצת הקונפיגורציות הייתה בת 1478 איברים. במאמר של רוברטסון ושות’, הם מצאו קבוצה אחרת בת 633 איברים, ובמאמר של גונתייה הוא השתמש באותה קבוצה כמו רוברטסון. זה בהחלט מעניין לשאול את השאלה איך מצאו את הקבוצות הללו, והתשובה היא פשוטה - המון, המון ניסוי וטעיה. נסו לקרוא את המאמר של קנת ואפל, שמבלים הרבה זמן בלהסביר את הנסיבות שהובילו לתוצאה שלהם - הם מפרטים כל צעד ושעל. ולמה לפרט כל כך? כי השאלה המתבקשת למראה המאמרים הללו היא - ההוכחות שלכם כל כך מסובכות, למה שנטרח בכלל להבין אותן? לא יכלתם לפשט אותן קצת? אז צריך להבין שהזוועות הללו הן מה שהתקבלו &lt;strong&gt;אחרי&lt;/strong&gt; הפישוטים.&lt;/p&gt;

&lt;p&gt;האופן שבו אפל והאקן הגיעו לקבוצה שלהם התבסס על נסיון ליצור מראש קבוצה של קונפיגורציות בלתי נמנעות, תוך בדיקה מה ניתן לצמצום ומה לא. אם התגלתה קונפיגורציה שלא ניתנת לצמצום, הם שינו קצת את הפרמטרים של השיטה שבה הם יוצרים את קבוצת הקונפיגורציות. הם נותנים קרדיט למתמטיקאי אחר, האש, על השיטה הבסיסית שנקראת “פריקה” (discharging): הרעיון הוא להקצות “מטענים” מספריים לצמתים של גרף מישורי כלשהו כך שסכום המטענים הוא חיובי, ואז לגרום לצמתים עם מטען חיובי לחלק אותו באופן שווה בין השכנים, ולהראות שרק במקרים ספציפיים יישארו בכלל מטענים חיוביים על הצמתים בגרף (וכל שאר המקרים נפסלים) ומזה כבר אפשר לשלוף קונפיגורציות. זה לא נשמע &lt;strong&gt;כל כך &lt;/strong&gt;מסובך, אבל זו רק המוטיבציה; כשנכנסתי לפרטים של התהליך המדויק שבו אפל והאקן השתמשו הלכתי לאיבוד מהר מאוד.&lt;/p&gt;

&lt;p&gt;לזכותי ייאמר שלא רק אני הלכתי לאיבוד! הנה מה שאומרים רוברטסון ושות’ על החלק הזה של המאמר של אפל והאקן:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p dir=&quot;ltr&quot;&gt;Even the part of the proof that is supposed to be checked by hand is extraordinarily complicated and tedious, and as far as we know, no one has made a complete independent check of it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;זו, אגב, כנראה הבעיה המרכזית של המאמר של אפל והאקן, ולא ההסתמכות על מחשב שאוהבים לתאר בתור הסיבה שבגללה ההוכחה הזו היא “חריגה”. תגידו, גם ההוכחה של המשפט האחרון של פרמה היא ארוכה ומסובכת, וזה בוודאי נכון; אבל ככל הנראה (לא קראתי בעצמי) ההוכחה של המשפט האחרון של פרמה &lt;strong&gt;יותר מעניינת&lt;/strong&gt; עבור מי שבקיאים בחומר, ולכן יש להם יותר מוטיבציה להבין אותה עד הסוף. ההוכחה של אפל והאקן היא פשוט… מסובכת. זו לא לגמרי אשמתם - ככה זו קומבינטוריקה.&lt;/p&gt;

&lt;p&gt;החלק הידני אצל אפל והאקן הוא זה שמגדיר את הקבוצה המפלצתית בגודלה שלהם (שלא נכללת במאמר במפורש, היא אמורה להיות בנספח שלא טרחתי לחפש) ומוכיחה שהקבוצה הזו היא “בלתי נמנעת”. ההוכחה לכך שהיא “ניתנת לצמצום” כבר דורשת בדיקת מחשב שאני לא סגור על מה היא בדיוק עושה, אבל כנראה צריכה לבדוק הרבה סיטואציות אפשריות שמערבות כל קונפיגורציה (המאמר מפרט קצת יותר על זה, מציג כל מני סוגי צמצומים שונים וכן הלאה; לא הבנתי שום דבר שם מספיק כדי לתאר את זה בבלוג). השורה התחתונה היא שבדיקת המחשב הזו היא לא כזו שאחרי אפשר להוציא הוכחה קצרה יותר; הבדיקה היא-היא ההוכחה.&lt;/p&gt;

&lt;p&gt;אני רוצה לחדד את הנקודה הזו. אם מביאים לנו מפה גדולה ומורכבת ואני טוען שאפשר לצבוע אותה בשלושה צבעים, אני יכול להוכיח את זה בצורה פשוטה - אני אומר באיזה צבע לצבוע כל מדינה במפה. את זה אפשר לבדוק בקלי קלות - רק צריך לבדוק שאין שתי מדינות שכנות עם אותו צבע, מה שיסתיים מיידית גם עבור מפות מורכבות מאוד. מה שקשה הוא &lt;strong&gt;למצוא&lt;/strong&gt; את הצביעה הזו. מחשב יכול לשבור את הראש במשך חודשים ארוכים בחיפוש אחר צביעה שכזו, אבל אם מצא - הופס, ההוכחה מכאן ואילך היא שניות.&lt;/p&gt;

&lt;p&gt;מה עדיין &lt;strong&gt;קשה&lt;/strong&gt; לעשות? ובכן, להוכיח שמפה &lt;strong&gt;לא ניתנת לצביעה&lt;/strong&gt; בשלושה צבעים. כאן אין לנו משהו שהוא משמעותית יותר טוב מאשר “להריץ בדיקה של כל האפשרויות”. צריך להסתייג כאן קצת - כן יש לנו שיטות מסודרות להוכחה שמשהו בסגנון הזה הוא בלתי אפשרי, וכן אפשר לפשט שם דברים וכדומה - אבל &lt;strong&gt;לא יותר מדי&lt;/strong&gt;. &lt;a href=&quot;https://gadial.net/2016/07/12/boolean_pythagorean_triples/&quot;&gt;דיברתי על זה כבר&lt;/a&gt; בהקשר של בעיה אחרת, של “צביעת שלשות פיתגוריות”. יש תחום שלם שנקרא Proof complexity שמתעסק בנושא הזה, כך שלא אכנס לכך יותר לעומק כאן. השורה התחתונה היא שהוכחת שלב ה”ניתנת לצמצום” היא קשה אינהרנטית, ברמה שמאלצת אותנו להשתמש במחשב. ואז לכו תסמכו על כך שלא נפלה טעות בתוכנית המחשב שמבצעת את החישוב הארוך והמסובך הזה (או שארעה תקלה באמצע החישוב ברמת החומרה של המחשב ואיזה ביט התהפך שם).&lt;/p&gt;

&lt;p&gt;ההוכחה של רוברטסון ושות’ משתמשת באותו רעיון בסיסי - אבל כאמור, עבור קבוצה &lt;strong&gt;שונה &lt;/strong&gt;של קונפיגורציות; הם לא ניסו לקחת את הקבוצה של אפל והאקן ולשפר אותה. התרומה הגדולה שלהם על פני אפל והאקן הוא שאת שלב ה”בלתי נמנעת” הם הצליחו לפשט ברמה שמאפשרת לבדוק אותו באמצעות מחשב. כפי שהם אומרים בבדיחות (?):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p dir=&quot;ltr&quot;&gt;The first proof needs a computer. The second can be checked by hand in a few months, or, using a computer, it can be verified in a few minutes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;כאן “ההוכחה הראשונה” היא של ה”ניתנת לצמצום” והשניה של ה”בלתי נמנעת”.&lt;/p&gt;

&lt;p&gt;במאמר של גונתייה לא התעמקתי עד הסוף (כן הורדתי את ההוכחה הפורמלית עצמה בשעתו והצצתי בה, אבל קשה לומר שהבנתי ממנה יותר מדי). נראה שהוא מתבסס על ההוכחה של רוברטסון ושות’, אבל עם וריאציות כלשהן על ההגדרות על מנת לפשט את הפורמליזציה של הבעיה בתוך Coq. כאן אני נתקע בשל חוסר ההיכרות שלי עם Coq (שלא עשיתי יותר מאשר לשחק בה קצת ואני לא מבין עד הסוף את הלוגיקה שעליה היא מבוססת); אם אני אכתוב פוסט על הוכחות פורמליות ועל Coq בוודאי שלא אתחיל דווקא מההוכחה הזו.&lt;/p&gt;

&lt;p&gt;אז זהו זה. זה כל מה שאני יכול להגיד על ההוכחות שאני מכיר. עכשיו עולות מאליהן שתי שאלות.&lt;/p&gt;

&lt;p&gt;ראשית, האם אין הוכחות אחרות? ובכן, בוודאי שיש! גיגול זריז יעלה עוד הוכחות שונות ומשונות, חלקן קצרות עד להפתיע. אני לא מאמין לאף אחת מהן מלבד השלוש שתיארתי כאן, אבל לא ניסיתי בכלל לחפש את הטעות בהוכחות האחרות (ואם אנסה, בכלל לא בטוח שאצליח; זוכרים כמה קשה היה לשים לב לטעות של קאמפ?) כמו במשפט האחרון של פרמה, אפשר בהחלט לשאול את השאלה אם קיימת גם הוכחה &lt;strong&gt;פשוטה&lt;/strong&gt; למשפט שפשוט חומקת מאיתנו; כמו במשפט האחרון של פרמה, נראה שהתשובה היא “ככל הנראה לא” (אפל והאקן מרחיבים על כך במאמר שלהם) אבל לכו תדעו. אני לא רוצה לדכא את היצירתיות של אף אחד; מה שכן, אם יש הוכחה אחרת, כנראה שהיא תצטרך להיות &lt;strong&gt;שונה&lt;/strong&gt; בסגנון שלה; לא וריאציה על הרעיון של קאמפ.&lt;/p&gt;

&lt;p&gt;שנית, האם אני מאמין להוכחות שכן קיימות? ובכן, כן. גם כי קיום הוכחה פורמלית ב-Coq מרגיע אותי, וגם כי אני מאמין לדברים שאני הרבה פחות מבין (המשפט האחרון של פרמה! שוב!). אולי אני טועה, אבל אם כן, אז מה? המשפט לא חשוב במיוחד, בסופו של דבר. שאלה יותר מעניינת ופילוסופית משהו היא האם הוכחה שדורשת מחשב לבדיקתה היא אכן הוכחה, וכאן אני רוצה להחזיר אותנו שוב לכך שהבעיה הבסיסית בהוכחה של אפל והאקן היא הקושי שלה, לא הקטע עם המחשב. אני לא מבין עד הסוף אף אחת משלוש ההוכחות, גם ברמת “הטקסט שמופיע בתוך המאמר”; יותר סביר שתיפול טעות בקריאה שלי את המאמרים הללו מאשר בתוכנית מחשב שבודקת את מה שמופיע בהם. אני אמין &lt;strong&gt;פחות&lt;/strong&gt; מאשר המחשב; אם פוסלים את המחשב בתור בודק הוכחות לגיטימי, מה יגידו אזובי הקיר.&lt;/p&gt;</content><author><name></name></author><category term="משפט ארבעת הצבעים" /><summary type="html">בפוסט הקודם הצגתי את ההוכחה של קאמפ למשפט ארבעת הצבעים, והסברתי כיצד היא נכשלת. בפוסט הזה אני רוצה לסקור בצורה זריזה יחסית ובלי להיכנס לעומק הפרטים את ההוכחות למשפט ארבעת הצבעים שכן קיימות. למה לא להיכנס לעומק הפרטים? ראשית, כי אני לא מבין אותם; ושנית, כי הם מורכבים יחסית ואני לא חושב שאפשר להציג אותם בצורה טובה בבלוג. תחת זאת אקשר אל שלושת המאמרים הרלוונטיים כך שתוכלו לנסות ולקרוא אותם בעצמכם אם תרצו.</summary></entry><entry><title type="html">משפט ארבעת הצבעים (חלק ב’)</title><link href="http://localhost:4000/blog/2018/12/04/four_color_theorem_kempe_proof" rel="alternate" type="text/html" title="משפט ארבעת הצבעים (חלק ב')" /><published>2018-12-04T18:12:58+02:00</published><updated>2018-12-04T18:12:58+02:00</updated><id>http://localhost:4000/blog/2018/12/04/four_color_theorem_kempe_proof</id><content type="html" xml:base="http://localhost:4000/blog/2018/12/04/four_color_theorem_kempe_proof">&lt;p&gt;בפוסט הקודם הצגתי את בעיית ארבעת הצבעים: בהינתן מפה - כלומר, חלוקה של איזור מסויים לתתי-איזורים שלכל אחד מהם אני קורא “מדינה” - להוכיח שדי בארבעה צבעים כדי לצבוע אותה כך שלא יהיו שתי מדינות עם גבול משותף הצבועות באותו הצבע. בפוסט הזה אני אציג את ההוכחה השגויה של קאמפ למשפט הזה - הוכחה יפה עם רעיונות מוצלחים למדי שנפלה בשל נקודה עדינה שקל לפספס.&lt;/p&gt;

&lt;p&gt;נתחיל מהבהרה קטנה לעניין “למה מפות וגרפים הן בערך אותו דבר”. אם אני אצייר עיגול קטן בתוך כל מדינה (“עיר בירה”) ואמתח קווים בין העיגולים של מדינות סמוכות (“קווי רכבת”), אני אקבל גרף מישורי; לכן הדיבורים על מפות ומדינות הן דרך אחרת לומר “כל גרף מישורי הוא 4-צביע”. הנה דוגמא לאופן שבו זה נעשה על חלק ממפת ארה”ב (כמובן, מבלי ש”ערי הבירה” יתאימו לערי הבירה האמיתיות של המדינות):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3702 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/map-with-cities.png&quot; alt=&quot;&quot; width=&quot;559&quot; height=&quot;622&quot; /&gt;&lt;/p&gt;

&lt;p&gt;כמובן, התיאור הזה הוא פשטני מדי; מסתתרת כאן הוכחה לא טריוויאלית, אבל אני לא אכנס אליה כלל.&lt;/p&gt;

&lt;p&gt;סיבה אחת שבגללה גרפים מישוריים מעניינים אותנו היא שהם מקיימים את &lt;strong&gt;נוסחת אוילר&lt;/strong&gt;. נוסחת אוילר מקשרת את מספר הצמתים של גרף מישורי, מספר הקשתות שלו ומספר הפאות שלו. מה אלו צמתים, קשתות ופאות? צמתים הם המרכיבים הבסיסיים של הגרף - אפשר לחשוב עליהם בתור עיגולים קטנים אם רוצים. קשתות הן הקווים שמחברים זוגות של צמתים. גרף הוא &lt;strong&gt;מישורי&lt;/strong&gt; אם אין שתי קשתות שדורכות זו על זו (פורמלית, גרף הוא מישורי אם &lt;strong&gt;אפשר&lt;/strong&gt; לצייר אותו בצורה כזו ועדיין לשמור על התכונה של אילו צמתים מחוברים). ופאות? בגרף מישורי, פאות הם האיזורים ש”נראים כמו מדינות” - איזורים שמוקפים כולם בקשתות. בנוסף לאלו יש גם פאה אחת נוספת, ה”חיצונית”.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3703 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/planar-graph.png&quot; alt=&quot;&quot; width=&quot;562&quot; height=&quot;662&quot; /&gt;&lt;/p&gt;

&lt;p&gt;אנחנו רואים שגרף מישורי בעצם נראה כמו… מפה. כלומר, אם ניקח מפה תמימה ונבנה ממנה גרף מישורי, בעצם נקבל מפה אחרת, שנקראת &lt;strong&gt;הדואלית&lt;/strong&gt; שלה. בואו נבין איך דברים משתנים במעבר הזה:&lt;/p&gt;
&lt;ul&gt;
 	&lt;li&gt;צומת בגרף הדואלי (&quot;עיר בירה&quot;) הייתה פאה במפה המקורית (&quot;מדינה&quot;)&lt;/li&gt;
 	&lt;li&gt;קשת בגרף הדואלי (&quot;קו רכבת בין ערי בירה&quot;) הייתה קשת שונה במפה המקורית (&quot;קו גבול בין שתי מדינות סמוכות&quot;).&lt;/li&gt;
 	&lt;li&gt;פאה בגרף הדואלי (&quot;מסלול מעגלי של רכבות&quot;) הייתה צומת במפה המקורית (&quot;נקודת מפגש של גבולות&quot;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3704 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/dual-graph.png&quot; alt=&quot;&quot; width=&quot;568&quot; height=&quot;611&quot; /&gt;&lt;/p&gt;

&lt;p&gt;באיור, שבו הוספתי סימון עבור נקודות המפגש של שלושה גבולות ויותר, קל יחסית להבין את המעבר הזה. אם הייתה לנו מדינה בגרף המקורי, אז הצומת שמתאים לה הוא הצומת היחיד שנמצא בתוך “שטח” המדינה. עבור קשתות, כל קשת בגרף הדואלי חוצה בדיוק קשת אחת בגרף המקורי, מה שנותן את ההתאמה ביניהן. מה שאולי קצת מבלבל הוא ה”קסם” שבמסגרתו כל צומת מהגרף המקורי (מפגש של כמה גבולות) נמצאת עכשיו בתוך פאה בודדת של הגרף הדואלי, אבל העקרון ברור - אפשר לעבור במסלול מעגלי על כל המדינות שהגבול שלהן משתתף בצומת הזה.&lt;/p&gt;

&lt;p&gt;עכשיו אפשר לחזור ולדבר על נוסחת אוילר. היא פשוטה להחריד: אם \(V\) הוא מספר הצמתים בגרף מישורי, \(E\) הוא מספר הקשתות ו-\(F\) הוא מספר הפאות שלו (כולל הפאה “החיצונית”) אז \(V-E+F=2\). הנוסחה התמימה הזו היא כנראה הנוסחה האהובה עלי במתמטיקה, וכבר &lt;a href=&quot;https://gadial.net/2010/01/31/euler_formula_and_platonic_solids/&quot;&gt;הקדשתי לה פוסט&lt;/a&gt; (שעוסק בפאונים ולא בגרפים מישוריים אבל זה אותו הדבר; במקור אוילר אכן הוכיח אותה לפאונים).&lt;/p&gt;

&lt;p&gt;קאמפ משתמש בנוסחת אוילר כדי להוכיח שבכל גרף מישורי חייב להיות צומת עם &lt;strong&gt;לכל היותר&lt;/strong&gt; חמישה שכנים. החלק הזה במאמר של קאמפ הוא נכון לחלוטין והטיעון לא קשה; בואו נבין אותו עד הסוף. חוץ מנוסחת אוילר אצטרך עוד כמה נוסחאות שאפשר להסיק על גרפים מישוריים די בקלות. ראשית, \(2E\ge3F\). למה? ובכן, בואו נעבור פאה-פאה ונספור את &lt;strong&gt;כל&lt;/strong&gt; הקשתות שמרכיבות כל פאה. נקרא למספר הזה \(X\). מה אני יודע על \(X\)? ראשית, מכיוון שכל פאה כוללת &lt;strong&gt;לפחות&lt;/strong&gt; שלוש קשתות, הרי ש-\(X\ge3F\) (כי לכל אחת מ-\(F\) הפאות הוספנו ל-\(X\) לפחות 3). שנית, מכיוון שכל קשת שייכת בו זמנית בדיוק &lt;strong&gt;לשתי&lt;/strong&gt; פאות, הרי ש-\(X=2E\) (כי ספרנו כל קשת פעמיים). קיבלנו \(2E\ge3F\) בלי להתאמץ בכלל.&lt;/p&gt;

&lt;p&gt;עכשיו, בואו נסמן ב-\(p_{i}\) את מספר הצמתים בגרף שיש להם \(i\) שכנים. שימו לב שמספר השכנים של צומת שווה בדיוק למספר הקשתות שמחוברות אליו, ושבשיטת הספירה הזו כל קשת נספרת פעמיים (פעם אחת לכל אחד משני הצמתים שאליהם היא מחוברת). לכן אנחנו מקבלים את הנוסחה הבאה:&lt;/p&gt;

&lt;p&gt;\(2E=p_{1}+2p_{2}+3p_{3}+\dots\)&lt;/p&gt;

&lt;p&gt;הסכום באגף ימין הוא לא אינסופי כי החל ממקום מסויים \(p_{i}=0\) לכל \(i\) ולכן הסכום נעצר שם.&lt;/p&gt;

&lt;p&gt;עכשיו, כמה צמתים יש בגרף בסך הכל? סכום מספר הצמתים עם שכן אחד, ומספר הצמתים עם שני שכנים, וכדומה:&lt;/p&gt;

&lt;p&gt;\(V=p_{1}+p_{2}+p_{3}+\dots\)&lt;/p&gt;

&lt;p&gt;עכשיו ננקוט בתעלול אלגברי נחמד: נכפול את המשוואה השניה ב-6 ונחסר ממנה את הראשונה. נקבל:&lt;/p&gt;

&lt;p&gt;\(6V-2E=5p_{1}+4p_{2}+3p_{3}+2p_{4}+p_{5}-p_{7}-2p_{8}-\dots\)&lt;/p&gt;

&lt;p&gt;או בסימון מקוצר:&lt;/p&gt;

&lt;p&gt;\(2\left(3V-E\right)=\sum_{i=1}^{\infty}\left(6-i\right)p_{i}\)&lt;/p&gt;

&lt;p&gt;עד עכשיו לא השתמשנו בכלל בנוסחת אוילר. כעת אפשר להשתמש בה: אני מסיק ממנה ש-\(V=2+E-F\), מציב ב-\(2\left(3V-E\right)\) ומקבל:&lt;/p&gt;

&lt;p&gt;\(2\left(3V-E\right)=2\left(6+3E-3F-E\right)=12+2\left(2E-3F\right)\)&lt;/p&gt;

&lt;p&gt;מכיוון ש-\(2E\ge3F\), הביטוי כולו הוא חיובי (הוא 12 ועוד משהו אי-שלילי). כלומר, גם הסכום \(\sum_{i=1}^{\infty}\left(6-i\right)p_{i}\) הוא חיובי. אבל יש בסכום הזה רק חמישה איברים חיוביים:&lt;/p&gt;

&lt;p&gt;\(5p_{1}+4p_{2}+3p_{3}+2p_{4}+p_{5}\)&lt;/p&gt;

&lt;p&gt;המסקנה היא שלפחות אחד מה-\(p_{i}\)-ים הללו צריך להיות חיובי, והוא מתאים בדיוק לצומת עם חמישה שכנים או פחות, כפי שרצינו.&lt;/p&gt;

&lt;p&gt;מה קאמפ עשה כאן? הוא הראה שבכל מפה צריכה להופיע &lt;strong&gt;תבנית&lt;/strong&gt; מסויימת - או, כפי שאני מעדיף לקרוא לה, &lt;strong&gt;קונפיגורציה&lt;/strong&gt;. במקרה הנוכחי, מדינה עם חמש שכנות או פחות. זה היה החלק הראשון של הרעיון שלו. החלק השני היה להראות שאם בגרף מישורי יש תבנית כזו, אז אפשר להקטין את הגרף (להקטין את מספר הצמתים) כך שאם הגרף &lt;strong&gt;לא &lt;/strong&gt;היה 4-צביע קודם, גם אחרי ההקטנה הוא עדיין &lt;strong&gt;לא &lt;/strong&gt;יהיה 4-צביע. אם זה היה עובד, זה היה מוכיח בקלות את המשפט כי בהינתן גרף “לא 4-צביע” אפשר היה פשוט להקטין אותו עוד ועוד עד לקבלת גרף כל כך קטן שהוא חייב להיות 4-צביע (למשל, אם יש בו רק 4 צמתים). דרך אחרת, טיפה יותר אלגנטית מתמטית, היא לומר ש”מבין הדוגמאות הנגדיות למשפט ארבעת הצבעים ניקח אחת שהיא מינימלית ביחס למספר הצמתים שלה”, ואז כשאפשר להקטין את מספר הצמתים ועדיין לקבל דוגמא נגדית, זו סתירה ל”מינימלית”.&lt;/p&gt;

&lt;p&gt;בואו ננסח מחדש את התכונה הזו בצורה חיובית. מה שאני רוצה להוכיח הוא שאם בגרף יש תבנית מסויימת, אז אפשר לבחור צומת, להסיר אותה מהגרף ו”לתקן” את הגרף בהתאם כך שמקבלים גרף קטן יותר, ואז אם הגרף הזה צביע ב-4 צבעים, אפשר לחזור אל הגרף המקורי ולהשתמש בצביעה הזו כדי לבנות צביעה ב-4 צבעים של הגרף המקורי, כולל הצומת שהסרנו קודם. איך?&lt;/p&gt;

&lt;p&gt;ובכן, יש לנו חמישה מקרים לטפל בהם, החל מצומת עם שכן אחד וכלה בצומת עם חמישה שכנים. שלושת המקרים הראשונים קלים. אם יש לנו צומת עם לכל היותר שלושה שכנים, אפשר פשוט להסיר אותו מהגרף, לצבוע את הגרף שהתקבל כתוצאה מכך, ואז לחזור אל הגרף המקורי. הצומת שהסרנו קודם הוא בעל שלושה שכנים בלבד, ויש לרשותנו ארבעה צבעים שבהם אפשר לצבוע את הגרף; פשוט נבחר עבור הצומת שנותר לנו לצבוע צבע כלשהו שאין לשכניו (מובטח שיהיה לפחות אחד כזה, במקרה שבו כל השכנים צבועים בצבעים שונים):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3705 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/color3.png&quot; alt=&quot;&quot; width=&quot;566&quot; height=&quot;594&quot; /&gt;&lt;/p&gt;

&lt;p&gt;באיור הזה הסרתי את הצומת שמתאים למדינת קליפורניה ויש לו שלושה שכנים. הוא צבוע בלבן כדי לסמן שהוא טרם נצבע, והקשתות שיוצאות ממנו הן מקווקוות כדי לסמן שהן “לא חלק מהגרף”, וכעת צבעתי את יתר הגרף בארבעה צבעים. עכשיו אפשר להסתכל על קליפורניה ולראות במה נצבעו שכנותיה: בירוק, באדום ובצהוב, כך שהצבע הכחול פנוי.&lt;/p&gt;

&lt;p&gt;בואו נעבור עכשיו למקרה של צומת עם ארבעה שכנים. נניח שכבר צבענו את יתר הגרף, אבל לרוע המזל כל השכנים של הצומת נצבעו בצבעים שונים. מה עושים עכשיו?&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3707 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/color4-1.png&quot; alt=&quot;&quot; width=&quot;757&quot; height=&quot;505&quot; /&gt;&lt;/p&gt;

&lt;p&gt;כאן קאמפ הציע את הרעיון היפה שלו. נבחר את אחד מהשכנים, נאמר את שכן מספר 1, ונחליף את הצבע שלו לצבע של שכן מס’ 3. במקרה שלנו שכן מס’ 1 הוא אדום ואילו 3 הוא צהוב, אז נצבע מחדש את שכן מס’ 1 בצהוב. בזאת “פינינו” את הצבע האדום ואפשר לצבוע בו בלב שקט את הצומת שבאמצע. רק מה, שינוי הצבע של שכן מספר 1 עלול לגרום לבעיות חדשות. מה אם לשכן מס’ 1 יש שכנים ש&lt;strong&gt;כבר&lt;/strong&gt; צבועים בצהוב?&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3708 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/color4-2.png&quot; alt=&quot;&quot; width=&quot;779&quot; height=&quot;610&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ובכן, במקרה הזה קאמפ מציע פשוט לשנות את הצבע של השכנים הללו לאדום. אבל אם יש להם שכנים אדומים? ובכן, שיוחלפו בצהובים, וכן הלאה וכן הלאה. אנחנו מקבלים מעין &lt;strong&gt;תגובת שרשרת&lt;/strong&gt; לשינוי הצבע, אבל אין כאן משהו לא חוקי. במקרה הכי גרוע נקבל החלפה “מלאה” של הצבעים בגרף - כל הצמתים הצהובים יהפכו לאדומים, וכל הצמתים האדומים יהפכו לצהובים. עדיין נקבל גרף עם צביעה חוקית, אבל… אבל אם הצבע של שכן מס’ 3 יתהפך מצהוב לאדום בעצם לא הרווחנו כלום - עדיין כל השכנים של הצומת באמצע יהיו צבועים בצבעים שונים זה מזה.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3709 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/color4-3.png&quot; alt=&quot;&quot; width=&quot;765&quot; height=&quot;668&quot; /&gt;&lt;/p&gt;

&lt;p&gt;קאמפ אומר שכדי ששינוי הצבע של צומת מס’ 1 ישפיע ככה על צומת מס’ 3, חייבת להתקיים &lt;strong&gt;שרשרת&lt;/strong&gt; שמובילה מצומת 1 לצומת 3 והצמתים בה צבועים לסירוגין באדום וצהוב. שרשרת מסוג זה נקראת כיום על שמו - &lt;strong&gt;שרשרת קאמפ&lt;/strong&gt;. כמובן שאין מניעה לכך שבאמת תהיה כזו שרשרת וקל לבנות גרפים שבהם זה קורה. בואו נחזור לסיטואציה המקורית בגרף לדוגמא שלנו ונדגיש בה את השרשרת:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3711 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/color4-4-1.png&quot; alt=&quot;&quot; width=&quot;789&quot; height=&quot;627&quot; /&gt;&lt;/p&gt;

&lt;p&gt;אז מה עושים?&lt;/p&gt;

&lt;p&gt;אה-הא! בואו לא נשכח שיש לנו גם את צומת 2 וצומת 4! אפשר לעשות את תעלול החלפת הצבעים גם עבורן! וגם… וגם עבורן הוא עשוי להיכשל באותו האופן בדיוק, עם שרשרת קאמפ:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3712 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/color4-5.png&quot; alt=&quot;&quot; width=&quot;971&quot; height=&quot;782&quot; /&gt;&lt;/p&gt;

&lt;p&gt;אבל כאן נכנס טיעון המחץ של קאמפ - הגרף הוא &lt;strong&gt;מישורי&lt;/strong&gt; ולכן השרשרת מ-1 אל 3 והשרשרת מ-2 אל 4 בהכרח &lt;strong&gt;מתנגשות&lt;/strong&gt; - כלומר, חייב להיות להן צומת משותף (אחרת יהיו קשתות מהשרשראות שחותכות זו את זו) אבל לא יכול להיות לשרשראות צומת משותף כי שרשרת אחת היא בצבעי אדום-צהוב והשניה בצבעי כחול-ירוק. זה מסיים את הטיעון הזה. אין פה שום טעות - זה עובד, ועובד נפלא. אפשר לכתוב אלגוריתם על פי השיטה שקאמפ הציע פה והוא אכן יצליח “לתקן” את הצביעה של הגרף בהתאם ולאפשר צביעה של הצומת הנוסף בצבע שלא מתנגש עם שכניו.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3714 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/color4-6-1.png&quot; alt=&quot;&quot; width=&quot;1023&quot; height=&quot;780&quot; /&gt;&lt;/p&gt;

&lt;p&gt;אז מה הבעיה? הבעיה היא שצריך לטפל גם במקרה של צומת עם &lt;strong&gt;חמישה&lt;/strong&gt; שכנים. כאן קאמפ ניסה להשתמש בטיעון דומה ויצא לו משהו מאוד משכנע, עם טעות מאוד עדינה שקשה להבחין בה במבט ראשון - אבל תנסו!&lt;/p&gt;

&lt;p&gt;אם לצומת יש חמישה שכנים, אז בצביעה של הגרף בלי הצומת הזה, בהכרח יש צבע אחד לפחות שמופיע פעמיים. כמובן, אם לא כל ארבעת הצבעים מופיעים אנחנו שוב במקרה טריוויאלי, ולכן אנחנו מניחים שכל ארבעת הצבעים מופיעים, ואחד מהם מופיע בשני צמתים שונים. עכשיו אפשר להבדיל בין שתי אפשרויות שונות. הראשונה היא שהצבע הכפול - בואו נאמר שהוא האדום - מופיע בשתי מדינות “סמוכות” אבל ללא גבול משותף:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3715 size-medium&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/color5alt-282x300.png&quot; alt=&quot;&quot; width=&quot;282&quot; height=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;p&gt;זו סיטואציה שניתנת לטיפול כמו קודם: קודם כל ננסה להפוך את הצהוב לכחול. אם הצלחנו, מה טוב. אם לא, יש שרשרת קאמפ שמחברת את הצהוב והכחול ולכן “מבודדת” את הירוק מהאדומים. אפשר אם כן להפוך את הירוק לאדום, וסיימנו. גם פה אין טעות.&lt;/p&gt;

&lt;p&gt;הסיטואציה המעניינת היא זו שבה שתי המדינות האדומות לא יכולות להיות “סמוכות” כי בין כל שני שכנים סמוכים של הצומת המרכזי יש קשת. הנה דוגמא לסיטואציה הזו:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3716 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/color5.png&quot; alt=&quot;&quot; width=&quot;596&quot; height=&quot;696&quot; /&gt;&lt;/p&gt;

&lt;p&gt;כאן פשוט &lt;strong&gt;אי אפשר&lt;/strong&gt; להפוך אף צומת לאדום, כי כל אחד מהצמתים הוא שכן של אדום. לכן הפתרון שעבד עבור ארבעה צמתים לא יעבוד כאן - מה שהוא לכל היותר מבטיח שהוא שנוכל לקחת את &lt;strong&gt;אחד&lt;/strong&gt; מהצמתים האדומים ולשנות את הצבע שלו, אבל זה ישאיר אותנו עם צומת אדום אחר. לכן צריך כאן טיעון מתוחכם יותר, וזה מה שקאמפ עושה.&lt;/p&gt;

&lt;p&gt;קאמפ אומר - בואו ניקח את הירוק ונבדוק אם אפשר להפוך אותו לכחול או צהוב. אם אפשר, יופי! אחרת, יש שרשרת ירוק-כחול ויש שרשרת ירוק-צהוב שמקלקלות לנו. באיור הרשיתי לעצמי לשים את שרשרת הירוק-צהוב בים - פשוט תדמיינו שהרחבתי את ארה”ב עם עוד מדינות רלוונטיות.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3717 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/color5-chains.png&quot; alt=&quot;&quot; width=&quot;870&quot; height=&quot;709&quot; /&gt;&lt;/p&gt;

&lt;p&gt;מה שקורה עכשיו הוא ששני הצמתים האדומים מוחבאים “בתוך” השרשראות - האדום השמאלי מנותק מהצומת הכחול, והאדום הימני מנותק מהצומת הצהוב (שימו לב שזה עדיין יקרה אם אם השרשרת הירוקה-צהובה לא תקיף אותו בכלל אלא תקיף את השרשרת הירוקה-כחולה; גם זה תרחיש אפשרי). פירוש הדבר הוא שאפשר לשנות את האדום הימני לצהוב ואת האדום השמאלי לכחול, ובכך להיפטר כליל מהצבע האדום ואז אפשר לצבוע בו את הצומת שבמרכז.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;כאן&lt;/strong&gt; יש טעות. אבל מהי?&lt;/p&gt;

&lt;p&gt;הבאג בהוכחה הוא משהו שיכול להתגלות יחסית בקלות אם מממשים אלגוריתם פרקטי שמנסה לצבוע מפות באמצעות הטריק הזה ומפילים עליו המון מפות אקראיות - הטריק פשוט ייכשל מתישהו. מתי? בוודאי שאין שום סיבה שהוא ייכשל בהחלפת כחול/ירוק או בהחלפת צהוב/ירוק במקרים שבהם אין שרשראות מתאימות; לכן אם הוא נכשל בשני השלבים הללו זה מראה שהשרשראות שציירתי באיור למעלה אכן קיימות. והן אכן מנתקות את האדומים מהצהוב/כחול בהתאמה. אז מה בכל זאת ייכשל? ייכשל שלב הצביעה-מחדש של האדומים. ליתר דיוק, הצביעה-מחדש הראשונה תעבוד, אבל אז הצביעה-מחדש של האדום השני עלולה להיכשל באופן מזעזע. קשה לנו לראות את זה במבט ראשון כי האינטואיציה שלנו חושבת על שתי הצביעות-מחדש הללו בתור משהו שקורה “באותו הזמן” (או, במקרה שלי, פשוט חשבתי עליהן בתור “ברור שאפשר לעשות אותן” ואפילו לא הקדשתי מחשבה לביצוע שלהן בפועל ומה שיתרחש במהלכו).&lt;/p&gt;

&lt;p&gt;הנה הסבר עקרוני על מה ש&lt;strong&gt;יכול&lt;/strong&gt; להשתבש. האיור שלמעלה מטעה כי הוא נותן תחושה ששרשראות הצהוב-ירוק והכחול-ירוק הן נפרדות לגמרי זו מזו. אבל האמת העצובה היא שהן עלולות להיות “מעורבבות” - אחת מהן יכולה לעבור דרך השניה ואז לצאת חזרה מהצד השני, כי הן יכולות לשתף צמתים ירוקים. הנה דוגמא אפשרית:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3719 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/color5cross-1.png&quot; alt=&quot;&quot; width=&quot;770&quot; height=&quot;786&quot; /&gt;&lt;/p&gt;

&lt;p&gt;כאן הקו המקווקו העבה הוא השרשרת הצהובה-ירוקה ואילו הקו המקווקו הדק יותר הוא השרשרת הכחולה-ירוקה, ואנחנו רואים בבירור איך השרשרת הצהובה-ירוקה חותכת את השניה. ואנחנו גם רואים משהו עוד יותר גרוע בפנים - הצומת האדום הימני יותר, זה ש&lt;strong&gt;אמור&lt;/strong&gt; להיות מוחלף לצהוב, מחובר לאחד מהצמתים הצהובים על השרשרת הצהובה-ירוקה. זה אומר שכאשר נחליף אותו לצהוב, &lt;strong&gt;נשבור את השרשרת&lt;/strong&gt; הצהובה-ירוקה - חלק ממנה יהפוך לאדום. ברגע שבו זה קרה, ההיפוך של האדום &lt;strong&gt;השני&lt;/strong&gt;, זה שאמור להפוך לכחול, עשוי לגרום לכחול הנוסף שמחובר לצומת המרכזי שלנו להתהפך. כלומר, &lt;strong&gt;ההיפוך של האדום הראשון יצר שרשרת אדום-כחול שלא הייתה קיימת קודם&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;בואו נראה את זה קורה:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3720 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/12/color5cross2.png&quot; alt=&quot;&quot; width=&quot;805&quot; height=&quot;821&quot; /&gt;&lt;/p&gt;

&lt;p&gt;כאן הפכתי את האדום הימני לצהוב, ולכן את שכנו הצהוב לאדום. עכשיו הוספתי עוד צמתים כדי להראות כיצד יכולה להתקבל שרשרת אדום-כחול חדשה, שמנצלת את האדום החדש שזה עתה נוצר. ה”מצור” של השרשרת הצהובה-ירוקה נפרץ.&lt;/p&gt;

&lt;p&gt;מבלבל? אוי ואבוי, בהחלט כן. אין פלא שלקחו 11 שנים לשים לב לשגיאה של קאמפ. אבל מרגע שנתגלתה השגיאה, למה בעצם להקדיש זמן ומאמץ להוכחה של קאמפ? ובכן:&lt;/p&gt;
&lt;ol&gt;
 	&lt;li&gt;כי היא יפה.&lt;/li&gt;
 	&lt;li&gt;כי היא עדיין מוכיחה משפט לא טריוויאלי באפס מאמץ - שאפשר לצבוע כל מפה מישורית &lt;strong&gt;בחמישה&lt;/strong&gt; צבעים, והיא גם מציעה שיטה לכך (ההוכחה לכך מטפלת במקרה של צומת עם חמישה שכנים בדיוק כמו שטיפלנו במקרה של צומת עם ארבעה שכנים - מוצאים שני זוגות שלפחות בין אחד מהם לא יכולה להיות שרשרת, ו&quot;נפטרים&quot; מצבע אחד בעזרתו).&lt;/li&gt;
 	&lt;li&gt;כי הרעיונות שלה הם גם מה שהשתמשו בו בהוכחה ה&quot;אמיתית&quot;, רק בוריאציה הרבה יותר מסובכת.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span style=&quot;font-size: 1rem;&quot;&gt;אבל הדבר הכי מעניין בהוכחה השגויה הזו הוא ש&lt;/span&gt;&lt;strong style=&quot;font-size: 1rem;&quot;&gt;בזכות השגיאה&lt;/strong&gt;&lt;span style=&quot;font-size: 1rem;&quot;&gt;, המשפט כל כך מפורסם. אם ההוכחה של קאמפ הייתה עובדת, קרוב לודאי שמשפט ארבעת הצבעים היה נשכח שם, בתור אנקדוטה חביבה עם הוכחה לא עמוקה במיוחד. העובדה שההוכחה נפלה, ובצורה כל כך מתסכלת, ונדרשה כל כך הרבה יותר עבודה כדי להוכיח את המשפט לבסוף - זה כבר מהדהד את ה”הוכחה הנפלאה” שפייר דה פרמה טען שיש לו למשפט שלו וסביר להניח שכללה גם כן טעות עדינה שהטעתה בזמנו את פרמה. זה מה שהפך את משפט ארבעת הצבעים למפורסם כל כך.&lt;/span&gt;&lt;/p&gt;</content><author><name></name></author><category term="משפט ארבעת הצבעים" /><summary type="html">בפוסט הקודם הצגתי את בעיית ארבעת הצבעים: בהינתן מפה - כלומר, חלוקה של איזור מסויים לתתי-איזורים שלכל אחד מהם אני קורא “מדינה” - להוכיח שדי בארבעה צבעים כדי לצבוע אותה כך שלא יהיו שתי מדינות עם גבול משותף הצבועות באותו הצבע. בפוסט הזה אני אציג את ההוכחה השגויה של קאמפ למשפט הזה - הוכחה יפה עם רעיונות מוצלחים למדי שנפלה בשל נקודה עדינה שקל לפספס.</summary></entry><entry><title type="html">משפט ארבעת הצבעים (חלק א’)</title><link href="http://localhost:4000/blog/2018/11/10/four_color_theorem_intro" rel="alternate" type="text/html" title="משפט ארבעת הצבעים (חלק א')" /><published>2018-11-10T17:37:42+02:00</published><updated>2018-11-10T17:37:42+02:00</updated><id>http://localhost:4000/blog/2018/11/10/four_color_theorem_intro</id><content type="html" xml:base="http://localhost:4000/blog/2018/11/10/four_color_theorem_intro">&lt;p&gt;הסיפור של משפט ארבעת הצבעים כולל את כל מה שסיפור מתמטי טוב צריך לכלול: בעיה מתמטית שהיא פשוטה להחריד לניסוח, ונראית פשוטה באופן מתעתע; סיפור נחמד על האופן שבו התגלתה; הוכחה שצצה יחסית מהר, אבל אחרי למעלה מעשור התגלה שהיא שגויה; מאה שנים נוספות שנדרשו עד למציאת פתרון נכון; והעובדה שהפתרונות שיש כיום הם לא מספקים ברמה זו או אחרת, כך שעדיין יש תקווה למשהו טוב יותר - ושלל הוכחות “קצרות ופשוטות” ושגויות לחלוטין שעדיין מופרחות לאוויר מדי פעם. בקיצור, כל החומרים שהפכו את המשפט האחרון של פרמה לסיפור כל כך מוצלח. אז למה בעצם לא כתבתי על זה עד היום?&lt;/p&gt;

&lt;p&gt;ובכן, עם המשפט האחרון של פרמה, המצב שלי קל: אני יכול להודות ללא חשש בכך שאני לא מבין כלום מההוכחה שלו, שנחשבת למסובכת מאוד (אבל נכונה) ומסתמכת על מתמטיקה עמוקה ביותר, אבל במשפט ארבעת הצבעים זה לא המצב - ההוכחה מבוססת על רעיונות פשוטים יחסית אבל היא עדיין מפחידה מאוד, מסיבות שאסביר בהמשך. כך יצא שפשוט התרחקתי מהמשפט הזה כמו מאש ולא הרגשתי שאני מסוגל לכתוב עליו לפני שאאזור אומץ ואקרא קצת יותר.&lt;/p&gt;

&lt;p&gt;ובכן, קראתי. כמובן, לא קראתי מספיק כדי שאוכל להסביר את ההוכחות בצורה מלאה, אבל אני מקווה שעד שאסיים פה נבין לא רע את הבעיה והאופן שבו נפתרה. בואו נתחיל עם פוסט של סקירה היסטורית ונתקדם משם.&lt;/p&gt;

&lt;p&gt;את משפט ארבעת הצבעים קל מאוד לנסח: &lt;strong&gt;בהינתן מפה, אפשר לצבוע כל מדינה בה באחד מבין ארבעה צבעים, כך שאין שתי מדינות עם גבול משותף שהן באותו הצבע&lt;/strong&gt;. הניסוח הזה לא מדויק בכלל, אפילו שגוי, אבל בתור תיאור ראשוני זה מספיק טוב. מי שרוצים ניסוח פורמלי מדויק יכולים לקבל אחד פשוט כמעט באותה המידה, במחיר שימוש בכמה מושגים מתמטיים בסיסיים: &lt;strong&gt;כל גרף מישורי הוא &lt;/strong&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;strong&gt;-צביע&lt;/strong&gt;. כבר בניסוחים הללו אנחנו רואים שאפשר לדבר על המשפט הזה בשתי צורות שונות: אפשר לדבר על “מפות” ואפשר לדבר על “גרפים” ושתי דרכי ההתבוננות הללו מועילות.&lt;/p&gt;

&lt;p&gt;בואו נתבונן במפה של ארצות הברית, שנבחרה בגלל הצורה הנחמדה שבה היא מתחלקת למדינות, וריבוי המדינות שבה (והיא כנראה לא תהיה ידידותית מספיק לעיוורי צבעים ועמכם הסליחה):&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3687 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/11/900px-Map_of_USA_with_state_names_2.svg_.png&quot; alt=&quot;&quot; width=&quot;900&quot; height=&quot;556&quot; /&gt;&lt;/p&gt;

&lt;p&gt;המדינות של ארצות הברית במפה הזו נצבעו בארבעה צבעים: סגול (אורגון), ירוק (קליפורניה), צהוב (אריזונה) ואדום (נבדה - בואו נניח שזה אדום). חוץ מזה יש גם כחול בשביל הים וחום בשביל קנדה ומקסיקו, אבל בואו לא נחשיב את זה כחלק מהתמונה. ה”חוק” שמאחורי הצביעה הזו הוא ששתי מדינות עם גבול משותף לא יהיו צבועות באותו הצבע, פשוט כי אז יהיה יותר קשה להבדיל ביניהן. אפשר כמובן גם לצבוע את המפה עם יותר צבעים:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-3689&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/11/USA.jpg&quot; alt=&quot;&quot; width=&quot;272&quot; height=&quot;185&quot; /&gt;&lt;/p&gt;

&lt;p&gt;וככה היא אולי נראית יותר יפה, אבל אם אנחנו רוצים להיות חסכוניים, אנחנו שואלים כמה צבעים אנחנו &lt;strong&gt;חייבים&lt;/strong&gt; כדי לשמר את עניין ה”אין שתי מדינות שכנות עם אותו צבע”. האם יכלנו לצבוע את מפת ארה”ב עם שלושה צבעים בלבד? ובכן, לא. בואו נסתכל לצורך כך על החוף המערבי. קליפורניה ונבדה הן מדינות שכנות ולכן חייבות להיות צבועות בצבעים שונים, למשל ירוק ואדום כמו בתמונה. כעת, אריזונה היא שכנה משותפת של קליפורניה ונבדה ולכן לא יכולה להיות צבועה בצבעים שלהן, לכן היא צריכה להיות צבועה בצבע חדש, למשל צהוב כמו בתמונה. האם אפשר להסתפק בירוק, אדום וצהוב, ולא לצבוע אף מדינה בסגול?&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3687 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/11/900px-Map_of_USA_with_state_names_2.svg_.png&quot; alt=&quot;&quot; width=&quot;900&quot; height=&quot;556&quot; /&gt;&lt;/p&gt;

&lt;p&gt;בתמונה יוטה נצבעה בסגול, אבל היא לא שכנה של קליפורניה כך שבעצם אפשר לצבוע אותה בירוק (אבל לא בצהוב או אדום כי היא שכנה של נבדה ואריזונה). זה מכריח את איידהו להיות צבועה בצהוב (שכנה של יוטה שהפכנו לירוקה, ונבדה האדומה), אבל אז אנחנו נתקעים באורגון: אורגון היא שכנה של שלוש מדינות שכולן נצבעו בצבעים שונים מתוך הכרח: קליפורניה, נבדה ואיידהו. היא חייבת להיות צבועה בצבע רביעי.&lt;/p&gt;

&lt;p&gt;המשחק הנחמד הזה מלמד אותנו את השיעור הראשון על ענייני הצביעה הללו. הנה יש לנו מצב שבו שלושה צבעים לא מספיקים למרות שבשום מקום אין ארבע מדינות ש&lt;strong&gt;כולן שכנות זו של זו&lt;/strong&gt;. הנה “מפה” מלאכותית שבה יש ארבע מדינות שכולן שכנות:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3690 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/11/220px-Fourcolorsmap.svg_.png&quot; alt=&quot;&quot; width=&quot;220&quot; height=&quot;225&quot; /&gt;&lt;/p&gt;

&lt;p&gt;מבט אחד בתמונה הזו מבהיר שחייבים ארבעה צבעים לפחות עבור מפות מסויימות, אבל זה לא מבהיר שהצורך הזה עלול לבוא אלינו בצורה &lt;strong&gt;ערמומית&lt;/strong&gt; שכזו; כלומר, שהדוגמאות הנגדיות יהיו מתוחכמות ולאו דווקא יכילו את מה שנראה כמו המכשול המובן מאליו של המשפט. זה לקח שאנשים שונים ומשונים שניסו להוכיח את המשפט למדו על בשרם (או חמור מכך, לא למדו אותו למרות שהיו צריכים).&lt;/p&gt;

&lt;p&gt;מה שהמשפט מבטיח לנו הוא שלא משנה כמה ערמומיים נהיה אם ננסה לבנות מפות שהן מאתגרות לצביעה בכוונה - לא נוכל לבנות מפה שחייבים לפחות חמישה צבעים עבורה. תמיד די בארבעה.&lt;/p&gt;

&lt;p&gt;עכשיו, משהבנו מה בעצם אומר המשפט, בואו נדבר קצת על ההיסטוריה שלו. אולי אפשר לחשוב שהעניין הזה של ארבעת הצבעים יהיה ידוע כבר אלפי שנים, כי אנשים מתעסקים עם מפות כבר אלפי שנים, אבל בואו נודה באמת - לאף אחד לא אכפת ממספר הצבעים הקטן ביותר שנדרש כדי לצבוע מפות. לא קורה כלום אם מפה נצבעת בחמישה צבעים במקום בארבעה. כך שהמשפט הוא מלכתחילה קוריוז אינטלקטואלי, וככזה האדם הראשון שידוע לנו שהמציא אותו היה צעיר בן 21 בשם פרנסיס גאתרי, סטודנט למתמטיקה שלימים הפך גם לפרופסור למתמטיקה, שישב וצבע לו את מפת המחוזות של אנגליה (למה? למה אנשים צובעים את מפת המחוזות של אנגליה?)&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;alignnone wp-image-3691 size-full&quot; src=&quot;https://gadial.net/wp-content/uploads/2018/11/800px-England_Admin_Counties_1965-1974.png&quot; alt=&quot;&quot; width=&quot;800&quot; height=&quot;992&quot; /&gt;&lt;/p&gt;

&lt;p&gt;לא לגמרי ברור אם לגאתרי הייתה הוכחה כלשהי בראש או שהוא סתם ניחש שהמשפט אמור להתקיים. הוא סיפר עליו לאחיו, שהיה אז סטודנט של המתמטיקאי אוגסטוס דה-מורגן, והאח בא אל דה-מורגן אחרי השיעור ושאל אותו על המשפט הזה - האם הוא כבר ידוע, ואיך מוכיחים אותו. לדה-מורגן לא היה מושג, אבל היה לו משהו חשוב יותר - הוא &lt;strong&gt;התלהב&lt;/strong&gt; מהשאלה הזו. הוא ניסה לפתור אותה, ולא הצליח; והוא סיפר עליה לכל מי שרק היה מוכן להקשיב. העדות הכתובה הראשונה לקיום הבעיה היא מכתב ששלח דה-מורגן למתמטיקאי המילטון ב-23 באוקטובר, 1852, ובו הוא תיאר את הבעיה וביקש סיוע. משעשע לראות עד כמה דה-מורגן חשב שיש פה פתרון פשוט שחומק ממנו: הוא סיים את המכתב ב-&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p dir=&quot;ltr&quot;&gt;If you retort with some very simple case which makes me out a stupid animal, I think I must do as the Sphynx did.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;למרבה הצער, המילטון לא התלהב מהבעיה כמו דה-מורגן; כל התשובה שהוא טרח לתת לו הייתה&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p dir=&quot;ltr&quot;&gt;I am not likely to attempt your “quaternion of colours” very soon.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;כנראה שהמילטון חשב שהשאלה הזו היא סתם שטות זניחה, וכך יצא שהוא פספס הזדמנות להיות השם החשוב ביותר שמקושר לאחת מהבעיות המפורסמות במתמטיקה.&lt;/p&gt;

&lt;p&gt;למרות שדה-מורגן הפיץ את הבעיה בקרב עמיתיו, קשה לומר שנרשמה אצלם התלהבות גדולה או שהתחיל מחקר פעיל של הבעיה. עברו כמעט שלושים שנים מרגע שדה-מורגן שמע על הבעיה ועד שקרה איתה משהו משמעותי. דה-מורגן עצמו נפטר ב-1871 והבעיה נשכחה קצת, עד שבשנת 1878 המתמטיקאי ארתור קיילי ניסה לעורר בה קצת עניין חדש, וכנראה אז היא הגיעה לתשומת לבו של &lt;strong&gt;אלפרד קמפ&lt;/strong&gt;, שהוא כנראה הגיבור המרכזי הראשון בסיפור שלנו. כמו פרמה, שהיה הדמות המרכזית בסיפור של המשפט האחרון של פרמה, כך גם קמפ היה מתמטיקאי חובב; במקצועו הוא היה עורך דין, אבל הוא פרסם מאמרים מתמטיים פה ושם, ובשנת 1879 הוא פרסם מאמר שבו הוכיח את משפט ארבעת הצבעים. על פניו נראה היה שזה מסיים את הסיפור - ההוכחה של קמפ הייתה פשוטה למדי, אם כי לא טריוויאלית, כך שנראה היה שאפשר לסגור את הסיפור בתור קוריוז מתמטי נחמד שבא על פתרונו בצורה טובה.&lt;/p&gt;

&lt;p&gt;אבל 11 שנים לאחר מכן, ב-1890, התגלתה בהוכחה שגיאה, וזה התחיל את מחול השדים של שמונים השנים הבאות.&lt;/p&gt;

&lt;p&gt;אני הולך להציג את ההוכחה של קמפ במלואה בהמשך, כמו גם את השגיאה; לדעתי אלו הדברים שחשוב ביותר להכיר כשמדברים על המשפט. בשביל מה לטרוח לדבר על הוכחה שגויה? ובכן, כי ההוכחה הייתה &lt;strong&gt;כמעט נכונה&lt;/strong&gt;. היו בה רעיונות טובים מאוד, שהוכיחו את השימושיות שלהם בתורת הגרפים באופן כללי ובהקשר למשפט ארבעת הצבעים בפרט. היא גם מאוד משכנעת במבט ראשון, ולא קל להראות שהיא שגויה, מה שמסביר למה נדרש יותר מעשור כדי להפיל אותה. הכי חשוב: ההוכחות שנמצאו עד כה למשפט ארבעת הצבעים משתמשות בדיוק באותו רעיון מרכזי כמו ההוכחה של קמפ, וההבדל היחיד הוא בפרטים. אם נבין מה קמפ עשה, אז בכך הבנו את רוב מה שנדרש כדי לקבל את התמונה הגדולה של המשפט.&lt;/p&gt;

&lt;p&gt;קצת אחרי קמפ, ובעקבות ההוכחה שלו, פרסם מתמטיקאי בשם פיטר טייט “הוכחה” אחרת של המשפט, שהתבססה על רעיונות שונים לגמרי. לרוע המזל, היא הייתה &lt;strong&gt;ממש&lt;/strong&gt; שגויה בכל מני דרכים לא נעימות; למרות זאת היא הייתה מעניינת בפני עצמה, אבל לא אדבר עליה לעת עתה, כי היא לא רלוונטית לאופן שבו המשפט הוכח בסופו של דבר.&lt;/p&gt;

&lt;p&gt;בשנת 1890 מצא מתמטיקאי בשם פרסי הייווד את השגיאה בהוכחה של קמפ. במאמר שפרסם הוא הציג דוגמא נגדית, שאראה בהמשך; חלק מהעניין בסיפור הוא שלמצוא דוגמא נגדית להוכחה של קמפ זה &lt;strong&gt;קשה&lt;/strong&gt; (או לכל הפחות, לא טריוויאלי). הייווד כן הצביע על כך שההוכחה השגויה של קמפ מספיקה, אחרי תיקון כלשהו של הטיעון, כדי להוכיח שמספיקים &lt;strong&gt;חמישה&lt;/strong&gt; צבעים כדי לצבוע כל מפה. קמפ עצמו הודה בטעותו ואמר שאינו יודע איך לתקן את ההוכחה, וגם הייווד לא ידע; קצת קשה להאשים אותם, כי גם כיום אין לנו מושג איך אפשר להוכיח את המשפט הזה בלי להשתמש בעזרים שפשוט לא היו זמינים לקמפ ולהייווד.&lt;/p&gt;

&lt;p&gt;הבעיה לא נשכחה במאה ה-20, אבל גם לא הושגו בה התקדמויות או פריצות דרך משמעותיות. הרעיון שהוביל בסופו של דבר להוכחה היה של מתמטיקאי גרמני בשם היינריך האש; מה בדיוק היה הרעיון שלו אתאר בהמשך, אבל בבסיסו הוא המשך של הגישה של קאמפ. בשנת 1967 סטודנט בשם וולפגנג האקן ששמע הרצאה של האש בנושא התחיל להתעניין בנושא ולעבוד עליו ביחד עם האש. מה שהיה ברור כבר אז הוא שהשיטה של האש, למרות שיש בה פוטנציאל, תדרוש חישובים ידניים מזעזעים ברמת העומס שלהם (אני בכוונה לא אומר “ קושי” או “מורכבות”). האש והאקן לא הצליחו להגיע להסכמה איך בדיוק לפתח את השיטה והפסיקו את שיתוף הפעולה ב-1972, ואילו האקן המשיך בנסיונותיו עם מתמטיקאי אחרי, קנת אפל, כששניהם בטוחים ש&lt;strong&gt;ניתן&lt;/strong&gt; להתמודד עם העומס החישובי האדיר בעזרת יצורים שכבר לא בדיוק היו חדשים באותה התקופה אבל השימוש שלהם בהוכחות במתמטיקה היה מוגבל -&lt;strong&gt; מחשבים&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;ההוכחה של האקן ואפל מתבססת על מציאת קבוצה של יצורים שנקראים &lt;strong&gt;קונפיגורציות ניתנות לצמצום&lt;/strong&gt; (תרגום שלי ל-Reducible Configurations). קונפיגורציה ניתנת לצמצום היא מעין “תת-מפה” שהיא בעלת התכונה הבאה: אם מפה &lt;strong&gt;כלשהי&lt;/strong&gt; מכילה קונפיגורציה ניתנת לצמצום אז אפשר להחליף את המפה הזו במפה קטנה יותר (פחות מדינות), כך שאם המפה החדשה ניתנת לצביעה בארבעה צבעים, כך גם המפה המקורית. באופן שקול לוגית - אם המפה &lt;strong&gt;המקורית&lt;/strong&gt; לא הייתה ניתנת לצביעה בארבעה צבעים (כלומר, היא הייתה &lt;strong&gt;דוגמא נגדית למשפט ארבעת הצבעים&lt;/strong&gt;) אז גם המפה החדשה, הקטנה יותר, הייתה דוגמא נגדית שכזו. במילים אחרות, קונפיגורציה ניתנת לצמצום &lt;strong&gt;אינה&lt;/strong&gt; יכולה להופיע בדוגמא נגדית &lt;strong&gt;מינימלית&lt;/strong&gt; (מבחינת מספר הצמתים) למשפט ארבעת הצבעים.&lt;/p&gt;

&lt;p&gt;יש הרבה קונפיגורציות ניתנות לצמצום - ההוכחה של קאמפ התבססה עליהן; למשל, “טבעת” שמורכבת משלוש מדינות שכל אחת מהן היא שכנה של האחרות היא קונפיגורציה שכזו, ונבין יותר טוב למה אחרי שנתעמק בהוכחה של קאמפ. מה שסוגר את הוכחת משפט ארבעת הצבעים הוא מציאה של קבוצת קונפיגורציות ש&lt;strong&gt;לפחות אחת מהן&lt;/strong&gt; חייבת להופיע בכל גרף שהוא &lt;strong&gt;דוגמא נגדית מינימלית&lt;/strong&gt; למשפט ארבעת הצבעים. למה? כי כאמור, כל המהות של קונפיגורציה היא ש&lt;strong&gt;בדוגמא נגדית מינימלית&lt;/strong&gt;, קונפיגורציה ניתנת לצמצום &lt;strong&gt;אינה יכולה להופיע&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;הבניה של קבוצת קונפיגורציות כזו שאכן תצליח לפתור את המשפט הייתה עניין ארוך ומתמשך של ניסוי וטעיה; בכל פעם שבה התגלתה בעיה, היה צריך לשנות קצת את הקבוצה ולראות מה קורה עכשיו. המחשב היה חלק נכבד בתהליך העבודה הזה, עד שלבסוף נמצאה קבוצה ללא תקלות שאכן מוכיחה את המשפט ב-1976 פרסמו האקן ואפל את המאמר שלהם בנושא. אז מה בעצם הבעיה?&lt;/p&gt;

&lt;p&gt;הבעיה היא שפתרון כזה לא דרש מחשב רק כדי למצוא אותו; נדרש מחשב גם כדי &lt;strong&gt;לבדוק&lt;/strong&gt; אותו, וזו בדיקת מחשב בלתי טריוויאלית בעליל.&lt;/p&gt;

&lt;p&gt;יש תיאור פופולרי &lt;strong&gt;ושגוי לחלוטין&lt;/strong&gt; של ההוכחה שהפיל גם אותי בפח בשעתו. הוא מופיע, בין היתר, בויקיפדיה העברית; מאז כתיבת הערך על משפט ארבעת הצבעים באוגוסט 2003 ועד לזמן כתיבת פוסט זה בנובמבר 2018 נאמר בערך שמה שהאקן ואפל עשו היה להראות “שכל מפה אפשרית שקולה לאחת מבין 1,936 מפות שונות” ואז “הריצו תוכנית מחשב במשך 1,200 שעות כדי להראות שכל אחת ממפות אלה ניתנת לצביעה בארבעה צבעים” (הנה &lt;a href=&quot;https://he.wikipedia.org/w/index.php?title=%D7%9E%D7%A9%D7%A4%D7%98_%D7%90%D7%A8%D7%91%D7%A2%D7%AA_%D7%94%D7%A6%D7%91%D7%A2%D7%99%D7%9D&amp;amp;oldid=23770840&quot;&gt;קישור קבוע&lt;/a&gt; לגרסה הזו מ-2018 של הערך שבו הטעות מופיעה; אני מקווה שבזמן שאתם קוראים שורות אלו הטעות כבר תוקנה!). הבעיה הבסיסית בתיאור השגוי הזה היא ש&lt;strong&gt;קל מאוד לבדוק&lt;/strong&gt; צביעה של מפות, אם מישהו אחר כבר טרח ומצא צביעה שכזו. זו דוגמא קלאסית למה שנקרא “בעיה NP-שלמה”; בעיה שכנראה קשה למצוא לה פתרון, אבל אם מישהו אחר כבר מצא, אז לבדוק את הפתרון שלו זה טריוויאלי. אם כל מה שההוכחה הייתה כוללת הוא הוכחה ידנית של שקילות לאוסף גדול של מפות, ואז צביעה מפורשת של כל אחת מהמפות הללו, אני לא חושב שלמישהו הייתה בעיה עם ההוכחה.&lt;/p&gt;

&lt;p&gt;אבל מכיוון שהבדיקה היא ממש לא עד כדי כך פשוטה, אנחנו ניצבים בפני שתי בעיות:&lt;/p&gt;
&lt;ol&gt;
 	&lt;li&gt;בעיה פרקטית: כיצד אפשר להיות משוכנעים שההוכחה &lt;strong&gt;נכונה&lt;/strong&gt; ולא שנפלה טעות כלשהי בתוכנית המחשב שבודקת אותה?&lt;/li&gt;
 	&lt;li&gt;בעיה פילוסופית: האם הוכחה שאדם לא יכול לקרוא ולהבין בעצמו עדיין יכולה להיקרא &quot;הוכחה&quot;?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;אל הבעיה הפילוסופית אני לא רוצה להיכנס בכלל, כי הבלוג הזה מנסה באופן כללי מלהיכנס לעובי הקורה של פילוסופיה של המתמטיקה (ואני גם לא מתיימר להבין בה משהו). דעתי האישית היא שזו הוכחה סבבה מהבחינה הזו, אבל אני לא מנסה לשכנע אף אחד. אני כן מסכים שיש בפירוש הבדל עקרוני בין הוכחה כמו זו ובין הוכחות “עצומות ממדים אבל ניתנות לקריאה בידי אדם” כדוגמת ההוכחה של המשפט האחרון של פרמה או משפט המיון של חבורות פשוטות, אבל אני לא בטוח שההבדל הזה בכלל משחק לטובת ההוכחות הללו.&lt;/p&gt;

&lt;p&gt;הבעיה הפרקטית, לעומת זאת, היא מהותית, אבל אני לא חושב שהבעיה פה היא ספציפית השימוש ב&lt;strong&gt;מחשב&lt;/strong&gt; אלא באופן כללי הסיבוך של ההוכחות - גם הוכחת המשפט האחרון של פרמה עלולה להכיל טעות שהבודקים פספסו (ואכן, בהוכחה המקורית של וויילס הייתה טעות שוויילס עצמו לא הבחין בה ורק הבודק שם לב אליה; ועכשיו תחשבו שהבודק היה מתבלבל כמו וויילס עצמו). השאלה המהותית היא עד כמה קל &lt;strong&gt;לשחזר&lt;/strong&gt; את ההוכחה; הרי מתמטיקאית טובה שקוראת הוכחה בעצם מוכיחה את המשפט מחדש בראש, תוך שהיא נעזרת בתוכן של ההוכחה שהיא קוראת (בכל הוכחה יש השמטות של פרטים, והמתמטיקאית היא מיומנת מספיק כדי להשלים את החורים בעצמה). במקרה של ההוכחה של האקן ואפל, המשמעות היא שמישהו צריך לכתוב מחדש את תוכניות המחשב שבודקות את מה שזה לא יהיה, ולהריץ אותן בעצמו, ולראות שהעסק עבד.&lt;/p&gt;

&lt;p&gt;עשו את זה.&lt;/p&gt;

&lt;p&gt;האם זה מספיק כדי לסמוך על ההוכחה? ואולי יש איזה באג מהותי בתוכניות? ואולי יש איזה באג משותף לכל המעבדים בכל המחשבים שהריצו את התוכניות? ואולי ואולי ואולי. כשזה מגיע למחשבים אנחנו נוטים אוטומטית להיות סקפטיים יותר.&lt;/p&gt;

&lt;p&gt;מאז 1976 עבר קצת זמן והמחשבים קצת השתפרו. מה המצב היום? ובכן, טוב קצת יותר. ככל הידוע לי, עדיין אין שום הוכחה שלא דורשת מחשב, אבל ב-1996 נמצאה הוכחה שמתבססת על קבוצה פשוטה יותר של קונפיגורציות. זה כבר מעודד מאוד - זה מראה שאפשר להוכיח את המשפט ביותר מדרך אחת (למרות שהרעיון הבסיסי זהה) ולכן הסיכוי לטעות נראה זעום בהרבה. אבל מה שבאמת משקיט את החששות האישיים שלי היא &lt;a href=&quot;http://www.ams.org/notices/200811/tx081101382p.pdf&quot;&gt;הוכחה&lt;/a&gt; שנכתבה ב-2005 למערכת Coq. המערכת הזו היא מה שנקרא “proof assistant” - זו תוכנית מחשב שאפשר לכתוב בה הוכחות בלוגיקה פורמלית מסויימת, דמויית שפת תכנות, והמערכת יכולה לבדוק אוטומטית את ההוכחות. כלומר - תוכנית המחשב שבודקת את ההוכחה של משפט ארבעת הצבעים היא לא קוד מחשב שנכתב אד-הוק למטרה זו, אלא מערכת ספציפית שהושקעה עבודה רבה בתכנון שלה, בבדיקה שהיא חפה משגיאות וביסודות המתמטיים שהיא נשענת עליה. ההוכחה הזו היא כנראה גם הדוגמא ה”רצינית” ביותר שאני מכיר לשימוש במערכת כמו Coq.&lt;/p&gt;

&lt;p&gt;אם כן, זה הסיפור של משפט ארבעת הצבעים; מעין תם-ולא-נשלם שמבחינתי הוא בהחלט סיום מספק אבל אני מבין את אלו שמתנגדים אליו. “הוכחה פשוטה למשפט ארבעת הצבעים”, כמו “הוכחה פשוטה למשפט האחרון של פרמה” תמשיך להיות גביע קדוש שאפשר לשאוף אליו וכנראה שלא נמצא לעולם (חוק כללי במתמטיקה, אבל כזה שנכון בפרט בקומבינטוריקה: הוכחות יפות הן לא משהו שמובטח לנו משמיים ולפעמים פשוט אין כאלו). בפוסט הבא ננסה להבין מה הלך בהוכחה של קאמפ ולמה היא נכשלה; הכשלון המפואר הזה יספיק כדי לתת לנו הבנה טובה מאוד של איך הוכיחו את המשפט בסופו של דבר.&lt;/p&gt;</content><author><name></name></author><category term="משפט ארבעת הצבעים" /><summary type="html">הסיפור של משפט ארבעת הצבעים כולל את כל מה שסיפור מתמטי טוב צריך לכלול: בעיה מתמטית שהיא פשוטה להחריד לניסוח, ונראית פשוטה באופן מתעתע; סיפור נחמד על האופן שבו התגלתה; הוכחה שצצה יחסית מהר, אבל אחרי למעלה מעשור התגלה שהיא שגויה; מאה שנים נוספות שנדרשו עד למציאת פתרון נכון; והעובדה שהפתרונות שיש כיום הם לא מספקים ברמה זו או אחרת, כך שעדיין יש תקווה למשהו טוב יותר - ושלל הוכחות “קצרות ופשוטות” ושגויות לחלוטין שעדיין מופרחות לאוויר מדי פעם. בקיצור, כל החומרים שהפכו את המשפט האחרון של פרמה לסיפור כל כך מוצלח. אז למה בעצם לא כתבתי על זה עד היום?</summary></entry></feed>