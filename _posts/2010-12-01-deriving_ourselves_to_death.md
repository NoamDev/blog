---
id: 876
title: "היה זה תענוג לגזור"
date: 2010-12-01 23:14:56
layout: post
categories: 
  - אנליזה מתמטית
tags: 
  - גם טכני זה כיף!
  - חשבון אינפיניטסימלי
  - טכני
  - מתמטיקה תיכונית
  - נגזרת
---
<a href="http://www.gadial.net/2010/11/21/derivative/">באחד הפוסטים הקודמים</a> הצגתי את מושג הנגזרת, אך כל מה שעשיתי היה להציג את ההגדרה הפורמלית; אם כל מה שיש לנו הוא את ההגדרה הזו, אנחנו עדיין לא יכולים לעשות הרבה. בפוסט הזה אני רוצה להציג את הכלים והתוצאות הבסיסיות על חישוב פרקטי של נגזרות, כדי לשכנע אתכם בשני דברים: ראשית, שחישוב נגזרות הוא אכן פרקטי; ושנית, שהוא ממש <strong>כיף</strong>. אנחנו יוצאים להרפתקאה בג'ונגל כשאנחנו חמושים רק במספריים, ומסתבר שנוכל לפלס לעצמנו את דרך המלך באופן הזה.

אם כן, כזכור, הגדרתי נגזרת עבור פונקציות ממשיות, {% equation %}f:\mathbb{R}\to\mathbb{R}{% endequation %}, באופן הבא: {% equation %}f^{\prime}\left(x_{0}\right)=\lim_{h\to0}\frac{f\left(x_{0}+h\right)-f\left(x_{0}\right)}{h}{% endequation %}. הנגזרת הוגדרה באופן "נקודתי" - בהינתן נקודה {% equation %}x_{0}{% endequation %} מצאנו את ערך הנגזרת של הפונקציה בנקודה הזו. עם זאת, מה שאנחנו באמת רוצים הוא נגזרת "גלובלית" - בהינתן נוסחה עבור הפונקציה {% equation %}f{% endequation %}, להסיק ממנה נוסחה עבור הפונקציה {% equation %}f^{\prime}{% endequation %}. זה מה שנעשה בפוסט הזה.

בואו נתחיל ישר מללכלך את הידיים עם פונקציה פשוטה לדוגמה: {% equation %}f\left(x\right)=x^{n}{% endequation %}. כאן אפשר לחשב את הנגזרת לכל {% equation %}x_{0}{% endequation %} ישירות מתוך הגדרת הנגזרת, תוך שימוש ב<strong><a href="http://www.gadial.net/2010/06/22/newton_binom/">בינום של ניוטון</a>: </strong>{% equation %}\left(x_{0}+h\right)^{n}=x_{0}^{n}+n\cdot x_{0}^{n-1}h+\sum_{i=2}^{n}{n \choose i}x_{0}^{n-i}h^{i}{% endequation %}. הסכום המפחיד באגף ימין אינו כל כך חשוב - כל מה שחשוב בו הוא שהוא <strong>מתחלק </strong>ב-{% equation %}h^{2}{% endequation %}. מדוע? כי כעת, מהו {% equation %}\frac{f\left(x_{0}+h\right)-f\left(x_{0}\right)}{h}{% endequation %}, לכל נקודה {% equation %}x_{0}{% endequation %} שרק תרצו? ובכן, {% equation %}f\left(x_{0}+h\right)=\left(x_{0}+h\right)^{n}{% endequation %} ואילו {% equation %}f\left(x_{0}\right)=x_{0}^{n}{% endequation %} ולכן לאחר ביצוע החיסור של שניהם נקבל במונה {% equation %}n\cdot x_{0}^{n-1}h+\sum_{i=2}^{n}{n \choose i}x_{0}^{n-i}h^{i}{% endequation %}. אחרי חלוקה ב-{% equation %}h{% endequation %} נקבל {% equation %}n\cdot x_{0}^{n-1}+\sum_{i=2}^{n}{n \choose i}x_{0}^{n-i}h^{i-1}{% endequation %} - ושימו לב, הסכום שבאגף ימין עדיין מתחלק ב-{% equation %}h{% endequation %}, כלומר אפשר לחשוב עליו בתור "{% equation %}h{% endequation %} כפול משהו". אבל עכשיו אנו משאיפים את {% equation %}h{% endequation %} לאפס, וזה גורם לסכום להיעלם (כי הדבר היחיד בו שמשתנה הוא {% equation %}h{% endequation %} השואפת לאפס). נשארנו עם {% equation %}n\cdot x_{0}^{n-1}{% endequation %}. זה מוביל אותנו לנוסחה הכללית: אם {% equation %}f\left(x\right)=x^{n}{% endequation %} אז {% equation %}f^{\prime}\left(x\right)=nx^{n-1}{% endequation %}. בפרט שימו לב שהנגזרת של {% equation %}f\left(x\right)=x{% endequation %} היא {% equation %}f^{\prime}\left(x\right)=1{% endequation %} ושהנגזרת של פונקציה קבועה - {% equation %}f\left(x\right)=c=c\cdot x^{0}{% endequation %} - היא {% equation %}f^{\prime}\left(x\right)=0{% endequation %} (התוצאה הזו מתאימה לאינטואיציה שלנו - אם ערך הפונקציה קבוע אז הפונקציה מתארת "עמידה במקום", כך שהמהירות של הפונקציה היא אפס).

בפני עצמה התוצאה הזו אולי לא עד כדי כך מעניינת, אך בשילוב עם תכונה נוספת של הנגזרת, התוצאה הזו נותנת לנו את הנגזרת של <strong>כל הפולינומים</strong> (ש<a href="http://www.gadial.net/2010/09/22/functions_overview_for_calculus/">כפי שהזכרתי כאן בעבר</a>, הן אולי הפונקציות המעניינות הבסיסיות ביותר). מהי התכונה? מה שמכונה <strong>הלינאריות</strong> של הנגזרת, וניתן לתאר בפשטות כך: אם {% equation %}f,g{% endequation %} הן שתי פונקציות גזירות (כלומר, יש להן נגזרת בכל נקודה בתחום שמעניין אותנו), אז {% equation %}\left(f+g\right)^{\prime}=f^{\prime}+g^{\prime}{% endequation %}. כמו כן, אם {% equation %}c{% endequation %} הוא מספר ממשי קבוע, אז {% equation %}\left(cf\right)^{\prime}=cf^{\prime}{% endequation %}. במילים: נגזרת של סכום היא סכום הנגזרות, ונגזרת של {% equation %}f{% endequation %}-כפולה-בקבוע היא הנגזרת של {% equation %}f{% endequation %} כשהיא (הנגזרת) מוכפלת באותו קבוע. מכאן מגיעים מיידית לנוסחה הבאה: {% equation %}\left(\sum_{k=0}^{n}a_{k}x^{k}\right)^{\prime}=\sum_{k=1}^{n}k\cdot a_{k}x^{k-1}{% endequation %}. ההוכחה של תכונת הלינאריות היא עסק מיידי אם כבר יש לנו את התכונה הדומה עבור גבולות; מתקיים:

{% equation %}\left(f+g\right)^{\prime}\left(x_{0}\right)=\lim_{h\to0}\frac{\left(f+g\right)\left(x_{0}+h\right)-\left(f+g\right)\left(x_{0}\right)}{h}=\lim_{h\to0}\frac{f\left(x_{0}+h\right)+g\left(x_{0}+h\right)-f\left(x_{0}\right)-g\left(x_{0}\right)}{h}{% endequation %}

{% equation %}=\lim_{h\to0}\frac{f\left(x_{0}+h\right)-f\left(x_{0}\right)}{h}+\lim_{h\to0}\frac{g\left(x_{0}+h\right)-g\left(x_{0}\right)}{h}=f^{\prime}\left(x_{0}\right)+g^{\prime}\left(x_{0}\right){% endequation %}

הוכחה דומה עובדת גם עבור כפל בקבוע. המעבר היחיד כאן שהוא מתוחכם הוא הפירוק של הגבול האחד לשני גבולות - זה דורש הצדקה לא טריוויאלית, אך גם לא קשה במיוחד.

המזל שלנו לא נגמר כאן. מסתבר שקל לחשב גם את הנגזרת של מכפלת פונקציות: {% equation %}\left(fg\right)^{\prime}=f^{\prime}g+fg^{\prime}{% endequation %}. איך מגיעים לנוסחה הזו? שוב, על פי הגדרה:

{% equation %}\left(fg\right)^{\prime}\left(x_{0}\right)=\lim_{h\to0}\frac{\left(fg\right)\left(x_{0}+h\right)-\left(fg\right)\left(x_{0}\right)}{h}=\lim_{h\to0}\frac{f\left(x_{0}+h\right)g\left(x_{0}+h\right)-f\left(x_{0}\right)g\left(x_{0}\right)}{h}{% endequation %}

כאן אנחנו לכאורה נתקעים כי לא ברור איך אפשר לפשט את הנוסחה עוד; אבל אז נחלץ לעזרתנו טריק שימושי מאוד במתמטיקה - לחבר ולהחסיר את אותו איבר. אם אנחנו רוצים להחסיר מ-{% equation %}f\left(x_{0}+h\right)g\left(x_{0}+h\right){% endequation %} איבר כך שנקבל בסופו של דבר משהו שנראה כמו הנגזרת של {% equation %}f{% endequation %}, מה עלינו להחסיר? די בבירור זה חייב להיות {% equation %}f\left(x_{0}\right)g\left(x_{0}+h\right){% endequation %}, כי {% equation %}f\left(x_{0}\right){% endequation %} הוא הגורם שחסר לנו כדי לקבל משהו שנראה כמו נגזרת של {% equation %}f{% endequation %}, ו-{% equation %}g\left(x_{0}+h\right){% endequation %} הוא הגורם המשותף שאנחנו רוצים להוציא כדי להישאר רק עם {% equation %}f{% endequation %} בסוגריים.

בקיצור, אחרי חיסור וחיבור של האיבר הזה, אנו מקבלים את:

{% equation %}\lim_{h\to0}\frac{f\left(x_{0}+h\right)g\left(x_{0}+h\right)-f\left(x_{0}\right)g\left(x_{0}+h\right)+f\left(x_{0}\right)g\left(x_{0}+h\right)-f\left(x_{0}\right)g\left(x_{0}\right)}{h}{% endequation %}

{% equation %}=\lim_{h\to0}\frac{g\left(x_{0}+h\right)\left(f\left(x_{0}+h\right)-f\left(x_{0}\right)\right)+f\left(x_{0}\right)\left(g\left(x_{0}+h\right)-g\left(x_{0}\right)\right)}{h}{% endequation %}

ואת זה ניתן לפשט עוד קצת עם כללי הכפל והחיבור של גבולות. למשל, ברור ש-{% equation %}\lim_{h\to0}\frac{f\left(x_{0}\right)\left(g\left(x_{0}+h\right)-g\left(x_{0}\right)\right)}{h}=f\left(x_{0}\right)g^{\prime}\left(x_{0}\right){% endequation %}. הבעיה היא דווקא במחובר הראשון, שעבורו קל לראות ש-{% equation %}\lim_{h\to0}\frac{g\left(x_{0}+h\right)\left(f\left(x_{0}+h\right)-f\left(x_{0}\right)\right)}{h}=f^{\prime}\left(x_{0}\right)\cdot\lim_{h\to0}g\left(x_{0}+h\right){% endequation %}, אבל מהו {% equation %}\lim_{h\to0}g\left(x_{0}+h\right){% endequation %}? היינו רוצים להגיד שאפשר פשוט להציב {% equation %}h=0{% endequation %} ולקבל {% equation %}g\left(x_{0}\right){% endequation %}, אבל זה נכון רק אם הפונקציה {% equation %}g{% endequation %} <a href="http://www.gadial.net/2010/10/26/limit_of_functions_and_continuity/">רציפה</a> ב-{% equation %}x_{0}{% endequation %}...

ובכן, יש לנו מזל, כי משפט בסיסי בחדו"א הוא שכל פונקציה שגזירה בנקודה כלשהי גם רציפה בה. לא אוכיח אותו פורמלית אלא אתן אינטואיציה פשוטה: אם {% equation %}\lim_{h\to0}g\left(x_{0}+h\right)\ne g\left(x_{0}\right){% endequation %} אז {% equation %}\lim_{h\to0}\left(g\left(x_{0}+h\right)-g\left(x_{0}\right)\right)\ne0{% endequation %}, אבל אז הגבול {% equation %}\lim_{h\to0}\frac{g\left(x_{0}+h\right)-g\left(x_{0}\right)}{h}{% endequation %} אינו קיים בכלל שכן המונה שואף לקבוע, ואילו המכנה שואף לאפס, ולכן הגבול שואף לאינסוף (יותר גרוע אפילו - לאינסוף ולמינוס אינסוף, כתלות בשאלה אם {% equation %}h{% endequation %} חיובי או שלילי). מכאן שכדי שהנגזרת תהיה קיימת הפונקציה חייבת להיות רציפה: הערך של {% equation %}g\left(x_{0}+h\right){% endequation %} מתקרב לערך של {% equation %}g\left(x_{0}\right){% endequation %}, וכל השאלה שעליה עונה הנגזרת היא <strong>כמה מהר</strong> ההתקרבות הזו מתבצעת.

סיכום ביניים: אם אנחנו יודעים את הנגזרות של {% equation %}f{% endequation %} ושל {% equation %}g{% endequation %} אנחנו יודעים גם את הנגזרות של {% equation %}f+g{% endequation %} ושל {% equation %}f\cdot g{% endequation %} (כפל בסקלר הוא מקרה פרטי של כפל בפונקציה - סקלר הוא פונקציה קבועה). זה כבר נותן לנו הרבה כוח, כי פונקציות רבות ניתנות לתיאור באמצעות חיבור וכפל (למעשה, אפשר למצוא את הנגזרת של {% equation %}f\left(x\right)=x^{n}{% endequation %} גם בעזרת נוסחה זו בלבד, תוך ביצוע אינדוקציה והסתמכות על הידע שהנגזרת של {% equation %}f\left(x\right)=x{% endequation %} היא {% equation %}1{% endequation %}, מה שקל מאוד להוכיח מההגדרה; אבל אני חושב שההוכחה הכללית נחמדה יותר ולכן הבאתי אותה). אלא שעדיין לא הצגתי את מה שנותן לנו את הכי הרבה כוח: יש נוסחה גם עבור נגזרת של <strong>הרכבה</strong> של פונקציות. וכאן אולי כדאי להסביר למה אני מתכוון.

בואו נסתכל שניה על הפונקציה {% equation %}f\left(x\right)=x^{2}+3x{% endequation %}. וכעת בואו ונסתכל על הפונקציה {% equation %}h\left(x\right)=\sin^{2}x+3\sin x{% endequation %}. אלו שתי פונקציות שונות, אבל מאוד דומות באופיין: נראה כאילו {% equation %}h\left(x\right){% endequation %} היא מה שמתקבל מ-{% equation %}f\left(x\right){% endequation %} אם במקום {% equation %}x{% endequation %} "מציבים" את {% equation %}\sin x{% endequation %}. אם כן, אפשר לסמן {% equation %}h\left(x\right)=f\left(\sin x\right){% endequation %}. בדרך קצת יותר מסודרת נוכל להגדיר פונקציה {% equation %}g\left(x\right)=\sin x{% endequation %} ואז יש הגיון בסימון {% equation %}h\left(x\right)=f\left(g\left(x\right)\right){% endequation %}. לדבר הזה - {% equation %}f\left(g\left(x\right)\right){% endequation %} - קוראים <strong>הרכבה</strong> של {% equation %}f{% endequation %} על {% equation %}g{% endequation %} ומסמנים אותו ב-{% equation %}f\circ g{% endequation %} לפעמים (ולפעמים ב-{% equation %}g\circ f{% endequation %} כדי לבלבל סטודנטים, כתלות בהקשר ובספר הלימוד - זו הסיבה שבגללה אני נמנע משימוש בסימון הזה). הרכבה היא כלי רב עוצמה מאוד לבנייה של פונקציות מסובכות מתוך פונקציות פשוטות, והעובדה שיש לנו נוסחה פשוטה עבור נגזרת של הרכבת פונקציות היא לא פחות מנס. הנוסחה, שמכונה "כלל השרשרת", היא {% equation %}\left[f\left(g\left(x\right)\right)\right]^{\prime}=f^{\prime}\left(g\left(x\right)\right)\cdot g^{\prime}\left(x\right){% endequation %}. במילים - גוזרים את {% equation %}f{% endequation %}, ממשיכים להציב בה את {% equation %}g\left(x\right){% endequation %} כמקודם, ובנוסף לכך כופלים את הכל בנגזרת של {% equation %}g\left(x\right){% endequation %} (זו <strong>אינה</strong> מכפלת הנגזרת של {% equation %}f{% endequation %} בנגזרת של {% equation %}g{% endequation %} מכיוון שאת {% equation %}f^{\prime}{% endequation %} מחשבים בנקודה {% equation %}g\left(x\right){% endequation %} בעוד שאת {% equation %}g^{\prime}{% endequation %} מחשבים בנקודה {% equation %}x{% endequation %} - כלומר, הן לא מחושבות באותה הנקודה).

דוגמה פשוטה: אם {% equation %}f\left(x\right)=x^{2}{% endequation %} ו-{% equation %}g\left(x\right)=\left(x+1\right){% endequation %} אז ההרכבה שלהן היא {% equation %}\left(x+1\right)^{2}{% endequation %}. כעת, {% equation %}f^{\prime}\left(x\right)=2x{% endequation %} ו-{% equation %}g^{\prime}\left(x\right)=1{% endequation %} ולכן מכלל השרשרת עולה שהנגזרת של הפונקציה המורכבת היא {% equation %}2\left(x+1\right)\cdot1=2x+2{% endequation %}. אתם מוזמנים לפתוח את הסוגריים של {% equation %}\left(x+1\right)^{2}{% endequation %} ולחשב את הנגזרת באופן ישיר אם לא השתכנעתם.

הייתי שמח להוכיח את כלל השרשרת כאן, אבל בניגוד להוכחות שכבר הראיתי, ההוכחה של כלל השרשרת דורשת יותר תחכום, בגלל כל מני בעיות עדינות שצצות בהוכחה נאיבית "ישר על פי ההגדרה" שלה. גם להיכנס לבעיות יקח אותנו רחוק מדי. זה לא שההוכחה עד כדי כך מסובכת - היא לא; אבל הפוסט הזה ארוך מספיק בלעדיה. אם כן, קחו בינתיים את כלל השרשרת כנתון.

אילו עוד פונקציות אנחנו מכירים? הזכרתי קצת פונקציות בשעתו - {% equation %}\sin x,\cos x,\ln x,e^{x}{% endequation %}... לכולן קל למצוא נגזרת, אם כי בכל אחד מהמקרים ההוכחה דורשת כלים שמותאמים למקרה הספציפי שאותו תוקפים (כך למשל בשביל הפונקציות הטריגונומטריות צריך את הגבול {% equation %}\lim_{h\to0}\frac{\sin h}{h}=1{% endequation %} שה<a href="http://www.gadial.net/2008/01/20/lim_sin_x_over_x/">הוכחה שלו היא סיפור שלם</a>). מגלים, כי {% equation %}\left(\sin x\right)^{\prime}=\cos x{% endequation %}, {% equation %}\left(\cos x\right)^{\prime}=-\sin x{% endequation %}, {% equation %}\left(\ln x\right)^{\prime}=\frac{1}{x}{% endequation %} ו-{% equation %}\left(e^{x}\right)^{\prime}=e^{x}{% endequation %} (זוהי התכונה המיוחדת של פונקצית האקספוננט - נגזרתה שווה לעצמה).

מכאן אפשר לפתח עוד כמה דברים מעניינים. למשל, מהי הנגזרת של {% equation %}a^{x}{% endequation %} כאשר {% equation %}a{% endequation %} הוא מספר ממשי חיובי כלשהו, לאו דווקא {% equation %}e{% endequation %}? ובכן, אפשר תמיד לכתוב {% equation %}a=e^{\ln a}{% endequation %} (למה? תרגיל למי שדברים כאלו מעניינים אותו) ולכן {% equation %}a^{x}=e^{x\cdot\ln a}{% endequation %}. קיבלנו כאן <strong>הרכבה</strong> של שתי פונקציות: {% equation %}f\left(x\right)=e^{x}{% endequation %} ו-{% equation %}g\left(x\right)=x\ln a{% endequation %}. הנגזרת של {% equation %}g\left(x\right){% endequation %} היא {% equation %}\ln a{% endequation %} ולכן נקבל {% equation %}\left(a^{x}\right)^{\prime}=\ln a\cdot e^{x\ln a}=a^{x}\ln a{% endequation %}. זו עוד דוגמה לכוח שאנו מקבלים מכלל השרשרת.

בואו נראה עוד דוגמה. עד כה הצלחתי לטפל בפונקציה {% equation %}f\left(x\right)=x^{n}{% endequation %} רק במקרה שבו {% equation %}n{% endequation %} היה מספר שלם אי שלילי. מה על מספרים שליליים? ובכן, ב-{% equation %}n=-1{% endequation %}, כלומר בפונקציה {% equation %}f\left(x\right)=\frac{1}{x}{% endequation %}, ניתן לטפל באופן ישיר על פי ההגדרה:

{% equation %}\lim_{h\to0}\frac{\frac{1}{x_{0}+h}-\frac{1}{x_{0}}}{h}=\lim_{h\to0}\frac{\frac{x_{0}-x_{0}-h}{x_{0}\left(x_{0}+h\right)}}{h}=\lim_{h\to0}-\frac{1}{x_{0}^{2}+hx_{0}}=-\frac{1}{x_{0}^{2}}{% endequation %}

מקבלים, אם כן, ש-{% equation %}\left(\frac{1}{x}\right)^{\prime}=-\frac{1}{x^{2}}{% endequation %}. כעת, כל מספר שלם שלילי אפשר לכתוב כ-{% equation %}-n{% endequation %} כאשר {% equation %}n{% endequation %} הוא שלם חיובי, ואם {% equation %}h\left(x\right)=x^{-n}{% endequation %} אז אפשר גם לכתוב {% equation %}h\left(x\right)=\left(x^{n}\right)^{-1}=\frac{1}{x^{n}}{% endequation %}. במילים אחרות, יש לנו כאן את ההרכבה של הפונקציה {% equation %}g\left(x\right)=x^{n}{% endequation %} בתוך הפונקציה {% equation %}f\left(x\right)=\frac{1}{x}{% endequation %}. כלל השרשרת יניב לנו כאן את התוצאה {% equation %}h^{\prime}\left(x\right)=-\frac{1}{g^{2}\left(x\right)}\cdot g^{\prime}\left(x\right)=-\frac{nx^{n-1}}{x^{2n}}=-nx^{-\left(n+1\right)}{% endequation %}. במילים אחרות, הנוסחה {% equation %}\left(x^{m}\right)^{\prime}=mx^{m-1}{% endequation %} עובדת גם כאשר {% equation %}m{% endequation %} שלילי. בדרך גם ראינו מהי באופן כללי הנגזרת של פונקציה מהצורה {% equation %}\frac{1}{g\left(x\right)}{% endequation %}: היא פשוט {% equation %}-\frac{g^{\prime}\left(x\right)}{g^{2}\left(x\right)}{% endequation %}. בשילוב עם הנוסחה לנגזרת של מכפלת פונקציות, מקבלים את הנוסחה למנה של פונקציות: {% equation %}\left(\frac{f}{g}\right)^{\prime}=\left(f\cdot\frac{1}{g}\right)^{\prime}=\frac{f^{\prime}}{g}-\frac{fg^{\prime}}{g^{2}}=\frac{f^{\prime}g-fg^{\prime}}{g^{2}}{% endequation %}. בפרט, שימו לב שמכיוון שאנו יודעים לגזור כל פולינום, כעת אנחנו יכולים לגזור גם כל <strong>פונקציה רציונלית</strong> (פונקציה שהיא מנת שני פולינומים).

טרם דיגדגנו אפילו את קצה הגבול של מה שעוד נוכל לסחוט מכלל השרשרת! בואו נעבור לדבר על {% equation %}x^{n}{% endequation %} כאשר {% equation %}n{% endequation %} יכול להיות גם שבר. בפרט, מהו {% equation %}x^{\frac{1}{n}}{% endequation %}? לצורך כך אני שוב אוכיח תוצאה כללית יותר - נגזרת של פונקציה הופכית. אם {% equation %}f\left(x\right){% endequation %} היא פונקציה, אז אומרים ש-{% equation %}g\left(x\right){% endequation %} היא הפונקציה ההופכית שלה אם ההרכבה של שתיהן היא פונקצית הזהות, כלומר הפונקציה {% equation %}h\left(x\right)=x{% endequation %}. למשל, אם {% equation %}f\left(x\right)=x^{n}{% endequation %} אז {% equation %}g\left(x\right)=x^{\frac{1}{n}}{% endequation %} היא ההופכית שלה. אם כן, נניח שאני יודע את הנגזרת של {% equation %}f\left(x\right){% endequation %} - מה הנגזרת של ההופכית שלה {% equation %}g\left(x\right){% endequation %}?

כאן נשתמש בכלל השרשרת ובכך שאנחנו יודעים שהנגזרת של {% equation %}x{% endequation %} היא 1. מכיוון ש-{% equation %}g{% endequation %} היא ההופכית של {% equation %}f{% endequation %} אז {% equation %}f\left(g\left(x\right)\right)=x{% endequation %}, ולכן על ידי גזירת שני האגפים נקבל {% equation %}f^{\prime}\left(g\left(x\right)\right)g^{\prime}\left(x\right)=1{% endequation %}, כלומר {% equation %}g^{\prime}\left(x\right)=\frac{1}{f^{\prime}\left(g\left(x\right)\right)}{% endequation %}. ובמילים: נגזרת הפונקציה ההופכית של {% equation %}f{% endequation %} בנקודה {% equation %}x{% endequation %} שווה לאחד חלקי הנגזרת של {% equation %}f{% endequation %} בנקודה {% equation %}g\left(x\right){% endequation %}. שימו לב - צריך להציב את {% equation %}g{% endequation %} בתוך הנגזרת של {% equation %}f{% endequation %}!

זו הייתה נקודה שבלבלה אותי מאוד כשרק למדתי את הנושא לראשונה. ניקח לדוגמה את {% equation %}g\left(x\right)=\sqrt{x}{% endequation %} שהיא ההופכית של {% equation %}f\left(x\right)=x^{2}{% endequation %}. הנגזרת של {% equation %}f\left(x\right){% endequation %} היא {% equation %}f^{\prime}\left(x\right)=2x{% endequation %}, ולכן התבלבלתי וחשבתי ש-{% equation %}\left(\sqrt{x}\right)^{\prime}=\frac{1}{2x}{% endequation %}, אך זה לא נכון; מה ששכחתי לעשות הוא להציב את {% equation %}g\left(x\right){% endequation %} בתוך הנגזרת של {% equation %}f{% endequation %}. אחרי שעושים זאת, מקבלים את הנוסחה הנכונה {% equation %}\left(\sqrt{x}\right)^{\prime}=\frac{1}{2\sqrt{x}}{% endequation %}. ובאופן כללי מקבלים, בצורה לא מפתיעה, ש-{% equation %}\left(x^{\frac{1}{n}}\right)^{\prime}=\frac{1}{n}x^{\frac{1}{n}-1}{% endequation %}. כלומר, הנוסחה {% equation %}\left(x^{m}\right)^{\prime}=mx^{m-1}{% endequation %} נכונה לכל {% equation %}m{% endequation %} רציונלי. למעשה, זה מסיים את העניין גם עבור כל חזקה {% equation %}m{% endequation %} ממשית, שכן חזקה שכזו מוגדרת בתור גבול שמשתמש בחזקות רציונליות, ושיקולי רציפות מעבירים את נוסחת הנגזרת מהמקרה הרציונלי למקרה הממשי הכללי. אם זה נשמע כמו ג'יבריש, לא נורא; גם זה משהו שאני לא רוצה להיכנס אליו.

אם נקבל לרגע את ההנחה ש-{% equation %}\ln x{% endequation %} היא פונקציה שהוגדרה מראש כך שנגזרתה תהיה {% equation %}\frac{1}{x}{% endequation %} (זו, למעשה, ההגדרה המקובלת בספרות), ושאנו יודעים כי {% equation %}e^{x}{% endequation %} היא ההופכית שלה, אז קל להסיק מהכלל של נגזרת הפונקציה ההופכית את התוצאה {% equation %}\left(e^{x}\right)^{\prime}=e^{x}{% endequation %}: {% equation %}\left(e^{x}\right)^{\prime}=\frac{1}{1/e^{x}}=e^{x}{% endequation %}. זה היה שימוש טיפשי למדי בכלל הנגזרת של ההופכית. בואו ניישם אותו למשהו קצת יותר רציני - הפונקציות ההופכיות לפונקציות הטריגונומטריות. מכיוון שהפונקציה ההופכית האהובה עלי בהקשר הזה היא {% equation %}\mbox{atan\ensuremath{\left(x\right)}}{% endequation %}, ההופכית של {% equation %}\tan\left(x\right){% endequation %}, בואו נבין איך באמת מחשבים את הנגזרת של {% equation %}\tan\left(x\right){% endequation %} קודם - הרי אמרתי (ללא הוכחה) מה הנגזרות של סינוס וקוסינוס אבל לא שלו; זאת מכיוון ש-{% equation %}\tan\left(x\right)=\frac{\sin x}{\cos x}{% endequation %} על פי הגדרתו.

אם כן, נגזור על פי כלל המנה שראינו קודם ונקבל {% equation %}\tan^{\prime}\left(x\right)=\frac{\sin^{\prime}\left(x\right)\cos\left(x\right)-\sin\left(x\right)\cos^{\prime}\left(x\right)}{\cos^{2}\left(x\right)}=\frac{\cos^{2}x+\sin^{2}x}{\cos^{2}x}=\frac{1}{\cos^{2}x}{% endequation %}, כשהמעבר האחרון מתבסס על הזהות הטריגונומטרית היסודית {% equation %}\sin^{2}x+\cos^{2}x=1{% endequation %} (זוהי אחת מאותן נוסחאות בודדות שבאמת <strong>כדאי לזכור בעל פה</strong>, אבל היא גם בעלת משמעות אינטואיטיבית פשוטה - על פי משפט פיתגורס, זהו המרחק מראשית הצירים של נקודה שנמצאת על מעגל היחידה, בזווית {% equation %}x{% endequation %} עם ציר ה-{% equation %}x{% endequation %}; ובוודאי שמרחק כל נקודה על מעגל היחידה מהראשית הוא 1...).

{% equation %}\frac{1}{\cos^{2}x}{% endequation %} זה נחמד אבל קצת בעייתי כשבאים למצוא את הנגזרת של {% equation %}\mbox{atan}{% endequation %}. לכן נחזור שניה אחורה בזמן לרגע שבו הייתה לנו הזהות {% equation %}\frac{\cos^{2}x+\sin^{2}x}{\cos^{2}x}{% endequation %}: אפשר לפרק את הסכום לשניים ולקבל ש-{% equation %}\tan^{\prime}\left(x\right)=1+\tan^{2}\left(x\right){% endequation %}. אם כן:

{% equation %}\mbox{atan}^{\prime}\left(x\right)=\frac{1}{\tan^{\prime}\left(\mbox{atan}\left(x\right)\right)}=\frac{1}{1+\tan^{2}\left(\mbox{atan}\left(x\right)\right)}=\frac{1}{1+x^{2}}{% endequation %}

כשהמעבר האחרון נובע מכך ש-{% equation %}\mbox{atan}{% endequation %} היא ההופכית של {% equation %}\tan{% endequation %}. שימו לב לתוצאה המעניינת כאן - {% equation %}\frac{1}{1+x^{2}}{% endequation %} היא פונקציה שכלל לא מזכירה פונקציות טריגונומטריות, ואיכשהוא היא נבעה מתוכן. זה אומר שאם נלך "בכיוון ההפוך" (ואדבר על זה יותר בקרוב), הפונקציות הטריגונומטריות יצוצו לנו באופן טבעי גם אם אנחנו בכלל לא מתעסקים בגאומטריה.

אם כן, בואו נעשה סיכום ביניים קצר. אנחנו יודעים לגזור: את כל הפולינומים והפונקציות הרציונליות, את כל הפונקציות הטריגונומטריות וההופכיות שלהן, את כל הפונקציות המעריכיות והלוגריתמיות, וכל פונקציה שמתקבלת מהפונקציות הללו על ידי חיבור, כפל, הרכבה או הוצאת הופכי. יותר מכך: אנחנו יודעים לעשות את כל זה באופן <strong>אלגוריתמי</strong>: אין שום קושי מהותי בכתיבת תוכנית מחשב שבהניתן פונקציה, מסובכת ככל שתהיה, שנבנתה באמצעות הפונקציות הבסיסיות שהצגתי ואוסף פעולות הבניה שהצגתי, תחשב את הנגזרת שלה (ואכן, קיימות תוכנות רבות שעושות זאת). זו אולי הסיבה שבגללה כל כך אוהבים לתת מטלות גזירה מעיקות בבית הספר - זה אלגוריתמי ובית הספר עוסק בעיקר בשינון כמה אלגוריתמים טכניים לפתרון בעיות. בעולם האמיתי גזירות מסובכות זה משהו שעדיף להשאיר למחשב...

אם כן, בפעולת הגזירה אנחנו שולטים די טוב. זה מעביר אותנו באופן טבעי לשאלה הבאה - מה עם הפעולה <strong>ההפוכה מגזירה</strong>? כלומר, אם נותנים לנו פונקציה ואומרים לנו שהיא הנגזרת של משהו, האם אנו יכולים לגלות את המשהו? אקרא כאן למשהו "האנטי-נגזרת" של הפונקציה, אם כי יש לו שם מקובל יותר שאתאר בפוסט הבא (כרגע אני לא רוצה לקלקל את אלמנט ההפתעה עבור המעטים שיופתעו - ומי שלא יופתע כבר יודע מה השם הנכון ממילא). אל תתבלבלו בין זה ובין מציאת נגזרת של פונקציה הפוכה. אני מתכוון, למשל, לכך שהפונקציה {% equation %}x^{3}{% endequation %} מתקבלת על ידי גזירה של... מפתה אולי לומר {% equation %}x^{4}{% endequation %}, אבל הנגזרת של {% equation %}x^{4}{% endequation %} היא {% equation %}4x^{3}{% endequation %}, כך ש-{% equation %}x^{3}{% endequation %} מתקבלת מגזירה של {% equation %}\frac{x^{4}}{4}{% endequation %}. כאן אנחנו כבר רואים שהעסק טיפה מלוכלך.

באופן כללי במתמטיקה אם פעולה היא קלה, אפילו אלגוריתמית, לביצוע בכיוון אחד זה לא אומר הרבה על הכיוון השני. דוגמה קלאסית היא פעולת הכפל: קל לחשב אלגוריתמית את {% equation %}a\cdot b{% endequation %} אם יש לנו את {% equation %}a,b{% endequation %}, אבל אם נותנים לנו את המכפלה בלבד - כמה עבודה תידרש לנו כדי לפרק אותה לגורמים? התשובה היא שכל כך הרבה עבודה, ששיטות ההצפנה הפופולריות ביותר כיום מתבססות על כך שמדובר על בעיה קשה. כל ענף הקריפטוגרפיה המודרנית, למעשה, מתבסס על קיום פונקציות "חד-כיווניות" - שקל לחשב, אבל קשה להפוך (בהערת אגב אעיר ש"קל" ו"קשה" בהקשר הזה הם מושגים שמוגדרים באופן מתמטי מדויק ומסויים שאולי לא תואם לחלוטין את האינטואיציה שלנו; ויותר מכך, שלא באמת הוכח קיום של פונקציות שכאלו, אלא רק יש לנו אוסף של "חשודות" כדוגמת הזוג כפל/פירוק לגורמים).

הפונקציה {% equation %}\frac{1}{1+x^{2}}{% endequation %} היא מקרה בוחן לקושי של היפוך פעולת הגזירה. כדי לדעת מה ייתן אותה כנגזרת, צריך "להמציא" את הפונקציות הטריגונומטריות. אם כן, גם אם יש לנו פונקציה שנבנתה באופן "נחמד" מתוך פונקציות אלמנטריות זה כלל לא מבטיח שהאנטי-נגזרת שלה תורכב מפונקציות שכאלו בעצמה באופן נחמד. דוגמה קלאסית לכך היא הפונקציה החשובה עד למאוד שהיא האנטי-נגזרת של {% equation %}e^{x^{2}}{% endequation %} (למעשה של פונקציה טיפה יותר מסובכת אך אין הבדל מהותי) - אפשר <strong>להוכיח</strong> כי את האנטי-נגזרת הזו פשוט לא ניתן לכתוב באמצעות הפונקציות האלמנטריות ופעולות החיבור-כפל-הרכבה. מכאן שברור שאין מה לדבר על <strong>נוסחה</strong> שבהינתן הרכבה של שתי פונקציות פשוטות, תיתן את האנטי-נגזרת של ההרכבה באמצעות האנטי-נגזרות של הפונקציות המורכבות. אפילו כלל דומה עבור כפל פונקציות אין ממש (יש <strong>משהו</strong> שאולי אתאר בהמשך; הוא אמנם מפשט את העניינים לפעמים אבל זו לא נוסחה פשוטה כמו שהייתה עבור הנגזרת). רק פעולות החיבור והכפל בסקלר מתנהגות יפה כמקודם.

העיסוק בשאלת "בהינתן נגזרת, מהי האנטי-נגזרת?" יתגלה כקשור באופן הדוק למושג האינטרל שהצגתי <a href="http://www.gadial.net/2010/11/27/integral/">בפוסט הקודם</a>. כדי לא לספיילר יותר, אעצור כאן ואחכה לפוסט הבא. אני מקווה שנהניתם מהטיול בג'ונגל הגזירות ושאתם מסכימים שהצלחנו לסלול בו, פחות או יותר, כביש נוח למדי (אם כי, כמובן, טרם נוסעים עליו רכבים - עוד לא ממש הבנו איך הנגזרות משפרות לנו את החיים).
