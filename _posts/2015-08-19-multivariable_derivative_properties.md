---
id: 3285
title: "אנליזה וקטורית - תכונות בסיסיות של הנגזרת"
date: 2015-08-19 16:12:28
layout: post
categories: 
  - אנליזה מתמטית
tags: 
  - אנליזה וקטורית
  - נגזרת
---
<a href="http://www.gadial.net/2015/07/05/multivariable_derivatives/">אז הכרנו</a> את הנגזרת של פונקציה {% equation %}f:\mathbb{R}^{n}\to\mathbb{R}^{m}{% endequation %} וראינו איך אפשר לחשב אותה באמצעות נגזרות חלקיות. בואו נעבור עכשיו לכמה תוצאות תיאורטיות כלליות וקלות יחסית, כדי שנתרגל; עד סוף הפוסט נגיע להצגת תוצאה לא טריוויאלית ושימושית - <strong>משפט הפונקציה ההפוכה</strong>. אבל נתחיל מהבסיס.

נתחיל בתכונה אחת שנובעת כמעט מייד מכך שפונקציה היא גזירה אבל טרם הראיתי זאת במפורש, והגיע הזמן כי נשתמש בה בהמשך: רציפות. נזכיר ש-{% equation %}f{% endequation %} היא פונקציה רציפה ב-{% equation %}a{% endequation %} אם {% equation %}\lim_{x\to a}f\left(x\right)=f\left(a\right){% endequation %} - או, באופן שקול, אם {% equation %}\lim_{h\to0}f\left(a+h\right)-f\left(a\right)=0{% endequation %}. זו תכונה מאוד מאוד מועילה במקרים רבים כי היא מבטיחה ש-{% equation %}f{% endequation %} לא יכולה "להתפרע" יותר מדי כשמתקרבים לנקודה כלשהי. עכשיו, אם {% equation %}f{% endequation %} גזירה ב-{% equation %}a{% endequation %} היא גם רציפה שם. למה? כי נניח ש-{% equation %}\lim_{h\to0}\frac{f\left(a+h\right)-f\left(a\right)-Df\left(a\right)h}{\left|h\right|}=0{% endequation %} ועכשיו ננסה לכתוב את {% equation %}\lim_{h\to0}f\left(a+h\right)-f\left(a\right){% endequation %} בעזרת הגבול ההוא:

{% equation %}\lim_{h\to0}f\left(a+h\right)-f\left(a\right)=\lim_{h\to0}\left|h\right|\left[\frac{f\left(a+h\right)-f\left(a\right)-Df\left(a\right)\cdot h}{\left|h\right|}\right]+Df\left(a\right)\cdot h{% endequation %}

ומה קיבלנו פה? גבול שמערב כמה חלקים. ה-{% equation %}\left|h\right|{% endequation %} שואף כמובן לאפס. ה-{% equation %}\left[\frac{f\left(a+h\right)-f\left(a\right)-Df\left(a\right)\cdot h}{\left|h\right|}\right]{% endequation %} גם, כי הנחנו שהפונקציה גזירה. לכן כל המחובר השמאלי שואף לאפס. במחובר הימני אנחנו מקבלים מטריצה קבועה כפול וקטור ששואף לאפס - קל לראות שזה שואף לאפס (טפלו בכל רכיב בנפרד; זו פונקציה רציפה חד ממדית), וזה מסיים את ההוכחה.

עכשיו בואו נעבור לטפל בכללי גזירה שונים ומשונים. ככה זה עובד: הגדרנו פעולה של גזירה על פונקציות. מייד אנו תוהים - מה מניבה הגזירה עבור פונקציות פשוטות יחסית? כמו כן - על פונקציות מוגדרות כל מני פעולות - חיבור, כפל, הרכבה וכדומה. האם קל לדעת את הנגזרת של חיבור פונקציות, אם יודעים את הנגזרת של הפונקציות שמחברים?

פונקציה פשוטה במיוחד היא פונקציה קבועה: {% equation %}f\left(x\right)=c{% endequation %} עבור {% equation %}c\in\mathbb{R}^{m}{% endequation %} קבוע כלשהו. מכיוון שעבור פונקציה ממשית קבועה הנגזרת היא 0, נקבל כאן שהנגזרות החלקיות בכל מקום הן 0. אלו נגזרות חלקיות רציפות, ולכן {% equation %}f{% endequation %} המקורית גזירה והנגזרת שלה היא מטריצת אפסים, כלומר {% equation %}Df\left(a\right)=0{% endequation %} כשכאן 0 היא טרנספורמציית האפס. עוד פונקציה פשוטה במיוחד היא טרנספורמציה לינארית {% equation %}T:\mathbb{R}^{n}\to\mathbb{R}^{m}{% endequation %}. כאן אפילו אין טעם לדבר על נגזרות חלקיות כשההגדרה הבסיסית עובדת מייד ומראה לנו ש-{% equation %}T{% endequation %} היא (כמובן) הדיפרנציאל של עצמה: {% equation %}\lim_{h\to0}\frac{T\left(a+h\right)-T\left(a\right)-T\left(h\right)}{h}=\lim_{h\to0}\frac{T\left(a+h-a-h\right)}{h}=\lim_{h\to0}\frac{T\left(0\right)}{h}=0{% endequation %}. דוגמה לטרנספורמציה לינארית פשוטה שכזו היא חיבור: {% equation %}s\left(x,y\right)=x+y{% endequation %} (זו פונקציה {% equation %}s:\mathbb{R}^{2}\to\mathbb{R}{% endequation %}), אז אנחנו יודעים לגזור גם אותה.

ומה על כפל? {% equation %}p:\mathbb{R}^{2}\to\mathbb{R}{% endequation %} המוגדרת על ידי {% equation %}p\left(x,y\right)=xy{% endequation %}? גזירה חלקית מראה שהנגזרת בנקודה {% equation %}\left(a,b\right){% endequation %} היא {% equation %}\left(b,a\right){% endequation %}, כלומר הדיפרנציאל הוא {% equation %}bx+ay{% endequation %}.

מה שנחמד בפונקציות החיבור והכפל הללו הוא שהן יאפשרו לנו לטפל בחיבור וכפל של פונקציות סקלריות <strong>כלליות</strong>. למשל, אם {% equation %}f,g:\mathbb{R}^{n}\to\mathbb{R}{% endequation %} ואנחנו מגדירים {% equation %}h=f+g{% endequation %}, אז {% equation %}h=s\left(f,g\right){% endequation %}. יש לנו כאן <strong>הרכבה</strong> של פונקציה {% equation %}\mathbb{R}^{n}\to\mathbb{R}^{2}{% endequation %} שבנויה על הזוג {% equation %}\left(f,g\right){% endequation %}, עם הפונקציה {% equation %}s:\mathbb{R}^{2}\to\mathbb{R}{% endequation %}. אם נדע איך לגזור הרכבה, נדע לגזור גם חיבור וכפל של פונקציות, בלי שום מאמץ מחשבתי נוסף מצידנו. אז זו הבעיה שאפתור עכשיו.

הכלל שמתאר את העובדה שהרכבה של פונקציות גזירות הוא גזיר ונותן את הנוסחה לביצוע הגזירה נקרא <strong>כלל השרשרת</strong>. אתם בוודאי מכירים את הגרסה שלו עבור פונקציות ממשיות. בואו נתחיל מלראות אותה. מאוד קל לזכור את הגרסה הזו אם משתמשים בסימון של לייבניץ לגזירת פונקציות: אם {% equation %}f\left(x\right){% endequation %} היא פונקציה עם המשתנה היחיד {% equation %}x{% endequation %}, אז במקום לכתוב {% equation %}f^{\prime}{% endequation %} (בערך הכתיב שבו ניוטון השתמש), אפשר לכתוב {% equation %}\frac{df}{dx}{% endequation %}. אחת הסיבות לכתיב הזה היא שקל לזכור את כלל השרשרת בעזרתו.

אם {% equation %}y:\mathbb{R}\to\mathbb{R}{% endequation %} היא פונקציה, ואנחנו מסתכלים על ההרכבה {% equation %}f\left(y\left(x\right)\right){% endequation %}, אז הנגזרת שלה היא {% equation %}\frac{df}{dx}=\frac{df}{dy}\frac{dy}{dx}{% endequation %}. הבעיה היא - וזה משהו שאני מרגיש ביתר שאת עכשיו, כשאני מנסה לכתוב את הפוסט הזה בצורה מסודרת - שזה כתיב מאוד לא פורמלי שקל לאבד בו דקויות. בואו נסתכל שוב על המשוואה {% equation %}\frac{df}{dx}=\frac{df}{dy}\frac{dy}{dx}{% endequation %}. כאן נראה ש-{% equation %}f{% endequation %} היא פונקציה של שני משתנים שונים: המשתנה {% equation %}x{% endequation %}, באגף שמאל; והמשתנה {% equation %}y{% endequation %}, באגף ימין. אבל הרי {% equation %}y{% endequation %} הוא לא באמת משתנה; הוא פונקציה. ומה שמופיע באגף ימין הוא בעצם לא {% equation %}f{% endequation %}, הוא פונקציה מסובכת יותר שמתקבלת מהרכבת {% equation %}f{% endequation %} על {% equation %}y{% endequation %}. בקיצור, הסימון הזה יכול להיות מועיל אבל הוא גם מסוכן למי שלא שולט בו, ואני אישית לא אוהב אותו. וזה בלי שניכנס בכלל לתלונות על כך שמתרחש פה משהו שנקרא כמו "צמצום דיפרנציאלים" - משהו שבוודאי אין לו משמעות פורמלית עבור רמת החומר שבדרך כלל נלמדת באינפי 1.

אז הנה העסק בכתיב ניוטוני. נניח ש-{% equation %}f,g;\mathbb{R}\to\mathbb{R}{% endequation %} ונגדיר {% equation %}h\left(x\right)=f\left(g\left(x\right)\right){% endequation %} (לפעמים זה מסומן ב-{% equation %}f\circ g{% endequation %} ולפעמים ב-{% equation %}g\circ f{% endequation %}, תלוי איזה ספר אתם קוראים, ויש הגיון מאחורי שתי שיטות הסימון; לכן אני שונא גם את הסימון הזה). אז כלל השרשרת אומר לנו ש-{% equation %}h^{\prime}\left(x\right)=f^{\prime}\left(g\left(x\right)\right)g^{\prime}\left(x\right){% endequation %}. כלומר, הנגזרת ב-{% equation %}x{% endequation %} שווה למכפלה של הנגזרת של {% equation %}g{% endequation %} ב-{% equation %}x{% endequation %}, כפול הנגזרת של {% equation %}f{% endequation %}, אבל לא ב-{% equation %}x{% endequation %} אלא בנקודה שאליה {% equation %}g{% endequation %} מעביר את {% equation %}x{% endequation %} (ההבחנה הזו היא עניין מבלבל). למשל, אם {% equation %}g\left(x\right)=x^{2}{% endequation %} ו-{% equation %}f\left(x\right)=\sin x{% endequation %} אז {% equation %}h\left(x\right)=\sin\left(x^{2}\right){% endequation %} ולכן {% equation %}h^{\prime}\left(x\right)=\cos\left(x^{2}\right)\cdot2x{% endequation %} (ולא {% equation %}\cos\left(x\right)\cdot2x{% endequation %}).

האינטואיציה מאחורי ההוכחה של המקרה החד ממדי די פשוטה. ראשית, בואו ניזכר בכך שאפשר לכתוב את הנגזרת גם בצורה קצת שונה, אולי קצת יותר טבעית:

{% equation %}h^{\prime}\left(a\right)=\lim_{t\to0}\frac{h\left(a+t\right)-h\left(a\right)}{t}=\lim_{x\to a}\frac{h\left(x\right)-h\left(a\right)}{x-a}{% endequation %}

תוך שימוש בניסוח הזה, פשוט מפרקים את הביטוי של הנגזרת למכפלה של שני ביטויי נגזרת מתאימים על ידי כפל וחילוק ב-{% equation %}g\left(x\right)-g\left(a\right){% endequation %}:

{% equation %}h^{\prime}\left(a\right)=\lim_{x\to a}\frac{h\left(x\right)-h\left(a\right)}{x-a}=\lim_{x\to a}\frac{f\left(g\left(x\right)\right)-f\left(g\left(a\right)\right)}{g\left(x\right)-g\left(a\right)}\frac{g\left(x\right)-g\left(a\right)}{x-a}=f^{\prime}\left(g\left(a\right)\right)g^{\prime}\left(a\right){% endequation %}

כמובן, צריך להיות זהירים פה ולהסביר יותר במדויק למה {% equation %}\lim_{x\to a}\frac{f\left(g\left(x\right)\right)-f\left(g\left(a\right)\right)}{g\left(x\right)-g\left(a\right)}=f^{\prime}\left(g\left(a\right)\right){% endequation %}; הרי יכולות לצוץ כל מני בעיות משונות בגלל ש-{% equation %}g{% endequation %} יכולה להתנהג מוזר (מה קורה אם {% equation %}g\left(x\right)=g\left(a\right){% endequation %} עבור {% equation %}x\ne a{% endequation %} כלשהו?). אני מביא את חצי ההוכחה הזו כדי שנרגיש מאיפה הנוסחה מגיעה בכלל. הוכחה מלאה ומדוייקת אני אתן עכשיו למשפט הכללי, עבור פונקציות וקטוריות כלליות; מן הסתם נקבל את כלל השרשרת המקורי בתור מקרה פרטי.

אז איך בכלל מנוסח המשפט הכללי? אם אני רוצה להרכיב את {% equation %}f{% endequation %} על {% equation %}g{% endequation %} אני צריך שהטווח של {% equation %}g{% endequation %} יהיה מאותו מימד כמו התמונה של {% equation %}f{% endequation %}, כלומר {% equation %}g:\mathbb{R}^{n}\to\mathbb{R}^{k}{% endequation %} ואילו {% equation %}f:\mathbb{R}^{k}\to\mathbb{R}^{m}{% endequation %}. שימו לב ל-{% equation %}k{% endequation %} המשותף הזה. עכשיו נגדיר {% equation %}h\left(x\right)=f\left(g\left(x\right)\right){% endequation %} וקיבלנו פונקציה {% equation %}h:\mathbb{R}^{n}\to\mathbb{R}^{m}{% endequation %} נטולת {% equation %}k{% endequation %}. בהינתן {% equation %}a\in\mathbb{R}^{n}{% endequation %} אנחנו רוצים לדעת מהי {% equation %}Dh\left(a\right){% endequation %}; זוהי מטריצה {% equation %}m\times n{% endequation %} (זוכרים? כל שורה של המטריצה היא גרדיאנט של אחד מהרכיבים של {% equation %}h{% endequation %}; יש ל-{% equation %}h{% endequation %} {% equation %}m{% endequation %} רכיבים והאורך של כל גרדיאנט הוא {% equation %}n{% endequation %}). אם נרצה פשוט לקחת את הנוסחה של כלל השרשרת החד ממדי ולכתוב אותה מחדש, נקבל את הדבר הבא:

{% equation %}Dh\left(a\right)=Df\left(g\left(a\right)\right)\cdot Dg\left(a\right){% endequation %}

מה יש לנו כאן? ובכן, {% equation %}Df\left(g\left(a\right)\right){% endequation %} היא מטריצה {% equation %}m\times k{% endequation %} ואילו {% equation %}Dg\left(a\right){% endequation %} היא מטריצה {% equation %}k\times n{% endequation %}. לכן המכפלה שלהן - ובסדר הזה, הנגזרת של {% equation %}f{% endequation %} משמאל והנגזרת של {% equation %}g{% endequation %} מימין - נותנת לנו באמת מטריצה {% equation %}m\times n{% endequation %}. כך שנראה שהנוסחה עובדת! רק יהיה צריך להוכיח אותה. הבעיה היא שמייד ברור שההוכחה האלגנטית של המקרה החד ממדי לא תעבוד. כי אנחנו כבר לא עובדים עם ביטוי נחמד כמו {% equation %}\lim_{x\to a}\frac{h\left(x\right)-h\left(a\right)}{x-a}{% endequation %} אלא עם המפלצת {% equation %}\lim_{t\to0}\frac{h\left(a+t\right)-h\left(a\right)-Dh\left(a\right)t}{\left|t\right|}{% endequation %} שבה {% equation %}t{% endequation %} הוא בכלל וקטור והמטרה שלנו היא לא להראות שהגבול קיים אלא שהוא אפס. לכו תפתחו את זה למכפלה של שני גבולות שונים, שבהם מה ששואף לאפס שייך למרחבים ממימד אחר, והדיפרנציאלים המעורבים הם ממימדים שונים, וכו' וכו' וכו'. בקיצור, זה הולך להיות יותר טכני. בשורה התחתונה מה שנעשה הוא פשוט לבוא עם פטיש גדול ולהתחיל לדפוק על ההוכחה עד שזה יסתדר - אין כאן חוכמה גדולה ובעיקר יש טיפול שנראה קצת משמים בכל מני ביטויים. סביר להניח שחלקכם יאבדו אותי כאן ויכולים פשוט לקפוץ אל "עכשיו אפשר לשכוח מכל המהומה הטכנית" שאחר כך; מי שבאמת רוצה להבין, אני ממליץ על כתיבת ההוכחה בעצמכם במקביל אלי (הדרך היחידה שבה אני ממש מבין את ההוכחה היא על ידי כך שאני כותב אותה).

בתור התחלה, אנחנו לא מניחים ש-{% equation %}f,g{% endequation %} בהכרח מוגדרות לכל {% equation %}\mathbb{R}^{n}{% endequation %} ו-{% equation %}\mathbb{R}^{k}{% endequation %}, בהתאמה (הרבה פעמים אנחנו רוצים להשתמש בכלל השרשרת גם לפונקציות שמוגדרות רק עבור חלק מהתחום הזה). כל מה שאנחנו מניחים הוא ש-{% equation %}g{% endequation %} היא גזירה ב-{% equation %}a{% endequation %} ו-{% equation %}f{% endequation %} גזירה ב-{% equation %}g\left(a\right){% endequation %}. מכך אני רוצה להסיק ש-{% equation %}h{% endequation %} גזירה ב-{% equation %}a{% endequation %} ולמצוא את הנגזרת שלה. לצורך כך אני רוצה להיות מסוגל לדבר על ערכים של {% equation %}h{% endequation %} ב<strong>סביבה</strong> של {% equation %}a{% endequation %}, כי זה מה שמופיע בהגדרת הנגזרת - כלומר, על ערכים מהצורה {% equation %}h\left(a+t\right){% endequation %} עבור {% equation %}t{% endequation %} קטן. הטענה היא שעבור {% equation %}t{% endequation %} קטן מספיק (כלומר, {% equation %}\left|t\right|&lt;\delta{% endequation %} עבור {% equation %}\delta&gt;0{% endequation %} מסויים), הביטוי {% equation %}h\left(a+t\right){% endequation %} יהיה מוגדר. עכשיו, מכיוון שאנחנו יודעים ש-{% equation %}f{% endequation %} רציפה ב-{% equation %}g\left(a\right){% endequation %} בפרט קיים {% equation %}\varepsilon&gt;0{% endequation %} כך ש-{% equation %}f{% endequation %} מוגדרת לכל {% equation %}y{% endequation %} כך ש-{% equation %}\left|y-g\left(a\right)\right|&lt;\varepsilon{% endequation %}. מהרציפות של {% equation %}g{% endequation %} עולה שקיים {% equation %}\delta&gt;0{% endequation %} כך ש-שאם {% equation %}\left|x-a\right|&lt;\delta{% endequation %} אז {% equation %}g{% endequation %} מוגדרת ב-{% equation %}x{% endequation %} ומתקיים {% equation %}\left|g\left(x\right)-g\left(a\right)\right|&lt;\varepsilon{% endequation %} (זו ההגדרה של רציפות, כשפותחים אותה לאפסילון-דלתא). קיבלנו את ה-{% equation %}\delta{% endequation %} שרצינו.

אם כן, בואו ניקח {% equation %}t{% endequation %} כך ש-{% equation %}\left|t\right|&lt;\delta{% endequation %}. זה אומר ש-{% equation %}\left|g\left(a+t\right)-g\left(a\right)\right|&lt;\varepsilon{% endequation %} ולכן {% equation %}f{% endequation %} מוגדרת ב-{% equation %}g\left(a+t\right){% endequation %}. כעת, מכיוון ש-{% equation %}f{% endequation %} גזירה, זה אומר שמתקיים הגבול הבא:

{% equation %}\lim_{s\to0}\frac{f\left(g\left(a\right)+s\right)-f\left(g\left(a\right)\right)-Df\left(g\left(a\right)\right)s}{\left|s\right|}=0{% endequation %}

בואו נרשום את הביטוי שבתוך הגבול בתור פונקציה של {% equation %}s{% endequation %}: {% equation %}F\left(s\right)=\frac{f\left(g\left(a\right)+s\right)-f\left(g\left(a\right)\right)-Df\left(g\left(a\right)\right)s}{\left|s\right|}{% endequation %}. הפונקציה הזו מוגדרת לכל {% equation %}s{% endequation %} כך ש-{% equation %}0&lt;\left|s\right|&lt;\varepsilon{% endequation %} (עבור {% equation %}s{% endequation %}-ים גדולים יותר לא מובטח ש-{% equation %}f\left(g\left(a\right)+s\right){% endequation %} תהיה מוגדרת) ומה שאני רוצה לעשות הוא להציב במקום {% equation %}s{% endequation %} את {% equation %}g\left(a+t\right)-g\left(a\right){% endequation %} (שראינו לפני רגע שאכן קטן בערכו המוחלט מאפסילון), בערך כמו מה שעושים בהוכחת כלל השרשרת הרגיל. ההצבה הזו מועילה לי במיוחד בטיפול בגורם {% equation %}f\left(g\left(a\right)+k\right){% endequation %}: כרגע הוא לא משהו שאני יכול לכתוב עם {% equation %}h{% endequation %}, הפונקציה שאני רוצה בסופו של דבר לגזור; אבל אחרי ההצבה הזו נקבל את {% equation %}f\left(g\left(a+t\right)\right)=h\left(a+t\right){% endequation %}.

אם כן, בואו ניקח את המשוואה שהגדירה את {% equation %}F\left(s\right){% endequation %} ונטפל בה קצת - נכפול ב-{% equation %}\left|s\right|{% endequation %}, נעביר אגפים ונקבל

{% equation %}f\left(g\left(a\right)+s\right)-f\left(g\left(a\right)\right)=\left|s\right|F\left(k\right)+Df\left(g\left(a\right)\right)s{% endequation %}

לעת עתה אשתמש בקיצור {% equation %}\Delta g=g\left(a+t\right)-g\left(a\right){% endequation %} כי זה יחסוך לי כתיבה. אם כן, אחרי הצבת {% equation %}s=\Delta g{% endequation %} אני מקבל

{% equation %}h\left(a+t\right)-h\left(a\right)=\left|\Delta g\right|F\left(\Delta g\right)+Df\left(g\left(a\right)\right)\cdot\Delta g{% endequation %}

בואו ונסתכל על הגורם הכי ימני במשוואה הזו: {% equation %}Df\left(g\left(a\right)\right)\cdot\Delta g{% endequation %}. זה <strong>קצת</strong> מזכיר לנו את מה שאנחנו מצפים שיופיע בנוסחה הסופית: {% equation %}Df\left(g\left(a\right)\right)\cdot Dg\left(a\right){% endequation %}. כך שהשלב המתבקש הבא הוא לנסות ולמצוא תיאור נחמד יותר עבור {% equation %}\Delta g{% endequation %}. אפשר לשכוח לרגע מהמשוואה שקיבלנו ולהתמקד בניתוח שלו.

לצורך כך, בואו ניזכר בכך שגם {% equation %}g{% endequation %} היא פונקציה גזירה, ולכן אפשר לכתוב עבורה פונקציה דומה לזו שכתבנו עבור {% equation %}f{% endequation %}, רק פשוטה יותר:

{% equation %}G\left(t\right)=\frac{g\left(a+t\right)-g\left(a\right)-Dg\left(a\right)t}{\left|t\right|}{% endequation %}

הפונקציה הזו מוגדרת לכל {% equation %}0&lt;\left|t\right|&lt;\delta{% endequation %}, ואפשר להגדיר {% equation %}G\left(0\right)=0{% endequation %} ונקבל ש-{% equation %}G{% endequation %} הזו גם רציפה לכל {% equation %}\left|t\right|&lt;\delta{% endequation %}. ושוב, על ידי כפל והעברת אגפים נקבל

{% equation %}\Delta g=\left|t\right|G\left(t\right)+Dg\left(a\right)t{% endequation %}

קיבלנו את התיאור עבור {% equation %}\Delta g{% endequation %} שרצינו. עכשיו, בואו נחזור אל {% equation %}h{% endequation %}. המטרה שלנו, כזכור, היא לחשב את הגבול הבא:

{% equation %}\frac{h\left(a+t\right)-h\left(a\right)-Dh\left(a\right)t}{\left|t\right|}{% endequation %}

כאשר ההימור שלנו למועמדת לתפקיד {% equation %}Dh\left(a\right){% endequation %} היא {% equation %}Df\left(g\left(a\right)\right)\cdot Dg\left(a\right){% endequation %}. במילים אחרות, אנחנו רוצים לחשב את הגבול של

{% equation %}\frac{h\left(a+t\right)-h\left(a\right)-Df\left(g\left(a\right)\right)\cdot Dg\left(a\right)\cdot t}{\left|t\right|}{% endequation %}

(שימו לב שאני כותב את {% equation %}Df\left(g\left(a\right)\right)\cdot Dg\left(a\right)\cdot t{% endequation %} בלי סוגריים; זה תקין, מכיוון שכפל מטריצות הוא אסוציאטיבי).

עכשיו, נחליף את {% equation %}h\left(a+t\right)-h\left(a\right){% endequation %} בתיאור שמצאנו למעלה, ונקבל:

{% equation %}\frac{\left|\Delta g\right|F\left(\Delta g\right)+Df\left(g\left(a\right)\right)\cdot\Delta g-Df\left(g\left(a\right)\right)\cdot Dg\left(a\right)\cdot t}{\left|t\right|}{% endequation %}

ועכשיו נציב את ה-{% equation %}\Delta g{% endequation %} שמצאנו, ונקבל:

{% equation %}\frac{\left|\Delta g\right|F\left(\Delta g\right)+\left|t\right|Df\left(g\left(a\right)\right)G\left(t\right)+Df\left(g\left(a\right)\right)\cdot Dg\left(a\right)\cdot t-Df\left(g\left(a\right)\right)\cdot Dg\left(a\right)\cdot t}{\left|t\right|}{% endequation %}

שני הגורמים האחרונים מבטלים זה את זה, כך שאנחנו נשארים עם הביטוי היחסית פשוט

{% equation %}\frac{\left|\Delta g\right|F\left(\Delta g\right)}{\left|t\right|}+Df\left(g\left(a\right)\right)G\left(t\right){% endequation %}

ואנחנו רוצים להראות שהוא שואף לאפס כאשר {% equation %}t{% endequation %} שואף לאפס. מה שיש כאן הוא חשבון מכולת סטנדרטי של אינפי - מראים שיש לנו סכום של גורמים כך שכל גורם כולל חלק ששואף לאפס, וחלק שהוא חסום ולכן "לא מפריע" לו. נתחיל עם {% equation %}Df\left(g\left(a\right)\right)G\left(t\right){% endequation %}. כאן {% equation %}Df\left(g\left(a\right)\right){% endequation %} הוא מספר קבוע בעוד ש-{% equation %}G\left(t\right){% endequation %} שואפת כמובן לאפס (למה "כמובן"? בטח איבדתם אותי לגמרי כבר; {% equation %}G\left(t\right){% endequation %} היא הפונקציה שמתארת את הגבול שמגדיר את הגזירות של {% equation %}g{% endequation %}). הביטוי {% equation %}\frac{\left|\Delta g\right|}{\left|t\right|}F\left(\Delta g\right){% endequation %} מאתגר קצת יותר. מכיוון ש-{% equation %}g{% endequation %} רציפה, הרי ש-{% equation %}\Delta g=g\left(a+t\right)-g\left(a\right){% endequation %} שואפת לאפס כאשר {% equation %}t{% endequation %} שואף לאפס, ומכיוון ש-{% equation %}F{% endequation %} שואפת לאפס כשהקלט שלה שואף לאפס (מאותה סיבה של {% equation %}G{% endequation %}) קיבלנו ש-{% equation %}F\left(\Delta g\right){% endequation %} שואפת לאפס. נשאר רק להראות ש-{% equation %}\frac{\left|\Delta g\right|}{\left|t\right|}{% endequation %} חסומה.

לצורך כך, זכרו שראינו כי {% equation %}\Delta g=\left|t\right|G\left(t\right)+Dg\left(a\right)t{% endequation %}. ניקח נורמה בשני האגפים ונקבל

{% equation %}\left|\Delta g\right|\le\left|t\right|\left|G\left(t\right)\right|+\left|Dg\left(a\right)\right|\left|t\right|=\left|t\right|\left(\left|G\left(t\right)\right|+k\left|Dg\left(a\right)\right|\right){% endequation %}

המעבר האחרון עשוי להיות קצת מבלבל עבור מי שלא מכיר. זכרו ש-{% equation %}Dg\left(a\right){% endequation %} היא <strong>מטריצה</strong> מסדר {% equation %}k\times n{% endequation %} . לכן הביטוי {% equation %}\left|Dg\left(a\right)\right|{% endequation %} עבורה שונה מאשר עבור, נאמר {% equation %}\left|t\right|{% endequation %} - כאן זו <strong>נורמה של מטריצה</strong>. במקרה שלנו, ההגדרה של הנורמה הזו פשוטה - חשבו על המטריצה בתור וקטור ארוך, וקחו את הנורמה הרגילה שלה. כעת, {% equation %}Dg\left(a\right)\cdot t{% endequation %} זו מכפלה שלוקחת וקטור מגודל {% equation %}n{% endequation %} ומחזירה וקטור מגודל {% equation %}k{% endequation %}, שהכניסות שלו הן מכפלות סקלריות של {% equation %}t{% endequation %} עם {% equation %}k{% endequation %} שורות {% equation %}Dg\left(a\right){% endequation %}. קל לראות, באמצעות שימוש באי-שוויון המשולש, שמתקיים {% equation %}\left|Dg\left(a\right)\cdot t\right|\le k\left|Dg\left(a\right)\right|\left|t\right|{% endequation %}, ומכאן המעבר שלי.

קיבלנו ש-{% equation %}\frac{\left|\Delta g\right|}{\left|t\right|}=\left|G\left(t\right)\right|+k\left|Dg\left(a\right)\right|{% endequation %}. כעת, {% equation %}G\left(t\right){% endequation %} רציפה ושואפת לאפס ולכן גם {% equation %}\left|G\left(t\right)\right|{% endequation %}, ולכן היא בוודאי חסומה; ואילו {% equation %}k\left|Dg\left(a\right)\right|{% endequation %} הוא קבוע. זה מסיים את ההוכחה.

עכשיו אפשר לשכוח מכל המהומה הטכנית הזו ולקטוף באלגנטיות את הפירות. ראינו שהדיפרנציאל של {% equation %}s\left(x,y\right)=x+y{% endequation %} בכל נקודה הוא {% equation %}s{% endequation %} עצמה. כעת, נניח שיש לנו שתי פונקציות {% equation %}f:\mathbb{R}^{n}\to\mathbb{R}{% endequation %} ו-{% equation %}g:\mathbb{R}^{n}\to\mathbb{R}{% endequation %} ואנחנו רוצים לגזור את {% equation %}f+g{% endequation %}, מה עושים? נשים לב לכך ש-{% equation %}h\left(x\right)=\left(f+g\right)\left(x\right)=s\left(f,g\right)\left(x\right){% endequation %} (כאן {% equation %}f,g{% endequation %} זו בעצם דרך לתאר פונקציה מ-{% equation %}\mathbb{R}^{n}{% endequation %} אל {% equation %}\mathbb{R}^{2}{% endequation %} ש-{% equation %}f,g{% endequation %} הם רכיביה), ולכן נגזור על פי כלל השרשרת ונקבל

{% equation %}Dh\left(a\right)=Ds\left(f\left(a\right),g\left(a\right)\right)D\left(f\left(a\right),g\left(a\right)\right)=s\left(Df\left(a\right),Dg\left(a\right)\right)=Df\left(a\right)+Dg\left(a\right){% endequation %}

לא מפתיע, כמובן, אבל נחמד מאוד שזה מתקבל כך. קצת יותר מעניין יהיה לעשות את אותו דבר עבור כפל. שם הדיפרנציאל של {% equation %}xy{% endequation %} בנקודה {% equation %}\left(a,b\right){% endequation %} היה {% equation %}bx+ay{% endequation %}. אצלנו, הנקודה {% equation %}\left(a,b\right){% endequation %} היא בעצם {% equation %}\left(f\left(a\right),g\left(a\right)\right){% endequation %} ולכן נקבל מכלל השרשרת בסופו של דבר את {% equation %}g\left(a\right)Df\left(a\right)+f\left(a\right)Dg\left(a\right){% endequation %}.

אם כן, אנחנו יודעים כעת איך מחשבים את הנגזרת של פונקציות מורכבות יחסית - כאלו שמתקבלות מפונקציות פשוטות על ידי חיבור, כפל והרכבה. מה עם חיסור וחילוק? אפשר להרכיב את הפונקציה {% equation %}g\left(x\right)=-x{% endequation %} על כל פונקציה שנרצה ולקבל בקלות ש-{% equation %}D\left(-f\right)=-Df{% endequation %}, ולכן {% equation %}D\left(f-g\right)=Df-Dg{% endequation %}.

חילוק, כמובן, יהיה בעייתי יותר, כי לא ניתן לחלק באפס. אנחנו רוצים להרכיב את {% equation %}g\left(x\right)=\frac{1}{x}{% endequation %} (שהנגזרת שלה היא {% equation %}-\frac{1}{x^{2}}{% endequation %}, על פי כללי הגזירה הרגילים) על הפונקציה {% equation %}f{% endequation %}, אבל בשביל זה אנחנו צריכים לדרוש ש-{% equation %}f{% endequation %} תהיה שונה מאפס בנקודה שבה אנחנו מחשבים את הנגזרת. כלומר, אם {% equation %}f\left(a\right)\ne0{% endequation %} אז {% equation %}D\frac{1}{f}\left(a\right)=D\left(g\left(f\right)\right)\left(a\right)=-\frac{1}{f^{2}\left(a\right)}Df\left(a\right){% endequation %}.

מכאן גם אפשר לקבל את הנגזרת הכללית של מנת שתי פונקציות: {% equation %}D\frac{h}{f}=D\left(\frac{1}{f}\cdot h\right)=D\frac{1}{f}h+\frac{1}{f}Dh=-\frac{hDf}{f^{2}}+\frac{1}{f}Dh=\frac{fDh-hDf}{f^{2}}{% endequation %} - שוב, תחת ההנחה שאנחנו מחשבים את הפונקציות הללו רק בנקודות שבהן {% equation %}f{% endequation %} שונה מאפס.

כל אלו הן תוצאות נחמדות, כי הן לא שונות, בעצם, ממה שקורה באינפי רגיל במשתנה יחיד, למרות שאצלנו {% equation %}Df{% endequation %} זה יצור הרבה יותר מסובך מאשר הנגזרת הרגילה. זה בהחלט עוזר להרגיש ש"הצלחנו" בהגדרה שלנו. אם כן, הבה ונמשיך במיטב המסורת של אינפי, ונעבור אל הבניה האחרונה שלנו, שגם היא מוכללת בצורה טבעית, אבל הסיפור שלה אצלנו יהיה מסובך הרבה יותר - נגזרת הפונקציה ההפוכה.

נניח שיש לנו פונקציה {% equation %}f:\mathbb{R}^{n}\to\mathbb{R}^{n}{% endequation %} (שימו לב - כאן גם התחום וגם הטווח הם מאותו מימד {% equation %}n{% endequation %}). אז {% equation %}g:\mathbb{R}^{n}\to\mathbb{R}^{n}{% endequation %} היא <strong>הפונקציה ההפוכה</strong> ל-{% equation %}f{% endequation %} אם {% equation %}f\left(g\left(x\right)\right)=g\left(f\left(x\right)\right)=x{% endequation %} לכל {% equation %}x\in\mathbb{R}^{n}{% endequation %}. לא תמיד קיימת כזו, כמובן (חשבו על {% equation %}f\left(x\right)=0{% endequation %}). אם קיימת, מסמנים אותה לרוב ב-{% equation %}f^{-1}{% endequation %}. יותר מזה, לעתים קרובות לא קיימת ל-{% equation %}f{% endequation %} הופכית על כל {% equation %}\mathbb{R}^{n}{% endequation %}, אבל אם נגביל את התחום של {% equation %}f{% endequation %} לתת-קבוצה {% equation %}A\subseteq\mathbb{R}^{n}{% endequation %} נקבל משהו הפיך. דוגמה קלאסית היא הפונקציה {% equation %}f\left(x\right)=x^{2}{% endequation %}; היא לא חד-חד-ערכית על הממשיים כי {% equation %}f\left(x\right)=f\left(-x\right){% endequation %}; מצד שני, על הממשיים האי-שליליים היא כן חד-חד-ערכית והפיכה; ההופכית שלה היא {% equation %}g\left(x\right)=\sqrt{x}{% endequation %} (המוסכמה הרגילה היא ש-{% equation %}\sqrt{x}{% endequation %} כאשר {% equation %}x{% endequation %} ממשי מחזיר את השורש האי-שלילי אם קיימים שני שורשים).

נניח שגם {% equation %}f{% endequation %} וגם {% equation %}f^{-1}{% endequation %} הן גזירות, ונניח שאנחנו יודעים מה הנגזרת של {% equation %}f{% endequation %}; האם אפשר למצוא ממנה את הנגזרת של {% equation %}f^{-1}{% endequation %}? למשל, אנחנו יודעים שהנגזרת של {% equation %}\sin x{% endequation %} היא מאוד פשוטה: {% equation %}\cos x{% endequation %}. אבל איך אפשר לקבל מזה את הנגזרת של {% equation %}\arcsin x{% endequation %}? אני ממש לא זוכר את הנגזרת הזו בעל פה; בואו נראה אם נצליח לפתח אותה מחדש (כמובן, אנחנו מדברים פה על המקרה של אינפי בסיסי, אבל לא יהיה הבדל אמיתי בינו ובין המקרה הכללי).

הטריק הוא להשתמש בכלל השרשרת. אם {% equation %}f\left(f^{-1}\right)=I{% endequation %} כאשר {% equation %}I{% endequation %} היא פונקציית הזהות {% equation %}I\left(x\right)=x{% endequation %}, אז מצבנו טוב כי אנחנו יודעים בדיוק מהו {% equation %}DI{% endequation %}: כבר אמרנו שהנגזרת של פונקציה לינארית היא היא עצמה, כלומר {% equation %}DI\left(a\right)=I{% endequation %} לכל {% equation %}a{% endequation %}. נסמן {% equation %}b=f^{-1}\left(a\right){% endequation %} ועכשיו אפשר להשתמש בכלל השרשרת ולקבל ש-{% equation %}I=Df\left(b\right)Df^{-1}\left(a\right){% endequation %}. היינו רוצים עכשיו "לחלק" ב-{% equation %}Df\left(b\right){% endequation %}, אבל צריך להיזהר פה: זה לא מספר שאפשר סתם לחלק בו. זו טרנספורמציה לינארית. "לחלק" בהקשר של טרנספורמציות לינאריות פירושו לכפול בהופכי. לכן אני צריך להניח ש-{% equation %}Df\left(b\right){% endequation %} הפיכה בכלל, וזה שקול לכך ש-{% equation %}\det Df\left(b\right)\ne0{% endequation %} (מי שלא מכיר את {% equation %}\det{% endequation %} - נו נו נו! אמרתי שצריך אלגברה לינארית. <a href="http://www.gadial.net/2011/11/10/determinants/">הנה הפוסט שלי</a> על דטרמיננטות). במקרה שבו זה נכון, אז נקבל ש-{% equation %}Df^{-1}\left(a\right)=\left(Df\left(b\right)\right)^{-1}{% endequation %} - אלגנטי ויפה.

כדי להבין את הנוסחה הזו, בואו נפעיל אותה במקרה של {% equation %}\mbox{arcsin}{% endequation %}. עבור פונקציות במשתנה יחיד, זכרו שמה שאנחנו קוראים לו {% equation %}Df\left(a\right){% endequation %} הוא בעצם הפונקציה הלינארית {% equation %}f^{\prime}\left(a\right)x{% endequation %}. הפונקציה הזו הפיכה אם ורק אם {% equation %}f^{\prime}\left(a\right)\ne0{% endequation %} ואז ההופכית שלה היא פשוט {% equation %}\frac{1}{f^{\prime}\left(a\right)}x{% endequation %}. כלומר, הנוסחה במקרה הזה הופכת להיות {% equation %}\left(f^{-1}\right)^{\prime}\left(a\right)=\frac{1}{f^{\prime}\left(b\right)}{% endequation %}. לכן קיבלנו ש-{% equation %}\arcsin^{\prime}\left(a\right)=\frac{1}{\sin^{\prime}\left(\arcsin a\right)}=\frac{1}{\cos\left(\arcsin a\right)}{% endequation %}. כאן אנחנו לכאורה נתקעים, כי איך מחשבים קוסינוס של ארקסינוס? אבל מספיק לזכור את הזהות הבסיסית ביותר שקשורה לסינוסים וקוסינוסים - שהם מתארים נקודה על מעגל היחידה, ולכן {% equation %}\cos^{2}x+\sin^{2}x=1{% endequation %} לכל {% equation %}x{% endequation %}. מכאן אפשר לחלץ ולקבל ש-{% equation %}\cos x=\sqrt{1-\sin^{2}x}{% endequation %} עבור {% equation %}-\frac{\pi}{2}\le x\le\frac{\pi}{2}{% endequation %} (עבור ערכי {% equation %}x{% endequation %} אחרים צריך לפעמים לקחת את השורש השלילי). כלומר, {% equation %}\cos\left(\arcsin\left(a\right)\right)=\sqrt{1-\sin^{2}\left(\arcsin a\right)}=\sqrt{1-a^{2}}{% endequation %}. מסקנה: {% equation %}\arcsin^{\prime}\left(a\right)=\frac{1}{\sqrt{1-a^{2}}}{% endequation %}.

משהו כאן בבירור לא עובד כאשר {% equation %}a=\pm1{% endequation %}, כלומר כאשר הקלט ל-{% equation %}\sin{% endequation %} הוא כזה שיחזיר 1 או {% equation %}-1{% endequation %}, כלומר {% equation %}\pm\frac{\pi}{2}{% endequation %}, כלומר הנגזרת שמצאנו עובדת רק עבור {% equation %}-\frac{\pi}{2}&lt;a&lt;\frac{\pi}{2}{% endequation %} ואילו בשתי נקודות הקצה הללו משהו "מתפוצץ" (מה שמסביר, מנקודת מבט שונה, למה נאלצתי להצטמצם לתחום הזה). מה בעצם השתבש? אלו הן בדיוק נקודות המקסימום והמינימום של {% equation %}\sin{% endequation %}; אחרי {% equation %}\frac{\pi}{2}{% endequation %}, למשל, היא מתחילה "ליפול" בעוד שקודם היא עלתה. זה אומר שהיא כבר לא תהיה חד-חד-ערכית ולכן לא הפיכה, ולכן מראש היינו חייבים להצטמצם עם {% equation %}\arcsin{% endequation %} לקטע הזה. עכשיו, דרך נחמדה לדמיין פונקציה הופכית במימד אחד היא לקחת את הגרף של הפונקציה ולסובב אותו ב-90 מעלות נגד כיוון השעון, ואז לשקף ביחס לציר {% equation %}y{% endequation %}; אם אתם לא מאמינים תנסו לעשות את זה עם {% equation %}f\left(x\right)=x^{2}{% endequation %}. מן הסתם כשעושים דבר כזה, אז נקודה שבה המשיק של {% equation %}\sin x{% endequation %} היה אופקי (שיפוע 0) תהפוך לנקודה שבה המשיק של {% equation %}\arcsin x{% endequation %} יהיה אנכי (שיפוע "אינסוף"), מה שמסביר את הפיצוץ הזה.

אם כן, למדנו דבר מעניין - שאם {% equation %}\det Df\left(a\right)\ne0{% endequation %} אז הנגזרת של {% equation %}f^{-1}{% endequation %} ב-{% equation %}a{% endequation %} שווה ל-{% equation %}\left[Df\left(f^{-1}\left(a\right)\right)\right]^{-1}{% endequation %}. אבל שימו לב לשלוש ההנחות שיש לנו כאן:
<ol>
	<li>{% equation %}Df\left(a\right){% endequation %} הפיכה.</li>
	<li>{% equation %}f^{-1}{% endequation %} קיימת.</li>
	<li>{% equation %}f^{-1}{% endequation %} גזירה.</li>
</ol>
אם שלוש ההנחות הללו התקיימו, אנחנו יודעים לחשב את הנגזרת של {% equation %}f^{-1}{% endequation %}. אבל האמת היא שמתקיים פה קסם - אם {% equation %}f{% endequation %} היא גזירה ברציפות (כלומר, בעלת נגזרת רציפה) אז די בכך ש-{% equation %}Df\left(a\right){% endequation %} תהיה הפיכה על מנת להבטיח ש<strong>קיימת</strong> ל-{% equation %}f{% endequation %} הופכית בסביבה של {% equation %}a{% endequation %}, ושההופכית הזו תהיה גזירה (למעשה, אם {% equation %}f{% endequation %} גזירה ברציפות {% equation %}r{% endequation %} פעמים, כך גם הנגזרת של ההופכית). הקסם הזה, שנקרא <strong>משפט הפונקציה ההפוכה</strong>, הוא המשפט הלא טריוויאלי הראשון שאנחנו הולכים לראות, ומייד אחר כך נראה שימוש יפה שלו - <strong>משפט הפונקציות הסתומות</strong>. מכיוון שזה לא הולך להיות קצר או פשוט, נחכה עם זה (כולל הניסוח הפורמלי) עד לפוסט הבא. לעת עתה, טיזר - בואו נבין אינטואיטיבית למה זה עובד כמעט מייד בפונקציות {% equation %}f:\mathbb{R}\to\mathbb{R}{% endequation %}. אם {% equation %}f^{\prime}\left(a\right)\ne0{% endequation %} והנגזרת רציפה, זה אומר שיש סביבה של {% equation %}a{% endequation %} שבה {% equation %}f^{\prime}\left(a\right){% endequation %} נמצאת כולה מעל 0 או מתחת ל-0. במקרה הראשון זה אומר ש-{% equation %}f{% endequation %} עולה בסביבה הזו, ובמקרה השני - שהיא יורדת. בכל מקרה, היא <strong>מונוטונית</strong>. פונקציה מונוטונית היא, כמובן, הפיכה (עדיין צריך להוכיח שהיא גזירה, אבל לא נדבר על זה פה). כמובן שעבור פונקציות במימד גבוה יותר העסק כבר לא יהיה כל כך פשוט כי זה שהנגזרת היא טרנספורמציה לינארית הפיכה לא יגרור שהפונקציה היא מונוטונית; בפוסט הבא ניכנס לפרטים המלוכלכים.
