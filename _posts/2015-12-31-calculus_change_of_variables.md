---
id: 3307
title: "החלפת משתנים בחשבון דיפרנציאלי ואינטגרלי (\"שיטת ההצבה\")"
date: 2015-12-31 15:02:17
layout: post
categories: 
  - אנליזה מתמטית
tags: 
  - אינטגרציה
  - החלפת משתנים
---
היעד הנוכחי של סדרת הפוסטים שלי על אנליזה וקטורית הוא משפט כבד למדי - משפט החלפת המשתנים. אבל לפני שנצלול למעמקים הטכניים שלו, בואו נחזור לרגע לחדו"א של משתנה יחיד ונדבר על איך משפט החלפת המשתנים נראה שם, גם כי זה נותן לנו נקודת אחיזה למשפט הכללי והמסובך יותר, וגם כי מעולם לא כתבתי על המשפט הבסיסי פוסט והגיע הזמן. במשתנה יחיד הניסוח של המשפט פשוט וההוכחה פשוטה (יחסית) גם כן, כך שזהו מבוא מוצלח.

אבל לפני שנדבר על חדו"א, בואו ננסה להבין מה זו בכלל "החלפת משתנים" עם דוגמה יותר פשוטה - משוואות פולינומיות. בואו נסתכל במשוואה {% equation %}x^{4}-5x^{2}+4=0{% endequation %} - מה הפתרונות שלה? איך מוצאים אותם? ובכן, יש נוסחה לפתרון משוואות ממעלה ארבע, אבל היא מסובכת מאוד. האם יש דרך יותר פשוטה? ובכן, שימו לב שבמשוואה הזו מופיעות רק חזקות <strong>זוגיות</strong> של {% equation %}x{% endequation %} - החזקות 4, 2 ו-0. זה אומר לנו שבעצם יש פה משוואה ריבועית ב"תחפושת". כדי להוריד את התחפושת, אנחנו מבצעים החלפת משתנים: מגדירים משתנה חדש, {% equation %}t{% endequation %}, כך ש-{% equation %}t=x^{2}{% endequation %}, ואז המשוואה לעיל הופכת להיות המשוואה {% equation %}t^{2}-5t+4=0{% endequation %} שקל לפתור בדרכים סטנדרטיות לפתרון משוואה ריבועית (נוסחת השורשים או טרינום). מקבלים שהפתרונות הם {% equation %}t=1,4{% endequation %}. מכאן קל לקבל פתרונות למשוואה המקורית: מכיוון ש-{% equation %}t=x^{2}{% endequation %} קיבלנו שהמשוואות {% equation %}x^{2}=1{% endequation %} ו- {% equation %}x^{2}=4{% endequation %} נותנות פתרונות למשוואה המקורית, ובסך הכל נקבל שלמשוואה המקורית יש ארבעה פתרונות: {% equation %}x=1,-1,2,-2{% endequation %}.

אם כן, מהי בעצם החלפת משתנים? אנחנו מנסים <strong>לפשט</strong> ביטוי כלשהו על ידי כך שאנחנו מגדירים משתנה חדש, שהוא <strong>פונקציה</strong> של המשתנה הישן. בואו נחדד את זה על ידי כך שנעבור לטרמינולוגיה של חדו"א, שמשתמשת בפונקציות. ראשית כל הייתה לנו פונקציה {% equation %}h\left(x\right)=x^{4}-5x^{2}+4{% endequation %} וביקשו מאיתנו לפתור את המשוואה {% equation %}h\left(x\right)=0{% endequation %}. זה היה קשה, אבל אז שמנו לב לכך שאפשר לחשוב על {% equation %}h{% endequation %} בתור <strong>הרכבה</strong> של שתי פונקציות פשוטות יותר: {% equation %}f\left(t\right)=t^{2}-5t+4{% endequation %} ו-{% equation %}g\left(x\right)=x^{2}{% endequation %}. דהיינו, קיבלנו ש-{% equation %}h\left(x\right)=f\left(g\left(x\right)\right){% endequation %}, או בסימון מקובל אחר, {% equation %}h=f\circ g{% endequation %}. כעת השתמשנו בכך שיותר קל לנו לפתור משוואות שמערבות את {% equation %}f,g{% endequation %} בנפרד כדי לפתור את המשוואה המקורית עבור {% equation %}h{% endequation %}.

בואו נעבור עכשיו לדוגמה שקשורה לאינטגרלים לא מסויימים. ראשית כל נזכיר לכם אינטגרל אחד נחמד שאנחנו יודעים לפתור יפה: {% equation %}\int\frac{1}{x}dx{% endequation %}. האינטגרל הזה שווה ל-{% equation %}\ln x+C{% endequation %} (לא ניכנס עכשיו להסבר מדוע). עכשיו בואו נסתכל על אינטגרל דומה: {% equation %}\int\frac{1}{1-x}dx{% endequation %}. למה הוא שווה? האינטואיציה היא שאפשר לבצע פה החלפת משתנים: להגדיר משתנה חדש {% equation %}y=1-x{% endequation %} ואז לקבל את האינטגרל {% equation %}\int\frac{1}{y}dy{% endequation %}, לבצע את האינטגרציה ולקבל {% equation %}\ln y+C{% endequation %}, ואז להציב מחדש את המשתנה ולקבל {% equation %}\ln\left(1-x\right)+C{% endequation %}. ואיך נבדוק את עצמנו? נגזור: אחרי גזירה מקבלים {% equation %}\frac{1}{1-x}\cdot\left(1-x\right)^{\prime}=\frac{1}{1-x}\cdot\left(-1\right)=-\frac{1}{1-x}{% endequation %}. אוקיי, משהו לא עבד פה. קיבלנו מינוס של התוצאה הנכונה.

עוד לא השתכנעתם שיש פה בעיה? אז שימו לב שאפשר היה לנקוט באותו תעלול גם עבור {% equation %}\int\frac{1}{1+x^{2}}dx{% endequation %} ולקבל את ה"פתרון" {% equation %}\ln\left(1+x^{2}\right)+C{% endequation %}. אבל הפתרון הזה <strong>בבירור</strong> לא נכון, כי הנגזרת יוצאת בכלל {% equation %}\frac{2x}{1+x^{2}}{% endequation %}, ואם אתם זוכרים קצת אינטגרציה אתם זוכרים ש-{% equation %}\int\frac{1}{1+x^{2}}dx=\arctan x+C{% endequation %}. וזו פונקציה שונה לגמרי. בקיצור, משהו פה משתבש (וזה לא מפתיע; הרי לא הוכחתי עד עכשיו כלום, אני סתם הולך לפי אינטואיציה עיוורת). התחושה היא שמה שמשתבש הוא שחסר לי בביטוי המקורי את ה<strong>נגזרת</strong> של הביטוי שאני מחליף - זה מסביר את המינוס 1 במקרה הראשון (הנגזרת של {% equation %}1-x{% endequation %}) ואת ה-{% equation %}2x{% endequation %} במקרה השני (הנגזרת של {% equation %}1+x^{2}{% endequation %}). משפט החלפת המשתנים בחדו"א הוא בדיוק מה שמקבלים כשמתחשבים גם בעניין הזה.

הנה דוגמת צעצוע שבה הנגזרת של הביטוי הפנימי יוצאת 1 ולכן אין צורך בתיקון: {% equation %}\int\frac{1}{2+x}dx{% endequation %}. במקרה הזה נגדיר {% equation %}y=2+x{% endequation %} ואכן נקבל בסופו של דבר {% equation %}\ln\left(2+x\right)+C{% endequation %} בתור הפתרון. אבל גם במקרה הזה עדיין יש בעיה אחרת שצריך להתחשב בה וצצה כשאנחנו מנסים לחשב אינטגרל <strong>מסויים</strong> (כלומר, אינטגרל שבו יש גבולות אינטגרציה ואנחנו מחפשים את ערך האינטגרל ביניהם, ולא אינטגרל שבו אנחנו מחפשים פונקציה קדומה). נניח שאנחנו מחשבים את {% equation %}\int_{-1}^{1}\frac{1}{2+x}dx{% endequation %}. בבירור אין שום בעיה עם האינטגרל הזה, כי כאשר {% equation %}x{% endequation %} רץ ממינוס 1 אל 1, הביטוי {% equation %}2+x{% endequation %} רץ מ-1 אל 3, ולכן {% equation %}\frac{1}{2+x}{% endequation %} מוגדר בכל הקטע {% equation %}\left[-1,1\right]{% endequation %}. לעומת זאת, אם נבצע "סתם" החלפת משתנה {% equation %}y=2+x{% endequation %} נקבל את האינטגרל {% equation %}\int_{-1}^{1}\frac{1}{y}dy{% endequation %} שהוא כמובן בעייתי כי עבור {% equation %}y=0{% endequation %} שממש באמצע הקטע {% equation %}\left[-1,1\right]{% endequation %} נקבל ביטוי לא מוגדר (וזו לא בעיה נקודתית; האינגטרל "מתפוצץ" סביב הנקודה הזו). אם כן, כשמבצעים החלפת משתנים באינטגרל מסויים, גם גבולות האינטגרציה צריכים להשתנות בהתאם.

עכשיו משברור לנו מה שני ה"תיקונים" שצריך לעשות (כפל בנגזרת של מה שמחליפים, ותיקון גבולות אינטגרציה בהתאם) אפשר ממש לנסות ולחפש את הניסוח המדויק של משפט החלפת המשתנים באופן עצמאי, אבל זה קצת מעייף, אז אני פשוט אביא את הניסוח הנקי:

בהינתן פונקציה {% equation %}g:\left[a,b\right]\to\mathbb{R}{% endequation %} (זו הפונקציה שמבצעת את "החלפת המשתנים") שהיא ב-{% equation %}C^{1}{% endequation %} (כלומר - גזירה, והנגזרת רציפה) ו-{% equation %}g^{\prime}\left(x\right)\ne0{% endequation %} לכל {% equation %}x\in\left(a,b\right){% endequation %}, ובהינתן פונקציה {% equation %}f{% endequation %} רציפה שמוגדרת על התמונה של {% equation %}g{% endequation %}, מתקיים:

{% equation %}\int_{g\left(a\right)}^{g\left(b\right)}f\left(y\right)dy=\int_{a}^{b}\left(f\circ g\right)\left(x\right)g^{\prime}\left(x\right)dx{% endequation %}

בכתיב טיפה יותר חסכוני:

{% equation %}\int_{g\left(a\right)}^{g\left(b\right)}fdy=\int_{a}^{b}\left(f\circ g\right)g^{\prime}dx{% endequation %}

ואם נסמן {% equation %}I=\left[a,b\right]{% endequation %} ו-{% equation %}J=g\left(I\right){% endequation %} ונוותר על ה-{% equation %}dx{% endequation %}-ים, כפי שעשינו עם הגדרת האינטגרל הכללי באנליזה וקטורית, אפילו אפשר לכתוב

{% equation %}\int_{J}f=\int_{I}\left(f\circ g\right)\left|g^{\prime}\right|{% endequation %}

כאשר הערך המוחלט צץ לו כדי לקזז את העובדה שעכשיו אין לנו גבולות אינטגרציה עליונים ותחתונים אלא פשוט אינטגרציה על קטע; אסביר את זה עוד מעט. ראשית כל בואו נוכיח את המשפט הזה.

זה שעשוע נחמד לחשוב מאיפה צצו כל ההנחות המוזרות של המשפט, עם ה-{% equation %}C^{1}{% endequation %} וכאלה (טוב, יש עוד שעשועים נחמדים כמו לנסוע ברכבת הרים וכדומה, אבל אני מניח שאם שרדתם עד פה גם מבחינתכם זה שעשוע נחמד). אין כאן משהו מסובך במיוחד - ראשית, אנחנו רוצים ש-{% equation %}g{% endequation %} תהיה מונוטונית עולה או יורדת בכל {% equation %}I=\left[a,b\right]{% endequation %}, כך שהיא בפרט תהיה חד חד ערכית על הקטע הזה. מכיוון ש-{% equation %}g^{\prime}\left(x\right)\ne0{% endequation %} בתוך הקטע, בשילוב עם העובדה ש-{% equation %}g^{\prime}{% endequation %} רציפה, נקבל שלא ייתכן ש-{% equation %}g^{\prime}{% endequation %} מחליפה סימן בתוך הקטע (אם הייתה מחליפה סימן, אז על פי משפט ערך הביניים היא הייתה מתאפסת בתוך הקטע). עכשיו, אם {% equation %}g{% endequation %} היא פונקציה יורדת, זה אומר ש-{% equation %}g\left(a\right)&gt;g\left(b\right){% endequation %}, אז בואו ניזכר מה זה אומר מבחינת הסימון {% equation %}\int_{g\left(a\right)}^{g\left(b\right)}f{% endequation %}; המוסכמה היא שאם באינטגרל הגבול העליון קטן מהגבול התחתון, הוא שווה למינוס האינטגרל עם הגבולות "בסדר הנכון", כלומר {% equation %}\int_{g\left(a\right)}^{g\left(b\right)}f=-\int_{g\left(b\right)}^{g\left(a\right)}f{% endequation %}. זו בסך הכל מוסכמת סימון, לא יותר מכך. בלעדיה הייתי צריך להגיד יותר פעמים "נפריד למקרים". זה גם מסביר את הערך המוחלט בניסוח השני של המשפט - {% equation %}\int_{J}f{% endequation %} מניח תמיד שהגבולות ב-{% equation %}J{% endequation %} הם "בסדר הנכון" ולכן אם {% equation %}g{% endequation %} יורדת, כלומר אם {% equation %}g^{\prime}{% endequation %} שלילית, מקזזים את המינוס החסר באגף שמאל על ידי כך שמוחקים אותו גם מאגף ימין - זו המשמעות היחידה של הערך המוחלט על {% equation %}g^{\prime}{% endequation %}.

טוב ויפה, אבל איך מוכיחים את המשפט? ובכן, משתמשים בתותח כבד - <a href="http://www.gadial.net/2011/01/02/fundemental_theorem_of_calculus/">במשפט היסודי של החדו"א</a>. בואו ניזכר מה המשפט אומר (בגרסה קצת פחות כללית ממה שאפשר לסחוט): אם {% equation %}f{% endequation %} היא פונקציה רציפה על הקטע {% equation %}\left[ c,d\right]{% endequation %} אז ניתן להגדיר פונקציה {% equation %}F\left(x\right)=\int_{c}^{x}f\left(t\right)dt{% endequation %}, ונקבל ש-{% equation %}F{% endequation %} גזירה ומתקיים {% equation %}F^{\prime}\left(x\right)=f\left(x\right){% endequation %} לכל {% equation %}x\in\left[ c,d\right]{% endequation %}. אם תזכרו, נובע מכך די בקלות ש-{% equation %}\int_{c}^{d}f\left(x\right)dx=F\left(d\right)-F\left(c\right){% endequation %}.

עכשיו נשתמש בטריק שאפשר להמציא עם קצת הינדוס לאחור: נגדיר {% equation %}H\left(x\right)=F\left(g\left(x\right)\right){% endequation %}, ונגזור באמצעות כלל השרשרת. נקבל ש-{% equation %}H^{\prime}\left(x\right)=F^{\prime}\left(g\left(x\right)\right)g^{\prime}\left(x\right)=f\left(g\left(x\right)\right)g^{\prime}\left(x\right){% endequation %}. דהיינו, מצאנו את הפונקציה הקדומה של כל הביטוי {% equation %}\left(f\circ g\right)g^{\prime}{% endequation %}, מה שמאפשר לנו להשתמש במשפט היסודי של החדו"א פעמיים כדי לקבל את השוויון שרצינו:

{% equation %}\int_{a}^{b}\left(f\circ g\right)\left(x\right)g^{\prime}\left(x\right)dx=\int_{a}^{b}H^{\prime}\left(x\right)dx=H\left(b\right)-H\left(a\right)=F\left(g\left(b\right)\right)-F\left(g\left(a\right)\right)=\int_{g\left(a\right)}^{g\left(b\right)}f\left(y\right)dy{% endequation %}

זה מסיים את ההוכחה, אבל לפני שנסיים את הפוסט, בואו נראה כמה שימושים של העסק הזה כדי שלא נהיה לחלוטין באוויר. מה שכדאי לזכור כשבאים להשתמש בהחלפת משתנים בפועל הוא שאפשר להשתמש במשפט בשני הכיוונים שלו. באחד מהם אנחנו לוקחים ביטוי מסובך שמופיע בתוך האינטגרל ומחליפים אותו במשתנה חדש, אבל כדי שהקסם הזה יעבוד אנחנו חייבים שהביטוי הזה יכלול גם את הנגזרת של מה שהמשתנה בא לייצג לבסוף - כלומר, צריך לזהות תבניות מאוד ספציפיות. בכיוון השני אנחנו פשוט מחליפים את {% equation %}x{% endequation %} בביטוי מורכב יותר וה"עונש" שאנחנו משלמים על כך הוא שאנחנו צריכים לכפול בנגזרת של הביטוי המורכב הזה.

אני אתחיל דווקא עם דוגמה עבור הכיוון השני, כי טרם ראינו אותו בפעולה. בואו נחשב את האינטגרל {% equation %}\int_{0}^{1}\sqrt{1-x^{2}}dx{% endequation %}. זה נראה כמו אינטגרל מזעזע כי יש שם שורש ועניינים. אז משתמשים בתעלול מהסוג שכולנו אוהבים במתמטיקה - מכניסים מושג מתחום לכאורה לא קשור, שמפשט לנו את הבעיה. במקרה שלנו, טריגונומטריה. הזהות הבסיסית ביותר בטריגונומטריה היא {% equation %}\sin^{2}\alpha+\cos^{2}\alpha=1{% endequation %} (זה נובע ישירות ממשפט פיתגורס), ודרך אחרת לחשוב על זה היא בתור {% equation %}\sin\alpha=\pm\sqrt{1-\cos^{2}\alpha}{% endequation %}, שכבר נראה כמו הביטוי שאצלנו. אז נשתמש בהצבה שמחליפה את {% equation %}x{% endequation %} בפונקציה טריגונומטרית; לטכניקה הזו קוראים "הצבה טריגונומטרית" והיא יעילה למדי בחישוב כל מני אינטגרלים שנראים אבודים.

במקרה הזה, {% equation %}f\left(x\right)=\sqrt{1-x^{2}}{% endequation %} ואנחנו משתמשים ב-{% equation %}g\left(y\right)=\cos y{% endequation %} כדי לעבור מ-{% equation %}\int f\left(x\right)dx{% endequation %} אל {% equation %}\int f\left(g\left(y\right)\right)g^{\prime}\left(y\right)dy{% endequation %}. יש דרך ציורית לזכור את מה שמבצעים כאן - הביטו בביטוי {% equation %}\int\sqrt{1-x^{2}}dx{% endequation %}. כשאנחנו מבצעים את ההחלפה, אנחנו מחליפים את {% equation %}x{% endequation %} ב-{% equation %}\cos y{% endequation %}, ואפשר לשחק ב"נדמה לי" שאנחנו מחליפים את {% equation %}dx{% endequation %} ב<strong>נגזרת</strong> של הביטוי בהחלפה, כלומר ב-{% equation %}d\left(\cos y\right){% endequation %}. למה "נדמה לי"? כי ה-{% equation %}dx{% endequation %} הזה, זכרו, הוא לא אובייקט פורמלי כלשהו, אלא רק צורת כתיב (יש דרך לתת לו משמעות פורמלית אבל אנחנו ממש לא שם כרגע). האינטואיציה היא ש-{% equation %}d\left(\cos y\right)=-\sin ydy{% endequation %}, כשה-{% equation %}dy{% endequation %} הנוסף הגיע מכך שאנחנו "גוזרים את ה-{% equation %}y{% endequation %} שבתוך ה-{% equation %}\cos{% endequation %}". עכשיו צריך לטפל גם בגבולות האינטגרציה; במקרה שלנו ה-{% equation %}\int_{0}^{1}{% endequation %} שהתחלנו ממנו הוא כבר במשמעות של {% equation %}\int_{g\left(a\right)}^{g\left(b\right)}{% endequation %} ולכן צריך להתאמץ קצת כדי למצוא את ה-{% equation %}a,b{% endequation %}: {% equation %}0=\cos a{% endequation %} ו-{% equation %}1=\cos b{% endequation %} מובילים אותנו לבחור {% equation %}a=\frac{\pi}{2}{% endequation %} ו-{% equation %}b=0{% endequation %}. נקבל, אם כן:

{% equation %}\int_{0}^{1}\sqrt{1-x^{2}}dx=\int_{\pi/2}^{0}-\sqrt{1-\cos^{2}y}\sin ydy=\int_{0}^{\pi/2}\sin^{2}ydy{% endequation %}

אינטגרל של סינוס בריבוע נראה כמו עניין כואב, אבל למזלנו יש לנו את הזהות הטריגונומטרית {% equation %}\sin^{2}y=\frac{1-\cos2y}{2}{% endequation %}, כך שבעצם קיבלנו פה שני אינטגרלים קלים יחסית:

{% equation %}\int_{0}^{\pi/2}\sin^{2}ydy=\int_{0}^{\pi/2}\frac{dy}{2}-\frac{1}{2}\int_{0}^{\pi/2}\cos2ydy={% endequation %}

{% equation %}=\left[\frac{y}{2}\right]_{0}^{\pi/2}-\frac{1}{2}\left[\frac{\sin2y}{2}\right]_{0}^{\pi/2}=\frac{\pi}{4}{% endequation %}

כשכל החלק ה"טריגונומטרי" (המחובר הימני) מתאפס.

שימו לב לתוצאה המעניינת שקיבלנו - באינטגרל המקורי לא היה זכר לטריגונומטריה, אבל התוצאה המספרית שלנו יצאה {% equation %}\frac{\pi}{4}{% endequation %}. כנראה שהבחירה ללכת בדרך הטריגונומטריה אכן הייתה מוצדקת במובן כלשהו (פרט למובן של "היי, תראו, זה פתר את זה!")

בואו נעבור עכשיו לדוגמה מהסוג השני. נניח שאנחנו רוצים לחשב את {% equation %}\int_{0}^{1}\left(x^{3}+2\right)^{2}x^{2}dx{% endequation %}. הביטוי נראה מזעזע, אבל אנחנו חדי עין ורואים שה-{% equation %}x^{2}{% endequation %} שמחוץ לסוגריים נראה <strong>בערך </strong>כמו הנגזרת של הביטוי בתוך הסוגריים. זה נותן לנו אינטואיציה לגבי הצבה שכדאי להשתמש כאן כדי לפשט את המפלצת הזו - הצבה שתעלים לנו את ה-{% equation %}x^{2}{% endequation %} שבחוץ ותהפוך את מה שבסוגריים לפשוט: {% equation %}t=x^{3}+2{% endequation %}.

שימו לב להבדל. כאן אני מגדיר משתנה חדש {% equation %}t{% endequation %} בתור פונקציה של {% equation %}x{% endequation %}, ואילו קודם כתבתי את {% equation %}x{% endequation %} בתור פונקציה של משתנה חדש. זו הסיבה שקודם אני כפלתי ב-{% equation %}g^{\prime}{% endequation %} ואילו עכשיו אני "בולע" את ה-{% equation %}g^{\prime}{% endequation %}. אצלי כל הביטוי {% equation %}\left(x^{3}+2\right)^{2}x^{2}dx{% endequation %} הופך להיות {% equation %}\frac{1}{3}t^{2}dt{% endequation %}. שימו לב ל-{% equation %}\frac{1}{3}{% endequation %} הזה; הוא לא צץ משום מקום. אם {% equation %}t=x^{3}+2{% endequation %} אז (שוב, זה סימון נוח, אין פה משמעות פורמלית מעבר לכך) {% equation %}dt=3x^{2}dx{% endequation %} ולכן {% equation %}x^{2}dx=\frac{1}{3}dt{% endequation %}. ואיך משתנים הגבולות? הפעם אני פשוט מציב את הגבולות בנוסחה {% equation %}t=x^{3}+2{% endequation %}:

{% equation %}\int_{0}^{1}\left(x^{3}+2\right)^{2}x^{2}dx=\frac{1}{3}\int_{2}^{3}t^{2}dt=\frac{1}{3}\left[\frac{t^{3}}{3}\right]_{2}^{3}=\frac{27-8}{9}=\frac{19}{9}{% endequation %}

זהו זה עם הדוגמאות. אבל לפני שנסיים, אני בטוח שכולכם מצפים בכליון עיניים לראות את משפט החלפת המשתנים הכללי עבור אינטגרלים מעל {% equation %}\mathbb{R}^{n}{% endequation %}. אז הנה הניסוח, כדי שנוכל להתרשם כמה הוא דומה לניסוח של המשפט הבסיסי: אם {% equation %}g:A\to B{% endequation %} היא <strong>דיפאומורפיזם</strong> של קבוצות פתוחות ב-{% equation %}\mathbb{R}^{n}{% endequation %} ו-{% equation %}f:B\to\mathbb{R}{% endequation %} רציפה, אז {% equation %}f{% endequation %} אינטגרבילית מעל {% equation %}B{% endequation %} אם ורק אם {% equation %}\left(f\circ g\right)\left|\det Dg\right|{% endequation %} אינטגרבילית מעל {% equation %}A{% endequation %} ובמקרה זה מתקיים:

{% equation %}\int_{B}f=\int_{A}\left(f\circ g\right)\left|\det Dg\right|{% endequation %}

מה השתנה, בעצם? ראשית, במקום שיהיה כתוב {% equation %}\left|g^{\prime}\right|{% endequation %} כתוב {% equation %}\left|\det Dg\right|{% endequation %}, אבל היינו יכולים להשתמש באותו כתיב גם במקרה החד-ממדי; במקרה החד-ממדי המספר הנגזר בנקודה מסויימת הוא בדיוק הדטרמיננטה של הנגזרת (במובן הרב-ממדי של הנגזרת - קירוב לינארי) באותה נקודה. הדבר השני שהשתנה הוא שבמקום כל מני הנחות על {% equation %}g{% endequation %} אנחנו אומרים שהיא "דיפאומורפיזם", שזה מושג שבכלל לא הגדרתי, אבל אין בו משהו מיוחד - זו פונקציה {% equation %}g:A\to B{% endequation %} שהיא חד-חד-ערכית ועל, כך שגם {% equation %}g{% endequation %} וגם {% equation %}g^{-1}{% endequation %} שייכות ל-{% equation %}C^{r}{% endequation %} עבור {% equation %}r\ge1{% endequation %} כלשהו. כפי שניתן לנחש מכך שיש להן שם מיוחד, פונקציות שהן דיפאומורפיזמים הן בעלות חשיבות כללית באנליזה וקטורית, לא רק עבור משפט החלפת המשתנים.

אם כן, זה המשפט בגרסתו הכללית, אבל איך מוכיחים אותו בגרסה הזו? או, טוב ששאלתם. זה ידרוש עוד לא מעט עבודה.
