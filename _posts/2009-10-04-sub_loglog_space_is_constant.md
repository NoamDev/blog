---
id: 211
title: "למה זכרון שהוא פחות מלגלג הוא קבוע?"
date: 2009-10-04 22:44:43
layout: post
categories: 
  - תורת הסיבוכיות
tags: 
  - סיבוכיות זכרון
---
ב<a href="http://www.gadial.net/?p=204">פוסט קודם</a> הזכרתי בחטף טענה ב<a href="http://he.wikipedia.org/wiki/%D7%A1%D7%99%D7%91%D7%95%D7%9B%D7%99%D7%95%D7%AA">תורת הסיבוכיות</a> שנשמעת מוזרה מעט במבט ראשון - שאם בעיה דורשת כמות נמוכה יחסית של זכרון לפתרונה, אך כזו שעדיין תלויה בגודל הקלט (ועל כן, כאשר הקלט גדל עוד ועוד גם הזכרון גדל עוד ועוד, "לאינסוף"), הרי שלמעשה ניתן לפתור אותה תוך שימוש בכמות קבועה של זכרון (בלי תלות בגודל הקלט), וחסל. ה"נמוכה יחסית" הייתה, מבחינה פורמלית, כל פונקציה שקטנה ממש אסימפטוטית מ-{::nomarkdown}\( \lg\lg n\){:/nomarkdown} (הכוונה בכך היא שניתן להקטין את היחס {::nomarkdown}\( \frac{f\left(n\right)}{\lg\lg n}\){:/nomarkdown} כרצוננו ככל שנגדיל את {::nomarkdown}\( n\){:/nomarkdown}).

בפוסט הזה אני רוצה להראות בדיוק מדוע זה כך. ההוכחה אינה קלה במיוחד, אך היא משתמשת ברעיונות שכולם סטנדרטיים יחסית בתורת הסיבוכיות ולכן היא מספקת תירוץ טוב להציג אותם. הרעיון הבסיסי הוא שמכונה שמשתמשת רק בכמות עלובה כל כך של זכרון אינה מסוגלת לעשות כמעט שום דבר מעניין - בפרט, היא לא יכולה להשתמש ברוב הזכרון שעומד לרשותה כי אז היא "תתבלבל" ותנצל כמות גדולה הרבה יותר שלו. באופן טיפה יותר פורמלי מה שעושים הוא לקחת מכונה {::nomarkdown}\( M\){:/nomarkdown} שפועלת בסיבוכיות זכרון {::nomarkdown}\( f\left(n\right)\){:/nomarkdown} קטנה כמתואר לעיל, ולתת באופן כמעט מפורש חסם קבוע (שאינו תלוי ב-{::nomarkdown}\( n\){:/nomarkdown}) על כמות הזכרון שהמכונה תצרוך באמת בכל ריצה שלה. כדי להשתכנע שהחסם עובד, פועלים בדרך השלילה - מניחים שיש קלטים שעליהם המכונה חורגת מהחסם, לוקחים את המינימלי שבהם, ומראים שאפשר לקצר גם אותו ועדיין לקבל קלט שעליו המכונה חורגת מהחסם - סתירה למינימליות. עיקר החוכמה כאן היא איך מראים שאפשר לקצר את הקלט - זה דורש ניתוח מדוקדק יחסית של התנהגות המכונה על כל ביט בקלט והדגמה שקיימים שני ביטים שהם "זהים" מבחינת התנהגות המכונה עליהם, ניתוח שהוא טכני באופן בלתי נמנע.

התוצאה הזו היא אחד מהמקומות שבהם יש חשיבות גדולה למודל הספציפי של החישוב שאנחנו בוחרים - עבור מודל אחר ככל הנראה הפונקציה היתה שונה (במודלים "מתוחכמים" יותר אפשר להסתיר פעולות בעלות סיבוכיות לא קבועה תחת מעטה של "פעולה אטומית"). לכן אתאר בקצרה את המודל שלנו - <a href="http://he.wikipedia.org/wiki/%D7%9E%D7%9B%D7%95%D7%A0%D7%AA_%D7%98%D7%99%D7%95%D7%A8%D7%99%D7%A0%D7%92">מכונת טיורינג</a> היא יצור שמורכב מסרט קלט (הניתן לקריאה בלבד), סרט עבודה לקריאה ולכתיבה, ראש קורא שנע על סרט הקלט, ראש קורא/כותב שנע על סרט העבודה, ואוסף {::nomarkdown}\( Q\){:/nomarkdown} של "מצבים פנימיים", שהמכונה נמצאת כל רגע באחד מהם. המכונה פועלת ב"צעדים", כאשר ההתנהגות בכל צעד נקבעת על פי המצב הפנימי של המכונה ותוכן התאים ששני הראשים קוראים; ובכל צעד המכונה יכולה לשנות את המצב הפנימי שלה, לכתוב תו על סרט העבודה במקום התו שהיה קודם במקום שעליו הראש הצביע, ולהזיז כל אחד מהראשים צעד אחד ימינה או שמאלה (הם בלתי תלויים זה בזה). זה הכל. בניסוחים נאיביים בדרך כלל לא טורחים לתת למכונה שני סרטים, וסרט הקלט משמש גם לקריאה וגם לכתיבה; אבל מכיוון שאנחנו עוסקים כאן בסיבוכיות זכרון שקטנה בהרבה מגודל הקלט, ההפרדה בין הזכרון של הקלט והזכרון שעליו כותבים היא הכרחית.

כעת הגיע הזמן להציג את המושג המרכזי בהוכחה (ומושג חשוב באופן כללי בתורת הסיבוכיות) - ה"קונפיגורציה" של המכונה (תרגום לעברית יכול להיות "תיאור רגעי", אבל אני מעדיף את הלועזית כאן). גם כאן אתן הגדרה שתפורה עבור ההוכחה הזו, ואינה זהה לחלוטין להגדרה הסטנדרטית. קונפיגורציה של מכונה באה לתאר את מצבה הרגעי במהלך חישוב, ומורכבת מתוכן סרט העבודה ("הסרט כרגע מכיל את המחרוזת 01001"), מיקום הראש הקורא/כותב עליו ("הראש כרגע מעל תא מספר 3"), התוכן של התא שהראש הקורא נמצא מעליו כרגע ("אני קורא את הביט 1") והמצב הפנימי הנוכחי של המכונה ("המכונה במצב פנימי מספר 17"). האבחנה המרכזית הנוגעת לקונפיגורציות היא שאם המכונה נמצאת באותה קונפיגורציה פעמיים במהלך החישוב שלה, כשבנוסף לכך בשתי הפעמים הללו הראש הקורא נמצא מעל אותו תא - פירוש הדבר הוא שהיא בלולאה אינסופית. מדוע? כי הקונפיגורציה הנוכחית, בתוספת מיקום הראש הקורא, קובעות בצורה יחידה ודטרמיניסטית את התנהגות המכונה בצעד הבא, ובפרט את הקונפיגורציה הבאה (והמיקום הבא של הראש הקורא). חשבו על תוכנית מחשב שמגיעה פעמיים לאותה שורת קוד, כשמצב כל המשתנים בתוכנית זהה בין שתי הפעמים - אם היא הגיעה משורה 17 שוב אל שורה 17 מבלי שכלום השתנה, אז בגלל הדטרמיניזם של אופן פעולתה, היא שוב תגיע לשורה 17 מבלי לשנות שום דבר, ושוב ושוב עד אין קץ.

נניח שהמכונה שלנו רצה על קלט מאורך {::nomarkdown}\( n\){:/nomarkdown}, ולכן היא יכולה להשתמש לכל היותר ב-{::nomarkdown}\( f\left(n\right)\){:/nomarkdown} תאים של זכרון העבודה. כמה קונפיגורציות שונות אפשריות קיימות עבורה? לצורך העניין נניח שסרט העבודה מכיל רק ביטים, אז יש {::nomarkdown}\( 2^{f\left(n\right)}\){:/nomarkdown} אפשרויות שונות לתוכן סרט העבודה (קומבינטוריקה פשוטה: לכל אחד מ-{::nomarkdown}\( f\left(n\right)\){:/nomarkdown} התאים יש לנו שתי אפשרויות, 0 או 1, וכל תא נקבע באופן בלתי תלוי באחרים). כמו כן יש {::nomarkdown}\( f\left(n\right)\){:/nomarkdown} אפשרויות למיקום הראש הקורא/כותב, 2 אפשרויות לתוכן התא שהראש הקורא קורא ו-{::nomarkdown}\( \left\|Q\right\|\){:/nomarkdown}מצבים פנימיים אפשריים (זה מספר קבוע שאינו תלוי ב-{::nomarkdown}\( n\){:/nomarkdown} ולכן אינו כה מעניין). סה"כ יש {::nomarkdown}\( t\left(n\right)=2\cdot\left\|Q\right\|\cdot f\left(n\right)\cdot2^{f\left(n\right)}=O\left(2^{f\left(n\right)}\right)\){:/nomarkdown} קונפיגורציות אפשריות. אם כן, אם הראש הקורא של המכונה מבקר בתא כלשהו בסרט הקלט יותר מ-{::nomarkdown}\( t\left(n\right)\){:/nomarkdown} פעמיים, המכונה נכנסה ללולאה אינסופית, כי היינו באותה קונפיגורציה פעמיים בעת שהראש הקורא היה באותו תא (למה היינו באותה קונפיגורציה פעמיים? <a href="http://he.wikipedia.org/wiki/%D7%A2%D7%A7%D7%A8%D7%95%D7%9F_%D7%A9%D7%95%D7%91%D7%9A_%D7%94%D7%99%D7%95%D7%A0%D7%99%D7%9D">עקרון שובך היונים</a>).

כעת מגיע אחד מהרעיונות המורכבים ביותר בהוכחה. לכל תא בסרט <strong>הקלט</strong>, נבנה רשימה של כל הקונפיגורציות שבהן המכונה הייתה בשעה שהיא ביקרה בתא הזה. למשל, הרשימה "11,53,23" עבור תא מס' 3 אומרת שבפעם הראשונה שבה המכונה הגיעה לתא מס' 3, היא הייתה בקונפיגורציה 11, ובפעם השניה שבה היא הגיעה לתא מס' 3 (אולי אלפי צעדים לאחר מכן) היא הייתה בקונפיגורציה 53; ובפעם השלישית - בואו נניח שהיא הייתה מייד לאחר הפעם השניה, כי הראש הקורא לא זז - היא שינתה משהו בסרט העבודה שלה ועברה לקונפיגורציה 23. המספרים מומצאים, כמובן, אבל זה הרעיון. השאלה המהותית כאן היא מה האורך האפשרי של הרשימה הזו? התשובה פשוטה, ונעוצה במה שאמרתי לפני שנייה: אם הרשימה (עבור תא <strong>כלשהו</strong>) תכיל יותר מ-{::nomarkdown}\( t\left(n\right)\){:/nomarkdown} איברים, פירוש הדבר שהמכונה בלולאה אינסופית ולכן הרשימה תתחיל לחזור על עצמה לאחר מכן. מכאן שיש בסך הכל {::nomarkdown}\( t\left(n\right)^{t\left(n\right)}\){:/nomarkdown} סדרות אפשריות שכאלו של קונפיגורציות (כי אמרנו שיש לכל היותר {::nomarkdown}\( t\left(n\right)\){:/nomarkdown} איברים בסדרה, ו"איבר" יכול להיות כל אחת מ-{::nomarkdown}\( t\left(n\right)\){:/nomarkdown} הקונפיגורציות החוקיות). מסובך? כן, בהחלט; רצוי לקרוא את זה כמה פעמים (וגם אם לא מבינים, זה לא סוף העולם).

אנחנו חותרים להראות שעבור ריצות "בעייתיות" לכאורה עבורנו, נצליח למצוא כמה וכמה תאים בסרט הקלט שסדרת הקונפיגורציות שלהן תהיה זהה (ולכן התנהגות המכונה עליהן תהיה זהה). לשם כך אנחנו רוצים למצוא {::nomarkdown}\( n\){:/nomarkdown}-ים שעבורם יש יחסית מעט סדרות של קונפיגורציות, ויחסית הרבה תאי קלט - למעשה, פי שלוש מאשר סדרות של קונפיגורציות. זה נשמע מופרך - הרי יש {::nomarkdown}\( n\){:/nomarkdown} תאי קלט, אבל {::nomarkdown}\( t\left(n\right)^{t\left(n\right)}\){:/nomarkdown} סדרות; והרי פונקציות אקספוננציאליות גדלות מהר מאוד - אם כן, איך ייתכן שיהיה {::nomarkdown}\( n\){:/nomarkdown} שעבורו {::nomarkdown}\( t\left(n\right)^{t\left(n\right)}&lt;n\){:/nomarkdown}? התשובה פשוטה - אל תשכחו ש-{::nomarkdown}\( f\left(n\right)\){:/nomarkdown}, סיבוכיות הזכרון שלנו, היא קטנה מאוד, הרבה הרבה הרבה יותר קטנה מ-{::nomarkdown}\( n\){:/nomarkdown}; זה בדיוק הרעיון כאן, וזה גם המקום שממנו החסם על {::nomarkdown}\( f\left(n\right)\){:/nomarkdown} מגיע. אם {::nomarkdown}\( f\left(n\right)=o\left(\lg\lg n\right)\){:/nomarkdown}, אז מתקיים ש-{::nomarkdown}\( t\left(n\right)^{t\left(n\right)}=o\left(n\right)\){:/nomarkdown}, כלומר קיים {::nomarkdown}\( n_{0}\){:/nomarkdown} גדול דיו כך שלכל {::nomarkdown}\( n&gt;n_{0}\){:/nomarkdown} מתקיים {::nomarkdown}\( t\left(n\right)^{t\left(n\right)}&lt;\frac{n}{3}\){:/nomarkdown}. אני לא אכנס כאן לפרטי ההוכחה שהם טכניים ולא מעניינים - ה"אינטואיציה" היא שהחלק הדומיננטי ביותר ב-{::nomarkdown}\( t\left(n\right)^{t\left(n\right)}\){:/nomarkdown} הוא מהצורה {::nomarkdown}\( 2^{2^{f\left(n\right)}}\){:/nomarkdown}, ושתי החזקות הללו "נאכלות" בידי הלוגריתם הכפול (כלומר: {::nomarkdown}\( 2^{2^{f\left(n\right)}}=o\left(2^{2^{\lg\lg n}}\right)=o\left(2^{\lg n}\right)=o\left(n\right)\){:/nomarkdown}).

כעת הגענו לטענה המרכזית שלנו - המכונה לא משתמשת ביותר מאשר {::nomarkdown}\( f\left(n_{0}\right)\){:/nomarkdown} זכרון בכלל, על כל קלט. מכיוון ש-{::nomarkdown}\( n_{0}\){:/nomarkdown} הוא קבוע (ואפילו הראינו דרך יחסית קונסטרוקטיבית למצוא אותו), גם {::nomarkdown}\( f\left(n_{0}\right)\){:/nomarkdown} הוא קבוע, ולכן הטענה הזו מסיימת את ההוכחה. כדי להראות אותה, נניח בשלילה שהיא איננה נכונה וניקח את הקלט {::nomarkdown}\( x\){:/nomarkdown} בעל האורך המינימלי שעדיין גדול מ-{::nomarkdown}\( n_{0}\){:/nomarkdown} (כלומר, {::nomarkdown}\( \left\|x\right\|=n&gt;n_{0}\){:/nomarkdown}) שבריצתה עליו המכונה משתמשת ביותר מ-{::nomarkdown}\( f\left(n_{0}\right)\){:/nomarkdown} זכרון. מה שנראה הוא שניתן להקטין את {::nomarkdown}\( x\){:/nomarkdown} ולקבל קלט אחר, {::nomarkdown}\( x^{\prime}\){:/nomarkdown}, שעליו המכונה מתנהגת באופן זהה, ולכן גם מנצלת את אותה כמות זכרון, וזוהי סתירה למינימליות {::nomarkdown}\( x\){:/nomarkdown}. במילים אחרות - אנחנו מראים שעל קלטים ארוכים מספיק, המכונה מתנהגת באופן זהה לזה שבו היא מתנהגת על קלטים קצרים יותר - ולכן צריכת הזיכרון שלה היא לא יותר מאשר צריכת הזיכרון המקסימלית של המכונה על אחד מאותם קלטים קצרים. מכיוון שיש מספר סופי של קלטים קצרים שכזה, צריכת הזכרון המקסימלית הזו היא מספר קבוע.

כעת נעבור לפאנץ' שמסביר את קיום מספר הקסם המסתורי {::nomarkdown}\( \frac{n}{3}\){:/nomarkdown}. מכיוון ש-{::nomarkdown}\( \left\|x\right\|=n&gt;n_{0}\){:/nomarkdown} אז {::nomarkdown}\( t\left(n\right)^{t\left(n\right)}&lt;\frac{n}{3}\){:/nomarkdown}. ובמילים - מספר סדרות הקונפיגורציות האפשריות הוא פחות משליש ממספר תאי הזכרון. מכאן נובע שיש לפחות שלושה תאי זכרון <strong>עם אותה סדרת קונפיגורציות בדיוק</strong>. נניח שהתוכן שלהם הוא 0 (עבור תוכן של 1 ההוכחה היא אותו דבר), אז ניתן לתאר את הקלט כולו כך: {::nomarkdown}\( x=\alpha0\beta0\gamma0\delta\){:/nomarkdown}, כש-{::nomarkdown}\( \alpha,\beta,\gamma,\delta\){:/nomarkdown} הם פשוט סימונים לתת-מחרוזות. כן, אני יודע שזה נראה קצת מפחיד.

מה שאני רוצה להראות הוא שגם אם אקצץ את {::nomarkdown}\( \beta0\){:/nomarkdown} מהמחרוזת הזו ואקבל {::nomarkdown}\( x^{\prime}=\alpha0\gamma0\delta\){:/nomarkdown}, ההתנהגות של המכונה על הקלט תהיה זהה (חוץ מההתנהגות שלה על הקטע {::nomarkdown}\( \beta\){:/nomarkdown} שכבר אינו קיים). כמקודם, זה טכני ואעדיף שלא לחפור יותר מדי בפרטים, אבל הנה הרעיון הכללי: כל עוד המכונה (שמתחילה לעבור על הקלט מצד שמאל) מתרוצצת על החלק של {::nomarkdown}\( \alpha\){:/nomarkdown} ברור שההתנהגות שלה זהה הן עבור {::nomarkdown}\( x\){:/nomarkdown} והן עבור {::nomarkdown}\( x^{\prime}\){:/nomarkdown}. בכל פעם שהיא מגיעה ל-0 הראשון היא עשויה או לפנות שמאלה, או ימינה. אם היא פונה שמאלה היא ממשיכה להתעסק באיזור ה-{::nomarkdown}\( \alpha\){:/nomarkdown}; כשהיא פונה ימינה לראשונה, נניח בביקור ה-{::nomarkdown}\( i\){:/nomarkdown}, זה יהיה כך הן עבור {::nomarkdown}\( x\){:/nomarkdown} והן עבור {::nomarkdown}\( x^{\prime}\){:/nomarkdown} - המכונה תהיה באותה קונפיגורציה. כעת ריצת המכונה על {::nomarkdown}\( x\){:/nomarkdown} מגיעה לאיזור של {::nomarkdown}\( \beta\){:/nomarkdown} ומי יודע מה קורה שם, אבל דבר אחד ברור - בכל פעם שהיא מגיעה אל ה-{::nomarkdown}\( 0\){:/nomarkdown} שמימין לאותו {::nomarkdown}\( \beta\){:/nomarkdown}, היא תפנה שמאלה, עד הפעם ה-{::nomarkdown}\( i\){:/nomarkdown} בדיוק - וזאת בגלל שסדרת הקונפיגורציות של ה-{::nomarkdown}\( 0\){:/nomarkdown} שליד {::nomarkdown}\( \alpha\){:/nomarkdown} וה-{::nomarkdown}\( 0\){:/nomarkdown} שליד {::nomarkdown}\( \beta\){:/nomarkdown} זהה, ולכן ההתנהגות של המכונה שם היא זהה.

כלומר, בפעם הראשונה שבה המכונה תפנה <strong>ימינה</strong> ב-{::nomarkdown}\( 0\){:/nomarkdown} שאחרי ה-{::nomarkdown}\( \beta\){:/nomarkdown} זה יהיה בביקור ה-{::nomarkdown}\( i\){:/nomarkdown} של המכונה שם - כלומר, כשהיא נמצאת באותה קונפיגורציה בדיוק כמו המכונה בריצתה על {::nomarkdown}\( x^{\prime}\){:/nomarkdown} כשהיא פנתה ימינה בביקור ה-{::nomarkdown}\( i\){:/nomarkdown} שלה על ה-{::nomarkdown}\( 0\){:/nomarkdown} שליד {::nomarkdown}\( \alpha\){:/nomarkdown}... אני מקווה שהבנתם את הרעיון. אם לא, נסו לשחק את המשחק בעצמכם קצת - זו כנראה הדרך היחידה להבין עד הסוף, שאינה טרוחה בהוכחה ארוכה וטרחנית. אם טרם הבנתם, קחו את המילה שלי לגבי העניין הזה.

באופן דומה אפשר להראות שגם על {::nomarkdown}\( x^{\prime\prime}=\alpha0\beta0\delta\){:/nomarkdown} המכונה מתנהגת כמו שהיא מתנהגת על {::nomarkdown}\( x\){:/nomarkdown}. כעת אפשר להגיע לפאנץ' הסופי. אנחנו יודעים שלצריכת הזיכרון המקסימלית שלה המכונה מגיעה כשהיא על תו כלשהו מהקלט, אבל איזה תו? אם הוא ב-{::nomarkdown}\( \alpha\){:/nomarkdown}, או ב-{::nomarkdown}\( \gamma\){:/nomarkdown}, או ב-{::nomarkdown}\( \delta\){:/nomarkdown}, או ב-{::nomarkdown}\( 0\){:/nomarkdown} שליד {::nomarkdown}\( \alpha\){:/nomarkdown}, או ב-{::nomarkdown}\( 0\){:/nomarkdown} שליד {::nomarkdown}\( \gamma\){:/nomarkdown} - בכל אחד מהמקרים הללו, התו הזה קיים גם ב-{::nomarkdown}\( x^{\prime}\){:/nomarkdown} והמכונה מתנהגת עליו באותו אופן - כלומר, המכונה מגיעה לצריכת הזכרון המקסימלית שלה גם על {::nomarkdown}\( x^{\prime}\){:/nomarkdown} הקטן מ-{::nomarkdown}\( x\){:/nomarkdown}. ואם צריכת הזכרון המקסימלית היא ב-{::nomarkdown}\( \beta\){:/nomarkdown} או ב-{::nomarkdown}\( 0\){:/nomarkdown} שלידו, אז היא מגיעה אליו ב-{::nomarkdown}\( x^{\prime\prime}\){:/nomarkdown} הקטן יותר מ-{::nomarkdown}\( x\){:/nomarkdown}. זו הסיבה שנזקקנו הן ל-{::nomarkdown}\( x^{\prime}\){:/nomarkdown} והן ל-{::nomarkdown}\( x^{\prime\prime}\){:/nomarkdown} - כדי למנוע את המצב המעצבן שבו צריכת הזכרון המקסימלית היא דווקא בתוך החלק מהמילה שאנחנו מקצצים.

זה סוף ההוכחה. היא הייתה מאוד טכנית, כמו שהבטחתי, אך אני מקווה שלפחות חלק מהרעיונות שבה ברורים כעת יותר, ושעוד נפגוש בהם בעתיד.
